# -*- coding: utf-8 -*-
## import django 
from django.shortcuts import get_object_or_404, render, redirect
from django.http import HttpResponse
from django.template import loader
from django.conf import settings
from django.core.files.storage import FileSystemStorage
from django.contrib.auth.models import User

## import methods defined on utils.py
from .utils.sample_convertion import *
from .utils.stats_calculation import *
from .utils.stats_graphics import *

from .models import *

from .fusioncharts.fusioncharts import FusionCharts
import statistics

import re, os, shutil
import datetime, time

#import pdb; pdb.set_trace()


def index(request):
    #latest_question_list = Question.objects.order_by('-pub_date')[:5]
    #context = {'latest_question_list': latest_question_list}
    return render(request, 'wetlab/index.html')

def get_sample_file (request):
    if request.method == 'POST' and (request.POST['action']=='uploadFile'):
        ### First step in collecting data from the NextSeq run. Sample Sheet and experiment name are required
        
        get_user_names={}
        projects=[]
        run_name=request.POST['runname']
        myfile = request.FILES['myfile']
        ## check that runName is not already used in the database. Error page is showed if runName is already  defined
        if (RunProcess.objects.filter(runName = run_name)).exists():
            return render (request,'wetlab/error_page.html', {'content':['Run Name is already used. ','Run Name must be unique in database.',' ',
                                                            'ADVICE:','Change the value of run name in the "run name Field"']})
        ## check if file contains the extension. Error page is showed if file does not contain any extension
        try:
            split_filename=re.search('(.*)(\.\w+$)',myfile.name)
        except:
            return render (request,'wetlab/error_page.html', {'content':['Uploaded file does not containt extension', 'Sample Sheet must have a csv extension','',
                                                            'ADVICE:','Select the Sample file generated by Illumina Experient Manager (IEM)']})
        ext_file=split_filename.group(2)
        ## check if file contains the csv extension. Error page is showed if file does not contain the csv extension
        if ext_file != '.csv':
            return render (request,'wetlab/error_page.html', {'content':['Sample Sheet must have a csv extension','',
                                                            'ADVICE:','Select the Sample file generated by Illumina Experient Manager (IEM)']})
        fs = FileSystemStorage()
        timestr = time.strftime("%Y%m%d-%H%M%S")
        ## including the timestamp to the sample sheet file
        #import pdb; pdb.set_trace()
        file_name=str('wetlab/documents/' + split_filename.group(1) + timestr + ext_file)
        filename = fs.save(file_name,  myfile)
        uploaded_file_url = fs.url(filename)
        
        ### add the document directory to read the csv file
        stored_file=str('documents/' + file_name)
        ## Fetch from the Sample Sheet file the projects included in the run and the user. Error page is showed if not project/description colunms are found
        try:        
            project_list=get_projects_in_run(stored_file)
        except:

            ## delete sample sheet file 
            fs.delete(file_name)
            return render (request,'wetlab/error_page.html', {'content':['Sample Sheet does not contain "Sample_proyect" and/or "Description" fields','',
                                                            'ADVICE:','Check that csv file generated by Illumina Experient Manager (IEM) includes these columns']})
        ## Check if the users are already defined on database. Error page is showed if users are not defined on database
        user_already_defined=[]
        for key, val  in project_list.items():
            if ( not User.objects.filter(username__icontains = val).exists()):
                user_already_defined.append(val)
        if (len(user_already_defined)>0):
            if (len(user_already_defined)>1):
                head_text='The following users are not defined in database:'
            else:
                head_text='The following user is not defined in database:'
            ## convert the list into string to display the user names on error page
            display_user= ' ,  '.join(user_already_defined)
            ## delete sample sheet file before showing the error page
            #import pdb; pdb.set_trace()
            fs.delete(file_name)
                
            return render (request,'wetlab/error_page.html', {'content':[ head_text,'', display_user,'', 
                           'Researcher names must be installed in database before uploading the Sample sheet']})
        ## Check if the projects are already defined on database. Error page is showed if projects are already defined on database
        #import pdb; pdb.set_trace()
        project_already_defined=[]
        for key, val  in project_list.items():
            if ( Projects.objects.filter(projectName__icontains = key).exists()):
                project_already_defined.append(val)
        if (len(project_already_defined)>0):
            if (len(project_already_defined)>1):
                head_text='The following projects are already defined in database:'
            else:
                head_text='The following project is already defined in database:'
            ## convert the list into string to display the user names on error page
            display_project= '  '.join(project_already_defined)
                ## delete sample sheet file before showing the error page
            fs.delete(file_name)
            return render (request,'wetlab/error_page.html', {'content':[ head_text,'', display_project,'', 
                          'Project names must be unique','', 'ADVICE:','Edit the installed in the database before uploading the Sample sheet']})
        ##Once the information looks good. it will be stores in runProcess and projects table 
        

        #import pdb; pdb.set_trace()

        ## store data in runProcess table, run is in pre-recorded state
        run_proc_data = RunProcess(runName=run_name,sampleSheet= file_name, runState='Pre-Recorded')
        run_proc_data.save()
        
        ## create new project tables based on the project involved in the run and 
        ## include the project information in projects variable to build the new FORM
        #import pdb; pdb.set_trace()
        for key, val  in project_list.items():
            userid=User.objects.get(username__exact = val)
            p_data=Projects(runprocess_id=RunProcess.objects.get(runName =run_name), projectName=key, user_id=userid)
            p_data.save()
            projects.append([key, val])
        projects.append(['runname', request.POST['runname']])
        ## displays the list of projects and the user names found on Sample Sheet
        return render(request, 'wetlab/getSampleSheet.html', {'get_user_names': projects })
        
    elif request.method=='POST' and (request.POST['action']=='displayResult'):
        projects=request.POST.getlist('project')
        user_name=request.POST.getlist('username')
        library_kit=request.POST.getlist('librarykit')
        run_name= request.POST['runname']
        ## get the sample sheet used in the run
        
        run_p = RunProcess.objects.get(runName__exact = run_name)
        s_file=run_p.get_sample_file()
        ## get the different type of library kit used in the run and 
        ## convert the sample sheet into Base Space. Number of converted 
        ## file will be the same as the number of different lybraries use in the run
        library={}
        bs_file={}
        results=[]
        
        #import pdb; pdb.set_trace() 
        in_file=str('documents/' + s_file)
        #import pdb; pdb.set_trace()
        ## build the project list for each library kit 
        for x in range(len(library_kit)):
            if library_kit[x] in library :
                library[library_kit[x]].append(projects[x])
            else:
                library[library_kit[x]]= [projects[x]]
        ## convert the sample sheet to base space format and have different files according the library kit
        #import pdb; pdb.set_trace()
        for key, value in library.items():
            bs_file[key]=sample_sheet_map_basespace(in_file, key, value)
            results.append([key, bs_file[key]]) 
            
        ## save the project information on database
         
        for p in range(len( projects)):
            my_project = projects [p]
            my_name = user_name[p]
            my_libkit = library_kit[p]
            update_info_proj=Projects.objects.get(projectName = my_project)
            update_info_proj.libraryKit=my_libkit
            update_info_proj.baseSpaceFile=bs_file[my_libkit]
            update_info_proj.proState='Recorded'
            update_info_proj.save()
        #import pdb; pdb.set_trace()
        results.append(['runname', run_name])
        
        #import pdb; pdb.set_trace()
        ## save the sample sheet file under tmp/recorded to be processed when run folder was created
        subfolder_name=str(run_p.id)
        #import pdb; pdb.set_trace()
        os.mkdir(os.path.join('documents/wetlab/tmp/recorded', subfolder_name ))
        sample_sheet_copy= os.path.join('documents/wetlab/tmp/recorded', subfolder_name, 'samplesheet.csv' )
        shutil.copy(in_file,sample_sheet_copy)
        ## update the state of the run to 'Recorded'
        run_p.runState='Recorded'
        run_p.save()
        ## update the project state to Recorded
        project_to_be_updated = Projects.objects.filter(runprocess_id__exact = run_p.id)
        for project in project_to_be_updated :
            project.procState='Recorded'
            project.save()
            
        return render (request, 'wetlab/getSampleSheet.html', {'completed_form':results})
    

    return render(request, 'wetlab/getSampleSheet.html')

def get_information_run(run_name_found,run_id):
    info_dict={}
    ## collect the state to get the valid information of run that matches the run name 
    run_state=run_name_found.get_state()
    if (run_state != 'Completed'):
        d_list=['Run name','State of the Run is','Run was requested by',
                'The Sample Sheet used is','Run was recorded on date']
    else:
        d_list=['Run name','State of the Run is','Run was requested by',
                'Disk space used for Images','Disk space used for Fasta Files',
                'Disk space used for other Files','Run recorded date'] 
    run_info_data=run_name_found.get_info_process().split(';')
    r_data_display=[] 
    for i in range (len (d_list)):
        r_data_display.append([d_list[i],run_info_data[i]])
    info_dict['data']=r_data_display
    info_dict['run_state'] = run_state
    if (run_state == 'Recorded'):
        info_dict['graphic_value']=25
        info_dict['graphic_color']= 'violet'
    if (run_state == 'Sample Sent'):
        info_dict['graphic_value']=40
        info_dict['graphic_color']= 'pink'
    if (run_state == 'Process Running'):
        info_dict['graphic_value']=50
        info_dict['graphic_color']= 'brown'
    if (run_state == 'Bcl2Fastq Executed'):
        info_dict['graphic_value']=60
        info_dict['graphic_color']= 'orange'
    if (run_state == 'Running Stats'):
        info_dict['graphic_value']=75
        info_dict['graphic_color']= 'yellow'
    if (run_state == 'Completed'):
        info_dict['graphic_value']=100
        info_dict['graphic_color']= 'green'
        # finding the running parameters index for the run
        runName_id=RunningParameters.objects.get(pk=run_id)
        # Adding the Run Parameters information
        rp_list=['Run ID','Experiment Name ','RTA version ','System Suite Version','Library ID ','Chemistry','Run Start Date', 'Analysis Work Flow Type','Run Management Type','Planned Read1 Cycles',
                'Planned Read2 Cycles','Planned Index1 Read Cycles','Planned Index2 Read Cycles','Application Version','Num Tiles per Swatch','Image Channel',
                'Flowcel','Image Dimensions', 'Flowcell Layout']
        rp_data=runName_id.get_run_parameters_info().split(';')
        r_rp_display=[]
        for i in range (len(rp_list)):
            if i == 'Image Channel':
                img_data_list=rp_data[i].split(',')
                r_rp_display.append([rp_list[i],[img_data_list]])
            else:
                r_rp_display.append([rp_list[i], rp_data[i]])
        info_dict['parameters']=r_rp_display
        ### BaseSpaceFile.objects.get(pk=Document.objects.get(run_name=run_name_value).id)
    
    p_list= Projects.objects.filter(runprocess_id=run_id)
    if p_list !='':
        #import pdb; pdb.set_trace()
        p_data_list=[]
        for p in range (len(p_list)):
            p_data_list.append([p_list[p].projectName,p_list[p].id])
        info_dict['projects']=p_data_list
    #import pdb; pdb.set_trace()
    ## get the stats information if run is completed
    if run_state == 'Completed':
        fl_data_display=[]
        #import pdb; pdb.set_trace()
        fl_summary_id = NextSeqStatsFlSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='all')
        fl_list = ['Cluster (Raw)', 'Cluster (PF)', 'Yield (MBases)', 'Number of Samples']
        fl_data_display.append(fl_list)
        fl_values = fl_summary_id[0].get_fl_summary().split(';')
        fl_data_display.append(fl_values)
        info_dict['fl_summary']=fl_data_display
        
        # prepare the data for Lane Summary
        lane_data_display = []
        lane_summary_id = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='all')
        lane_list = ['Lane', 'PF Clusters', '% of the lane','% Perfect barcode',
                    '% One mismatch barcode','Yield (Mbases)','% >= Q30 bases',
                    'Mean Quality Score']
        lane_data_display.append(lane_list)
        for lane_sum in lane_summary_id:
            lane_values = lane_sum.get_lane_summary().split(';')
            lane_data_display.append(lane_values)
        info_dict['lane_summary'] = lane_data_display
        
        # prepare the data for default Flowcell summary
        default_fl_data_display=[]
        #import pdb; pdb.set_trace()
        default_fl_summary_id = NextSeqStatsFlSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='default')
        default_fl_data_display.append(fl_list)
        default_fl_values = default_fl_summary_id[0].get_fl_summary().split(';')
        default_fl_data_display.append(default_fl_values)
        info_dict['default_fl_summary']=default_fl_data_display
        
        # prepare the data for default Lane Summary
        default_lane_data_display = []
        default_lane_summary_id = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='default')
        default_lane_data_display.append(lane_list)
        for default_lane_sum in default_lane_summary_id:
            default_lane_values = default_lane_sum.get_lane_summary().split(';')
            default_lane_data_display.append(default_lane_values)
        info_dict['default_lane_summary'] = default_lane_data_display
        
        # prepare the data for top unknown barcode
        unknow_dict = {}
        for lane_un in range (4):
            lane_unknow_barcode = [] 
            lane_number=str(lane_un +1)
            
            unknow_bar_id = RawTopUnknowBarcodes.objects.filter(runprocess_id__exact =run_id , lane_number__exact = lane_number)
            #import pdb; pdb.set_trace()
            for item_id in unknow_bar_id:
                #import pdb; pdb.set_trace()
                unknow_values = item_id.get_unknow_barcodes().split(';')
                lane_unknow_barcode.append(unknow_values)
                unknow_bar_value = int(unknow_values[0].replace(',',''))
                if unknow_values[1] in unknow_dict:
                    unknow_dict [unknow_values[1]] += unknow_bar_value
                else:
                    unknow_dict [unknow_values[1]] = unknow_bar_value
                
            lane_number=str('unknow_bar_'+ str(lane_un))
            info_dict[lane_number] = lane_unknow_barcode
            #import pdb; pdb.set_trace()    
            # keep the top 10 unknow bar by deleting the lowest values
            unknow_dict_len = len (unknow_dict) 
            if unknow_dict_len> 10:
                while (len (unknow_dict_len) > 10):
                    min_val = min(unknow_dict, key=unknow_dict.get)
                    del unknow_dict [min_val]
        # create chart with the top unknown barcode in the run
        #import pdb; pdb.set_trace()
        data_source = json_unknow_barcode_graphic('Unknow Sequence', list(unknow_dict.keys()),list(unknow_dict.values()))
        unknow_pie3d = FusionCharts("pie3d", "ex1" , "600", "400", "chart-1", "json", data_source)
        #import pdb; pdb.set_trace()
        
        info_dict ['unknow_pie3d'] = unknow_pie3d.render() 
        
        # prepare the data for Run Binary summary stats
        index_run_summary = ['1','2','3','4', 'Non Index', 'Total']
        info_dict ['runSummaryHeading']= ['Level','Yield','Projected Yield','Aligned (%)','Error Rate (%)','Intensity Cycle 1','Quality >=30 (%)']
        line_description=['Read 1','Read 2','Read 3','Read 4','Non Index','Totals']
        line_run_summary = []
        for index in range (len(index_run_summary)):
            #import pdb; pdb.set_trace()
            run_summary_id = NextSeqStatsBinRunSummary.objects.filter(runprocess_id__exact =run_id , level__exact = index_run_summary[index])
            run_summary_values = run_summary_id[0].get_bin_run_summary().split(';')
            run_summary_values.insert(0, line_description[index])
            if index_run_summary[index] == 'Total':
                info_dict ['runSummaryTotal'] = run_summary_values
            else:
                line_run_summary.append(run_summary_values)
        #import pdb; pdb.set_trace()
        info_dict ['runSummary'] = line_run_summary

        # prepare the data for Reads Binary summary stats
        info_dict ['laneSummaryHeading']= ['Lane','Tiles','Density (K/mm2)','Cluster PF (%)','Phas/Prephas (%)',
                    'Reads (M)','Reads PF (M)','%>= Q30','Tield (G)','Cycles Err Rate',
                    'Aligned (%)','Error Rate (%)','Error Rate 35 cycle (%)',
                    'Error Rate 50 cycle (%)','Error Rate 75 cycle (%)',
                    'Error Rate 100 cycle (%)','Intensity Cycle 1']
        for read_number in range (1, 5):
            read_summary_values=[]
            for lane_number in range(1, 5):
                read_lane_id= NextSeqStatsBinRunRead.objects.filter(runprocess_id__exact =run_id, read__exact = read_number, lane__exact = lane_number)
                lane_values=read_lane_id[0].get_bin_run_read().split(';')
                read_summary_values.append(lane_values)
            read_number_index = str('laneSummary'+str(read_number))
            info_dict[read_number_index] = read_summary_values
        
        # prepare the graphics for the run
        folder_for_plot='/wetlab/documents/wetlab/images_plot/'

        run_graphics_id = NextSeqGraphicsStats.objects.filter(runprocess_id__exact =run_id)
        folder_graphic = folder_for_plot + run_graphics_id[0].get_folder_graphic()+ '/'
        graphics = run_graphics_id[0].get_graphics().split(';')
        graphic_text= ['Data By Lane','Flow Cell Chart','Data By Cycle','QScore Heatmap','QScore Distribution','Indexing QC']
        for index_graph in range (len(graphics)):
            tmp_value = graphics[index_graph]
            graphics[index_graph] = [graphic_text[index_graph], folder_graphic + tmp_value]
            
        info_dict['runGraphic'] = graphics
  
    return info_dict
    


def search_nextSeq (request):
    #############################################################
    ## Search for runs that fullfil the input values 
    #############################################################
    if request.method=='POST' and (request.POST['action']=='runsearch'):
        run_name=request.POST['runname']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        run_state=request.POST['runstate']
        # check that some values are in the request if not return the form
        if run_name == '' and start_date == '' and end_date == '' and run_state == '':
            return render(request, 'wetlab/SearchNextSeq.html')
            
        ### check the right format of start and end date
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})    
        ### Get runs when run name is not empty 
        if run_name !='':
            if (RunProcess.objects.filter(runName__exact =run_name).exists()):
                run_name_found=RunProcess.objects.filter(runName__exact =run_name)
                if (len(run_name_found)>1):
                    return render (request,'wetlab/error_page.html', {'content':['Too many matches found when searching for the run name ', run_name ,
                                                                    'ADVICE:', 'Select additional filter to find the run that you are looking for']})
                r_data_display= get_information_run(run_name_found[0],run_name_found[0].id)
                #import pdb; pdb.set_trace()
                return render(request, 'wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
            if (RunProcess.objects.filter(runName__contains =run_name).exists()):
                runs_found=RunProcess.objects.filter(runName__contains =run_name)
            else:
                return render (request,'wetlab/error_page.html', {'content':['No matches have been found for the run name ', run_name ,
                                                                    'ADVICE:', 'Select the Fuzzy search button to get the match']})
        if run_state != '':
            runs_found=RunProcess.objects.all()
        
        ### Check if state is not empty
        if run_state != '':
            if runs_found.filter(runState__exact = run_state).exists():
                runs_found = runs_found.filter(runState__exact = run_state)
            else :
                return render (request,'wetlab/error_page.html', {'content':['No matches have been found for the run name ', run_name ,
                                                                    'and the state', run_state ]})
        ### Check if start_date is not empty
        if start_date !='' and end_date != '':
            
            if runs_found.filter(generatedat__range=(start_date, end_date)).exists():
                 runs_found = runs_found.filter(generatedat__range=(start_date, end_date))
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no runs containing ', run_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if runs_found.filter(generatedat__gte = start_date).exists():
                 runs_found = runs_found.filter(generatedat__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', run_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if runs_found.filter(generatedat__lte = end_date).exists():
                 runs_found = runs_found.filter(generatedat__lte = end_date)
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', run_name,
                                        ' finish before ', end_date]})
        #If only 1 run mathes the user conditions, then get the project information    
        
        if (len(runs_found)== 1) :
            r_data_display= get_information_run(runs_found[0],runs_found[0].id)
            #import pdb; pdb.set_trace()
            return render(request, 'wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
        else:            
            ## collect the list of run that matches the run date 
            run_list=[]
            for i in range(len(runs_found)):
                run_list.append([runs_found[i],runs_found[i].id])
                #import pdb; pdb.set_trace()    
            return render(request, 'wetlab/SearchNextSeq.html', {'display_run_list': run_list })
    else:
    #import pdb; pdb.set_trace()
        return render(request, 'wetlab/SearchNextSeq.html')        

def search_nextProject (request):
    ############################################################# 
    ###  Find the projects that match the input values
    ############################################################# 
    
    if request.method=='POST' and (request.POST['action']=='searchproject'):
        project_name=request.POST['projectname']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        project_state=request.POST['projectstate']
        user_name = request.POST['username']
        # check that some values are in the request if not return the form
        if project_name == '' and start_date == '' and end_date == '' and user_name =='' and project_state == '':
            return render(request, 'wetlab/NextSearchProject.html')
        if user_name !=''  and len(user_name) <5 :
             return render (request,'wetlab/error_page.html', {'content':['The user name must contains at least 5 caracters ', 
                                                                    'ADVICE:', 'write the full user name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})    
        ### Get projects when project name is not empty 
        if project_name != '' :
            
            if Projects.objects.filter(projectName__exact = project_name).exists():
                project_id = Projects.objects.get (projectName__exact = project_name).id
                project_found_id = Projects.objects.get(pk=project_id)
                p_data_display  = get_information_project(project_found_id)
                return render(request, 'wetlab/projectInfo.html', {'display_one_project': p_data_display })
            if  Projects.objects.filter (projectName__contains = project_name).exists():
                #import pdb; pdb.set_trace()
                projects_found = Projects.objects.filter (projectName__contains = project_name)
            else:
                return render (request,'wetlab/error_page.html', {'content':['No Project found with the string , ', project_name ]})
        ### if there is no project name, then get all which will be filtered by other conditions set by user
        #import pdb; pdb.set_trace()
        if project_name == '':
            projects_found = Projects.objects.all()
                # check if user name is not empty
        if user_name != '':
            if User.objects.filter(username__icontains = user_name).exists():
                r_name_id = User.objects.get(username__icontains = user_name).id
                if projects_found.filter(user_id__exact =r_name_id).exists():
                    projects_found = projects_found.filter(user_id__exact =r_name_id)
                else:
                     return render (request,'wetlab/error_page.html', {'content':['The Project found does not belong to the user, ', user_name ]})
            else:
                return render (request,'wetlab/error_page.html', {'content':['The Project found does not belong to the user, ', user_name ]})

                    # check if the date in the form match in project database
        if (project_state !='' ):
            if projects_found.filter(procState__exact = project_state):
                projects_found = projects_found.filter(procState__exact = project_state)
            else :
                return render (request,'wetlab/error_page.html', {'content':['There ane not Projects containing ', project_name, 
                                               'in state', project_state ]})
        if start_date !='' and end_date != '':
            
            if projects_found.filter(generatedat__range=(start_date, end_date)).exists():
                 projects_found = projects_found.filter(generatedat__range=(start_date, end_date))
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if projects_found.filter(generatedat__gte = start_date).exists():
                 projects_found = projects_found.filter(generatedat__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if projects_found.filter(generatedat__lte = end_date).exists():
                 projects_found = projects_found.filter(generatedat__lte = end_date)
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' finish before ', end_date]})
        #If only 1 project mathes the user conditions, then get the project information
        
        if len (projects_found) == 1:
            project_id = projects_found[0].id
            project_found_id = Projects.objects.get(pk=project_id)
            p_data_display  = get_information_project(project_found_id)
            return render(request, 'wetlab/NextSearchProject.html', {'display_one_project': p_data_display })
        else :
            # Display a list with all projects that matches the conditions
            project_list_dict = {}
            project_list = []
            for project in projects_found :
                p_name = project.get_project_name()
                p_name_id = project.id
                project_list.append([p_name, p_name_id])
            project_list_dict ['projects'] = project_list
            return render(request, 'wetlab/NextSearchProject.html', {'display_project_list': project_list_dict })


    else:
    #import pdb; pdb.set_trace()
        return render(request, 'wetlab/NextSearchProject.html')


def search_nextSample (request):
    ############################################################# 
    ###  Find the projects that match the input values
    ############################################################# 
    
    if request.method=='POST' and (request.POST['action']=='searchsample'):
        sample_name=request.POST['samplename']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']    
        user_name = request.POST['username']
        # check that some values are in the request if not return the form
        if user_name == '' and start_date == '' and end_date == '' and user_name =='':
            return render(request, 'wetlab/SearchNextSample.html')
        
        if user_name !=''  and len(user_name) <5 :
             return render (request,'wetlab/error_page.html', {'content':['The user name must contains at least 5 caracters ', 
                                                                    'ADVICE:', 'write the full user name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})    
        ### Get projects when project name is not empty 
        if sample_name != '' :
            if SamplesInProject.objects.filter(sampleName__exact = sample_name).exists():
                sample_found = SamplesInProject.objects.filter(sampleName__exact = sample_name)
                if len(sample_found) == 1:
                    # display sample 
                    return render(request, 'wetlab/SearchNextSample.html')
                else:
                    pass
            if SamplesInProject.objects.filter(sampleName__contains = sample_name).exists():
                sample_found = SamplesInProject.objects.filter(sampleName__exact = sample_name)
            else:
                return render (request,'wetlab/error_page.html', {'content':['No sample found with the string , ', sample_name ]})
            
        ### if there is no project name, then get all which will be filtered by other conditions set by user
        #import pdb; pdb.set_trace()
        if sample_name == '':
            sample_found = SamplesInProject.objects.all()
        # Check the start and end date
        if start_date !='' and end_date != '':
            
            if sample_found.filter(generatedat__range=(start_date, end_date)).exists():
                 sample_found = projects_found.filter(generatedat__range=(start_date, end_date))
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if sample_found.filter(generatedat__gte = start_date).exists():
                 sample_found = projects_found.filter(generatedat__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if sample_found.filter(generatedat__lte = end_date).exists():
                 sample_found = projects_found.filter(generatedat__lte = end_date)
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' finish before ', end_date]})
                # check if user name is not empty
        if user_name != '':
            
            if User.objects.filter(username__icontains = user_name).exists():
                users = User.objects.filter (username__icontains = user_name)
                if len(users) == 1:
                    user_id= users[0].id
                    
                    project_id_list = Projects.objects.prefetch_related('user_id').filter(user_id = user_id)
                    if len(project_id_list) == 1:
                        project_id_list[0].id
                        #import pdb; pdb.set_trace()
                        if sample_found.filter(project_id = project_id_list[0]).exists():
                            sample_found = sample_found.filter(project_id = project_id_list[0])
                            
                        else:
                            text_error = 'User ' + user_name +' does not have yet any samples'
                            return render (request,'wetlab/error_page.html', {'content':[text_error, 
                                        'ADVICE:', 'Contact with your administrator' ]})
                    else:
                        sample_found = sample_found.filter(project_id__in = project_id_list) 
                            
                else:
                    text_error= 'There are too many users names containing ' + sample_name  + '  which match your query'
                    return render (request,'wetlab/error_page.html', {'content':[text_error, 
                                        'ADVICE:', 'Fill in the user name field the full name of the user' ]})
                        
                #r_name_id = User.objects.get(username__icontains = user_name).id

            else:
                return render (request,'wetlab/error_page.html', {'content':['The samples found did not belong to the user, ', user_name ]})
            
        
        if len(project_id_list) == 1:
            
            # get the project  name for the match 
            #import pdb; pdb.set_trace()
            project_name = Projects.objects.get(pk = project_id_list[0].id).get_project_name()
            
            sample_found_count = sample_found.count()
            if sample_found_count == 1:
                sample_data_information = get_sample_information (sample_found.id)
                return render(request, 'wetlab/SearchNextSample.html',{'display_one_sample': sample_data_information })

            elif sample_found_count < 20 :
                multiple_samples ={}
                multiple_samples['project_name'] = project_name
                samples_list_in_project =[]
                #import pdb; pdb.set_trace()
                for sample_item in sample_found :
                    sample_name = sample_item.get_sample_name()
                    sample_id = sample_item.id
                    samples_list_in_project.append([sample_name, sample_id])
                multiple_samples['samples'] = samples_list_in_project
                return render(request, 'wetlab/SearchNextSample.html',{'multiple_sample_one_project': multiple_samples })
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are too many samples that match your query',
                            'ADVICE:', 'Include more caracters in the Sample Name field']})
        return render(request, 'wetlab/SearchNextSample.html')           
    
    else:
    #import pdb; pdb.set_trace()
        return render(request, 'wetlab/SearchNextSample.html')
    




def search_run (request, run_id):
    #import pdb; pdb.set_trace()
    if (RunProcess.objects.filter(pk=run_id).exists()):
        run_name_found = RunProcess.objects.filter(pk=run_id)
        r_data_display  = get_information_run(run_name_found[0],run_id)
        return render(request, 'wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
    else:
        return render (request,'wetlab/error_page.html', {'content':['No matches have been found for the run  ', 
                                                                             'ADVICE:', 'Select the Fuzzy search button to get the match']})
                                                                             
def latest_run (request) :
    latest_run = RunProcess.objects.order_by('id').last()
    #import pdb; pdb.set_trace()
    run_id = latest_run.id
    r_data_display  = get_information_run(latest_run,run_id)
    return render(request, 'wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })

def get_information_project (project_id):
    project_info_dict = {}
    p_data = []
    project_info_text = ['Project Name','Library Kit','File to upload to BaseSpace']
    project_values = project_id.get_project_info().split(';')
    for item in range(len(project_info_text)):
        p_data.append([project_info_text[item], project_values[item]])
    project_info_dict['p_data'] = p_data
    #import pdb; pdb.set_trace()
    project_info_dict ['user_name'] = project_id.get_user_name()
    p_state = project_id.get_state()
    project_info_dict['state'] = p_state
    if p_state == 'Recorded':
        project_info_dict['graphic_value']=25
        project_info_dict['graphic_color']='violet'
    if p_state == 'Sample Sent':
        project_info_dict['graphic_value']= 50
        project_info_dict['graphic_color']='brown'
    if p_state == 'B2FqExecuted':
        project_info_dict['graphic_value']= 75
        project_info_dict['graphic_color']='yelllow'
    if p_state == 'Completed':
        project_info_dict['graphic_value']= 100
        project_info_dict['graphic_color']='green'
        fl_data_display=[]
        #import pdb; pdb.set_trace()
        # prepare the data for Flowcell Summary
        fl_summary_id = NextSeqStatsFlSummary.objects.get(project_id__exact = project_id)
        fl_list = ['Cluster (Raw)', 'Cluster (PF)', 'Yield (MBases)', 'Number of Samples']
        fl_data_display.append(fl_list)
        fl_values = fl_summary_id.get_fl_summary().split(';')
        fl_data_display.append(fl_values)
        project_info_dict['fl_summary']=fl_data_display
        
        # prepare the data for Lane Summary
        lane_data_display = []
        lane_summary_id = NextSeqStatsLaneSummary.objects.filter(project_id__exact = project_id)
        lane_list = ['Lane', 'PF Clusters', '% of the lane','% Perfect barcode',
                    '% One mismatch barcode','Yield (Mbases)','% >= Q30 bases',
                    'Mean Quality Score']
        lane_data_display.append(lane_list)
        for lane_sum in lane_summary_id:
            lane_values = lane_sum.get_lane_summary().split(';')
            lane_data_display.append(lane_values)
        project_info_dict['lane_summary'] = lane_data_display
        
        # prepare the data for sample information
        
        sample_found_list = SamplesInProject.objects.filter(project_id__exact = project_id)
        sample_heading_list = ['Sample','Barcode','PF Clusters','Percent of Project', 'Yield (Mbases)','% >= Q30 bases', 'Mean Quality Score']
        project_info_dict['sample_heading'] = sample_heading_list
        sample_list =[]
        for sample_item in range(len(sample_found_list)) :
            sample_line = sample_found_list[sample_item].get_sample_information().split(';')
            sample_list.append(sample_line)
        #import pdb; pdb.set_trace()
        project_info_dict['sample_table'] = sample_list
    return project_info_dict

def get_sample_information (sample_id):
    sample_info_dict ={}
    data_surce= {}
    heading = 'Graphic for quality Sample'
    table_heading = ['Sample Name', 'Barcode Sequence', 'PF Clusters','% in Project','Yield (MB)','% >= Q30 bases','Mean Quality Score']
    #import pdb; pdb.set_trace()
    table_values = SamplesInProject.objects.get (pk = sample_id).get_sample_information().split(';') 
    sample_info_dict ['table_heading'] = table_heading
    sample_info_dict ['table_values'] = table_values
    data_source = graphic_for_quality_angular(heading, 80)
    quality_sample_angular = FusionCharts("angulargauge", "ex1" , "250", "200", "chart-1", "json", data_source)
    sample_info_dict['quality_chart1'] = quality_sample_angular.render()
    #import pdb; pdb.set_trace()
    project_name = SamplesInProject.objects.get (pk = sample_id).get_project_name()
    sample_info_dict ['project_name'] = project_name
    
    return sample_info_dict


def search_project (request, project_id):
    
    if (Projects.objects.filter(pk=project_id).exists()):
        project_found_id = Projects.objects.get(pk=project_id)
        p_data_display  = get_information_project(project_found_id)
        return render(request, 'wetlab/NextSearchProject.html', {'display_one_project': p_data_display })
    else:
        return render (request,'wetlab/error_page.html', {'content':['No matches have been found for the project  ' ]})


def search_sample (request, sample_id):
    
    if (SamplesInProject.objects.filter(pk=sample_id).exists()):
        #sample_found_id = SamplesInProject.objects.get(pk=sample_id)
        sample_data_display  = get_sample_information (sample_id)
        return render(request, 'wetlab/SearchNextSample.html', {'display_one_sample': sample_data_display })
    else:
        return render (request,'wetlab/error_page.html', {'content':['No matches have been found for the sample ' ]})
    
def next_seq_statistics (request):
    return render (request, 'wetlab/NextSeqStatistics.html', {})

def nextSeqStats_per_researcher (request):
    if request.method == 'POST':
        
        #import pdb; pdb.set_trace()
        r_name = request.POST['researchername']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "From Start Date" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date !='' :
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if len(r_name) < 5 :
            return render (request,'wetlab/error_page.html', {'content':['researcher name is too sort fo fined a match', 'Name must be at least 6 characters long' 
                                                            'ADVICE:', 'write a longer name in the researcher field ']})

        if User.objects.filter(username__icontains = r_name).exists():
            r_name_id = User.objects.get(username__icontains = r_name).id
            if Projects.objects.filter(user_id__exact =r_name_id).exists():
                if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed").exists():
                    r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed")
               
                # check if start and end date are present in the form
                    if start_date != '' and end_date !='':
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__range=(start_date, end_date)).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__range=(start_date, end_date))
                            #r_project_by_researcher = r_project_by_researcher.filter(generatedat__range=(start_date, end_date))
                        else:
                            return render (request,'wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'starting date  = ', start_date, 'and with ending date = ', end_date,
                                                                'ADVICE:', 'Contact with your administrator']})
                    if start_date != '' and end_date =='':
                        end_date = str(datetime.datetime.now().date())
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__range=(start_date, end_date)).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__range=(start_date, end_date))
                        else:
                            return render (request,'wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'starting date  = ', start_date, 
                                                                'ADVICE:', 'Contact with your administrator']})    
                    if start_date == '' and end_date !='':
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__lte= end_date).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", generatedat__lte = end_date)
                        else:
                            return render (request,'wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'ending date  = ', end_date, 
                                                                'ADVICE:', 'Contact with your administrator']})   
                    

                    if len (r_project_by_researcher) ==1:
                        # get researcher_project id
                        researcher_project_id = Projects.objects.get(user_id__exact =r_name_id).id
                        project_name = r_project_by_researcher[0].get_project_name()
                        user_name = r_project_by_researcher[0].get_user_name()
                        #import pdb; pdb.set_trace()
                        # fetch percent of Q>30 and mean_q for all projects per lane to create the median
                        # to be compared with the percent of this project
                        q_30_media, mean_q_media = [] , []
                        for lane in range (1,5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane).exclude(defaultAll__isnull = False).exclude (project_id__exact = researcher_project_id)
                            q_30_list , mean_q_list = [] , []
                            #import pdb; pdb.set_trace()
                            for item_lane in found_lane:
                                #import pdb; pdb.set_trace()
                                q_30_value, mean_q_value , yield_mb = item_lane.get_stats_info().split(';')
                                q_30_list.append(float(q_30_value))
                                mean_q_list.append(float(mean_q_value))
                            #import pdb; pdb.set_trace()
                            
                            q_30_media_lane = format(statistics.mean (q_30_list), '.2f')
                            mean_q_media_lane = format(statistics.mean (mean_q_list), '.2f')
                            q_30_media.append(q_30_media_lane)
                            mean_q_media.append(mean_q_media_lane)
                        
                        # fetch the Q>30 and mean_q for the researcher project per lane 
                        q_30_project_lane, mean_q_project_lane = [] , []
                        for lane in range (1, 5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane , project_id__exact = researcher_project_id )
                            #import pdb; pdb.set_trace()
                            q_30_value, mean_q_value , yield_mb = found_lane[0].get_stats_info().split(';')
                            q_30_project_lane.append(float(q_30_value))
                            mean_q_project_lane.append(float(mean_q_value))
                                                        
                        #import pdb; pdb.set_trace()
                        
                        data_source = json_2_column_graphic('Comparison of bases with Q value bigger than 30', q_30_project_lane,q_30_media)
                        q_30_mscol2D = FusionCharts("mscolumn3d", "ex1" , "600", "400", "chart-1", "json", data_source)
                        
                        data_source = json_2_column_graphic('Comparison of mean Quality Score', mean_q_project_lane,mean_q_media)
                        mean_q_mscol2D = FusionCharts("mscolumn3d", "ex2" , "600", "400", "chart-2", "json", data_source)
                        #import pdb; pdb.set_trace()
                        project_chart ={}
                        project_chart ['project_name'] = project_name
                        project_chart ['user_name'] = user_name
                        project_chart ['q_30_chart'] = q_30_mscol2D.render()
                        project_chart ['mean_q_chart'] = mean_q_mscol2D.render() 
                        #import pdb; pdb.set_trace()
                        # returning complete JavaScript and HTML code, which is used to generate chart in the browsers. 
                        return  render(request, 'wetlab/NextSeqStatsPerResearcher.html', {'researcher_one_project' : project_chart})
                        
                    else:
                        project_names = []
                        lane_in_project =[[]]
                        
                        # fetch percent of Q>30 and mean_q for all projects per lane to create the median
                        # to be compared with the percent of this project
                        q_30_media, mean_q_media = [] , []
                        for lane in range (1,5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane).exclude(defaultAll__isnull = False)
                            q_30_list , mean_q_list = [] , []
                            #import pdb; pdb.set_trace()
                            for item_lane in found_lane:
                                #import pdb; pdb.set_trace()
                                q_30_value, mean_q_value , yield_mb = item_lane.get_stats_info().split(';')
                                q_30_list.append(float(q_30_value))
                                mean_q_list.append(float(mean_q_value))
                            #import pdb; pdb.set_trace()
                            
                            q_30_media_lane = format(statistics.mean (q_30_list),'.2f')
                            mean_q_media_lane = format(statistics.mean (mean_q_list), '.2f')
                            q_30_media.append(q_30_media_lane)
                            mean_q_media.append(mean_q_media_lane)

                        # fetch the Q>30 and mean_q for the researcher projects per lane
                        r_project_id =r_project.id
                        
                        q_30_researcher_media , mean_q_researcher_media = [] , []
                        for lane in range (1,5):
                            q_30_list , mean_q_list = [] , []
                            for r_project in r_project_by_researcher:
                                project_names.append(r_project__str__)
                                project_researcher_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane, project_id__exact = r_project_id).exclude(defaultAll__isnull = False)
                                q_30_value, mean_q_value, yield_mb = project_researcher_lane[0].get_stats_info().split(';')
                                q_30_list.append(float(q_30_value))
                                mean_q_list.append(float(mean_q_value))
                                #import pdb; pdb.set_trace()
                            
                            q_30_media_lane = statistics.mean (q_30_list)
                            mean_q_media_lane = statistics.mean (mean_q_list)
                            q_30_researcher_media.append(q_30_media_lane)
                            mean_q_researcher_media.append(mean_q_media_lane)
                        
                        data_source = json_2_column_graphic('Comparison of bases with Q value bigger than 30', q_30_researcher_media , q_30_media)
                        q_30_mscol2D = FusionCharts("mscolumn3d", "ex1" , "600", "400", "chart-1", "json", data_source)
                        
                        data_source = json_2_column_graphic('Comparison of mean Quality Score', mean_q_researcher_media , mean_q_media)
                        mean_q_mscol2D = FusionCharts("mscolumn3d", "ex2" , "600", "400", "chart-2", "json", data_source)
                        #import pdb; pdb.set_trace()
                        project_chart ={}
                        project_chart ['project_names'] = project_names
                        project_chart ['q_30_chart'] = q_30_mscol2D.render()
                        project_chart ['mean_q_chart'] = mean_q_mscol2D.render() 
                        #import pdb; pdb.set_trace()
                        # returning complete JavaScript and HTML code, which is used to generate chart in the browsers. 
                        return  render(request, 'wetlab/NextSeqStatsPerResearcher.html', {'researcher_one_project' : project_chart})         
                           
                else:
                    #import pdb; pdb.set_trace()
                    return render (request,'wetlab/error_page.html', {'content':['Researcher does not have projects in Completed state. ', 
                                                            'ADVICE:', 'Contact with your administrator']})
            else:
                return render (request,'wetlab/error_page.html', {'content':['Researcher does not have projects associated to him ', 
                                                            'ADVICE:', 'Contact with your administrator']})
        else:
            return render (request,'wetlab/error_page.html', {'content':['No matches have been found for researcher name  ', 
                                                                'ADVICE:', 'Contact with your administrator']})
    else:
        return render (request, 'wetlab/NextSeqStatsPerResearcher.html', {})



def nextSeqStats_per_time (request):
    if request.method=='POST':
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
         ### check the right format of start and end date
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})    

        #############################################################
        #### searching for runs were match the state and start and end date
        #############################################################
        if (start_date != '' and end_date != ''):
            stat_per_time ={}
            if (RunProcess.objects.filter( runState='Completed', generatedat__range=(start_date, end_date)).exists()):
                run_stats_list=RunProcess.objects.filter(runState='Completed', generatedat__range=(start_date, end_date))
                #import pdb; pdb.set_trace()
                
                run_list=[]
                ## get the run names that matches de conditions
                for run in run_stats_list:
                        run_list.append([run.get_run_name(),run.id])
                    #import pdb; pdb.set_trace()
                stat_per_time ['run_names'] = run_list
                if len (run_stats_list) == 1:
                    number_of_runs = '1 Run'
                else:
                    number_of_runs = len (run_stats_list) + '  Runs'
                stat_per_time ['number_of_runs'] = number_of_runs
                stat_per_time ['dates'] = start_date + ' and  ' + end_date
                #import pdb; pdb.set_trace()
                #############################################################
                ### collect statistics for unkow Barcodes
                top_unbarcode_list = []
                top_count_sequence  = {}
                for lane_number in range (1,5):
                    top_unbarcode_dict_lane  = {} 
                    for run in run_stats_list:
                        run_id = run.id
                        top_unbarcode = RawTopUnknowBarcodes.objects.filter(runprocess_id__exact =run_id, lane_number__exact = lane_number, top_number__exact = 1)
                        count ,sequence  = top_unbarcode[0].get_unknow_barcodes().split(';')
                        count_float = float(count.replace(',',''))
                        #import pdb; pdb.set_trace()
                        ## Count the number of times that the sequence is found per project and lane 
                        if sequence in top_unbarcode_dict_lane :
                            top_unbarcode_dict_lane [sequence] += 1
                        else:
                            top_unbarcode_dict_lane [sequence] =1
                        
                        if sequence in top_count_sequence :
                            top_count_sequence [sequence] += count_float
                        else:
                            top_count_sequence [sequence]= count_float
                            
                    top_unbarcode_list.append(top_unbarcode_dict_lane)
                    
                l_count = 1
                themes = ['', 'ocean','fint','carbon','zune']
                # prepare the column graphic for nunber of top Unknow Barcode
                for lane_unbarcode in top_unbarcode_list:
                    heading = 'Number of undetermined barcode sequence in lane ' + str(l_count)
                    data_source = graphic_for_top_unbarcodes(heading , themes[l_count] , lane_unbarcode)
         
                    chart_number = 'chart-' + str(l_count)
                    render_number = 'ex'+ str(l_count)
                    lane_chart = 'lane_chart'+ str(l_count)
                    lane_graphic = FusionCharts("column3d", render_number , "500", "400", chart_number, "json", data_source)
                    #import pdb; pdb.set_trace()
                    stat_per_time [lane_chart] = lane_graphic.render()
                    l_count +=1 
                
                # prepare the pie graphic for the number of top Unknow Barcode per sequence
                data_source = pie_graphic_for_unknow_barcode('Number of count for the Undetermined Sequences', 'fint',top_count_sequence)
                unknow_pie3d = FusionCharts("pie3d", "ex5" , "500", "400", "chart-5", "json", data_source)
                stat_per_time ['unknow_pie3d'] = unknow_pie3d.render()
                #import pdb; pdb.set_trace()
                return render(request, 'wetlab/NextSeqStatsPerTime.html', {'display_stats_per_time_list': stat_per_time })
                
            else:
                return render (request,'wetlab/error_page.html', {'content':['No matches have been found for Runs created between', start_date, ' and the ',  end_date ]})
        else:
            return render (request,'wetlab/error_page.html', {'content':'Start date and End Date cannot be empty '}) 

        ############################################################# 

    return render (request,'wetlab/NextSeqStatsPerTime.html')
    
def get_list_of_libraries_values (library_found, q30_comparations, mean_comparations , n_bases_comparations) :
        
    for project_to_compare in library_found :
        library_to_compare_name = project_to_compare.get_library_name()
        project_to_compare_id = project_to_compare.id
        q30_compare_lib, mean_compare_lib, yield_mb_compare_lib = [], [] , []
        for lane_number in range (1,5):
            lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_to_compare_id, lane__exact = lane_number)
            q_30_value, mean_q_value, yield_mb = lane_in_project.get_stats_info().split(';')
            q30_compare_lib.append(float(q_30_value))
            mean_compare_lib.append(float(mean_q_value))
            yield_mb_compare_lib.append(float(yield_mb.replace(',','')))
        if library_to_compare_name in q30_comparations:
            q30_tmp_list =[float(q30_comparations [library_to_compare_name]), statistics.mean (q30_compare_lib)]
            q30_comparations [library_to_compare_name] = format(statistics.mean (q30_tmp_list), '.2f')
            mean_tmp_list = [float(mean_comparations [library_to_compare_name]), statistics.mean (mean_compare_lib)]
            mean_comparations [library_to_compare_name] = format(statistics.mean (mean_tmp_list), '.2f')
            n_bases_list =[float(n_bases_comparations [library_to_compare_name]), statistics.mean (yield_mb_compare_lib)]
            n_bases_comparations [library_to_compare_name] = format(statistics.mean (n_bases_list), '.2f')
        else:
            q30_comparations [library_to_compare_name] = format(statistics.mean (q30_compare_lib), '.2f')
            mean_comparations [library_to_compare_name] = format(statistics.mean (mean_compare_lib), '.2f')
            n_bases_comparations [library_to_compare_name] = format(statistics.mean (yield_mb_compare_lib), '.2f') 
 
 
def nextSeqStats_per_library (request):
    if request.method=='POST' :
        library_kit_name=request.POST['libraryKitName']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']    
        # check that some values are in the request if not return the form
        if library_kit_name == '' and start_date == '' and end_date == '' :
            return render(request, 'wetlab/NextSeqStatsPerLibrary.html')
        
        if library_kit_name !=''  and len(library_kit_name) <3 :
             return render (request,'wetlab/error_page.html', {'content':['The user name must contains at least 4 caracters ', 
                                                                    'ADVICE:', 'write the full Library Kit name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try: 
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try: 
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ', 
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})  
        if library_kit_name != '':
            if Projects.objects.filter(libraryKit__contains = library_kit_name, procState = 'Completed').exists():
                library_found = Projects.objects.filter(libraryKit__contains = library_kit_name, procState = 'Completed')
        else:
            library_found = Projects.objects.filter(procState == 'Completed')
        if (start_date != '' and end_date != ''):
            if library_found.filter(generatedat__range=(start_date, end_date)).exists():
                 library_found = library_found.filter(generatedat__range=(start_date, end_date))
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if library_found.filter(generatedat__gte = start_date).exists():
                 library_found = library_found.filter(generatedat__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if library_found.filter(generatedat__lte = end_date).exists():
                #import pdb; pdb.set_trace()
                library_found = library_found.filter(generatedat__lte = end_date)
            else:
                return render (request,'wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' finish before ', end_date]})
        
        #Collecting the statistics for the selected library
        # Get the projects which are using the library kit
        #import pdb; pdb.set_trace()
        library_stats ={}
        projects_name_in_library =[]
        q_30_list , mean_q_list , yield_mb_list = [] , [] ,[]
        # Getting 1 library. Library could be in several projects. Information is collected per lane and by project 
        #check if only 1 library kit matches the query
        library_names ={}
        for library in library_found :
            library_names [library.libraryKit] = 1
        if len(library_names) == 1:
            # There is only 1 library in the query. Results displays all projects data which have this library kit
            mean_lane_graphic ={}
            for project in library_found :
                projects_name_in_library.append(project.get_project_name())
            q30_in_lib, mean_in_lib, yield_mb_in_lib = [], [] , []
            for lane_number in range (1,5):
                q_30_lane , mean_q_lane , yield_mb_lane = {} , {} ,{}
                for project in library_found :
                    project_id = project.id
                    # Get quality information for each Lane summary of the project id
                                        
                    lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_id, lane__exact = lane_number)
                    q_30_value, mean_q_value, yield_mb = lane_in_project.get_stats_info().split(';')
                    project_name = project.get_project_name()
                    q_30_lane[project_name] = q_30_value
                    q30_in_lib.append(float(q_30_value))
                    mean_q_lane[project_name] = mean_q_value
                    mean_in_lib.append(float(mean_q_value))
                    yield_mb_lane[project_name] = yield_mb.replace(',','')
                    yield_mb_in_lib.append(float(yield_mb.replace(',','')))
                    #import pdb; pdb.set_trace()
                # creating the Yield MBases graphics
                chart_number = 'chart-' + str(lane_number)
                render_number = 'ex'+ str(lane_number)
                heading = 'Number of MBases in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Number of M bases', 'ocean', yield_mb_lane)
                yield_mb_lane_graphic = FusionCharts("column3d", render_number , "500", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                yield_graphic = 'yield_mb_graphic' + str(lane_number)
                library_stats [yield_graphic] = yield_mb_lane_graphic.render()
                
                # creating the Q30 graphics
                chart_number = 'q30-chart-' + str(lane_number)
                render_number = 'q30-ex'+ str(lane_number)
                heading = 'Percent of bases > Q30 in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Percent of Q 30', 'zune', q_30_lane)
                q30_lane_graphic = FusionCharts("column3d", render_number , "400", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                q30_graphic = 'q30_graphic' + str(lane_number)
                library_stats [q30_graphic] = q30_lane_graphic.render()
                
                # creating the Mean graphics
                chart_number = 'mean-chart-' + str(lane_number)
                render_number = 'mean-ex'+ str(lane_number)
                heading = 'Mean Quality Score in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Percent of Q 30', 'carbon', mean_q_lane)
                mean_lane_graphic = FusionCharts("column3d", render_number , "400", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                mean_graphic = 'mean_graphic' + str(lane_number)
                library_stats [mean_graphic] = mean_lane_graphic.render()
                
                    
            library_name = project.get_library_name()
            library_stats['library_name'] = library_name  
            library_stats['project_names'] = projects_name_in_library   
            #import pdb; pdb.set_trace()    
            ########################################################################
            # set the data for the library under study
            ########################################################################
            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {} 
            q30_comparations [library_name] = format(statistics.mean (q30_in_lib), '.2f')
            mean_comparations [library_name] = format(statistics.mean (mean_in_lib), '.2f')
            n_bases_comparations [library_name] = format(statistics.mean (yield_mb_in_lib), '.2f')
            error_in_library_to_compare = ''
            # get the data for the libraries to compare with  
            if start_date == '' and end_date == '':
                if Projects.objects.filter(procState = 'Completed').exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed').exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison. '
                    
            if start_date != '' and end_date == '':
                if Projects.objects.filter(procState = 'Completed', generatedat__gte = start_date).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__gte = start_date).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison, with the starting date  ' + start_date
            
            if start_date == '' and end_date != '':
                if Projects.objects.filter(procState = 'Completed', generatedat__lte = end_date).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__lte = end_date).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison ending with  ' + end_date
                    
            if start_date != '' and end_date != '':
                if Projects.objects.filter(procState = 'Completed', generatedat__range =(start_date, end_date)).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__range =(start_date, end_date)).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison for the start date  ' + start_date + '  and with the ending date  ' + end_date
              
            if error_in_library_to_compare == '':
                for project_to_compare in libraries_to_compare :
                    library_to_compare_name = project_to_compare.get_library_name()
                    project_to_compare_id = project_to_compare.id
                    #q_30_lane , mean_q_lane , yield_mb_lane = {} , {} ,{}
                    q30_compare_lib, mean_compare_lib, yield_mb_compare_lib = [], [] , []
                    for lane_number in range (1,5):
                        lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_to_compare_id, lane__exact = lane_number)
                        q_30_value, mean_q_value, yield_mb = lane_in_project.get_stats_info().split(';')
                        q30_compare_lib.append(float(q_30_value))
                        mean_compare_lib.append(float(mean_q_value))
                        yield_mb_compare_lib.append(float(yield_mb.replace(',','')))
                    if library_to_compare_name in q30_comparations:
                        q30_tmp_list =[float(q30_comparations [library_to_compare_name]), statistics.mean (q30_compare_lib)]
                        q30_comparations [library_to_compare_name] = format(statistics.mean (q30_tmp_list), '.2f')
                        mean_tmp_list = [float(mean_comparations [library_to_compare_name]), statistics.mean (mean_compare_lib)]
                        mean_comparations [library_to_compare_name] = format(statistics.mean (mean_tmp_list), '.2f')
                        n_bases_list =[float(n_bases_comparations [library_to_compare_name]), statistics.mean (yield_mb_compare_lib)]
                        n_bases_comparations [library_to_compare_name] = format(statistics.mean (n_bases_list), '.2f')
                    else:
                        q30_comparations [library_to_compare_name] = format(statistics.mean (q30_compare_lib), '.2f')
                        mean_comparations [library_to_compare_name] = format(statistics.mean (mean_compare_lib), '.2f')
                        n_bases_comparations [library_to_compare_name] = format(statistics.mean (yield_mb_compare_lib), '.2f')
                 
            else:
                library_stats ['error_library'] = error_in_library_to_compare
                
 
            heading = 'Comparison of Percent of bases > Q30  ' 
            data_source = graphic_for_library_kit (heading, 'Q30 comparison ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            comp_q30_lib_graphic = FusionCharts("column3d", 'comp-q30-1' , "500", "300", 'comp-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_q30_graphic'] = comp_q30_lib_graphic.render()

            heading = 'Comparison of Mean Quality Score ' 
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score comparison ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-mean-1' , "500", "300", 'comp-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_mean_graphic'] = comp_mean_lib_graphic.render()
            
            heading = 'Number of Bases comparison' 
            data_source = graphic_for_library_kit (heading, 'Number of Bases comparison ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-n_bases-1' , "500", "300", 'comp-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_n_bases_graphic'] = comp_mean_lib_graphic.render()
            
            return render (request,'wetlab/NextSeqStatsPerLibrary.html', {'display_library_stats': library_stats })
        else:
            library_list_stats ={}
            libraries_found_name =[]
            # get the library names that match with the searching criteria
            for library in library_found :
                lib_name =library.get_library_name ()
                if not lib_name in libraries_found_name :
                    libraries_found_name.append(lib_name)
            #import pdb; pdb.set_trace()
            library_list_stats['library_names'] = libraries_found_name
            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {} 
            ###
            # get the data for displaying the libraries found in the form request
            ###
            get_list_of_libraries_values (library_found, q30_comparations, mean_comparations , n_bases_comparations)
           
            heading = 'Comparison of Percent of bases > Q30  ' 
            data_source = graphic_for_library_kit (heading, 'Q30 comparison ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            comp_q30_lib_graphic = FusionCharts("column3d", 'comp-q30-1' , "500", "300", 'comp-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_q30_graphic'] = comp_q30_lib_graphic.render()

            heading = 'Comparison of Mean Quality Score ' 
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score comparison ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-mean-1' , "500", "300", 'comp-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_mean_graphic'] = comp_mean_lib_graphic.render()
            
            heading = 'Number of Bases comparison' 
            data_source = graphic_for_library_kit (heading, 'Number of Bases comparison ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-n_bases-1' , "500", "300", 'comp-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_n_bases_graphic'] = comp_mean_lib_graphic.render()
            ###
            # get the data for displaying the libraries found in the form request
            ###
            all_libraries = Projects.objects.filter(procState = 'Completed')
            if (start_date != '' and end_date != ''):
                if all_libraries.filter(generatedat__range=(start_date, end_date)).exists():
                     library_found = library_found.filter(generatedat__range=(start_date, end_date))
            if start_date !='' and end_date == '':
                if all_libraries.filter(generatedat__gte = start_date).exists():
                     all_libraries = library_found.filter(generatedat__gte = start_date)
            if start_date =='' and end_date != '':
                if all_libraries.filter(generatedat__lte = end_date).exists():
                    #import pdb; pdb.set_trace()
                    all_libraries = library_found.filter(generatedat__lte = end_date)
            
            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {} 
            get_list_of_libraries_values (all_libraries, q30_comparations, mean_comparations , n_bases_comparations)
            
            heading = 'Library kits of Percent of bases > Q30  ' 
            data_source = graphic_for_library_kit (heading, 'Q30 library kits ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            lib_q30_lib_graphic = FusionCharts("column3d", 'lib-q30-lib' , "500", "300", 'lib-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_q30_graphic'] = lib_q30_lib_graphic.render()

            heading = 'Library kits of Mean Quality Score ' 
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score Library kits ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            lib_mean_lib_graphic = FusionCharts("column3d", 'lib-mean-lib' , "500", "300", 'lib-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_mean_graphic'] = lib_mean_lib_graphic.render()
            
            heading = 'Number of Bases per Library kits' 
            data_source = graphic_for_library_kit (heading, 'Number of Bases per Library kits ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            lib_mean_lib_graphic = FusionCharts("column3d", 'lib-n_bases-lib' , "500", "300", 'lib-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_n_bases_graphic'] = lib_mean_lib_graphic.render()
            
            #import pdb; pdb.set_trace()
            return render (request,'wetlab/NextSeqStatsPerLibrary.html', {'display_list_of_library_stats': library_list_stats })

    else:
        return render (request,'wetlab/NextSeqStatsPerLibrary.html')
    
    
def downloadFile(request):
    #from urllib.parse import urlparse
    #from os.path import splitext, basename
    #filename = object_name.file.name.split('/')[-1]
    #path_to_file = '/home/bioinfo/web_carlosIII/wetlab/documents/test.pdf'
    #f = open(path_to_file, 'r',encoding='utf-8')
    #myfile = File(f)
    
    found=re.search('.*/wetlab/documents/(.*)\'>',str(request))
    if found:
        file_name=found.group(1)
    else:
        return render (request, 'wetlab/error_page.html', {'content':['File not found ', 'check with your administator']})
    #file_tmp_name=str(request).split('/')[-1]
    #temp_1=file_tmp_name.replace(">","")
    #file_name=temp_1.replace("'","")

    #disassembled = urlparse(str(request))
    #filename, file_ext = splitext(basename(disassembled.path))
    #file_name=str(filename + file_ext)
    #import pdb; pdb.set_trace()
    extension = file_name[-4:]
    if (extension == '.csv'):
        with open(os.path.join(settings.MEDIA_ROOT, file_name), 'r') as fh:
            response = HttpResponse(fh.read(),content_type="text/csv")
            response['Content-Disposition'] = 'attachment; filename=download.csv'
    #to open the file as text but pdf is binary. Change 'r' to 'rb' in open
    if (extension == 'xlsx'):
        #### For excel files use the  content_type='application/vnd.ms-excel'
        with open(os.path.join(settings.MEDIA_ROOT, file_name), 'rb') as fh:
            response = HttpResponse(fh.read(),content_type='application/vnd.ms-excel')
            response['Content-Disposition'] = 'attachment; filename=download.xlsx'
    if  (extension == '.pdf'):   
         # PDF file to be downloaded
        with open(os.path.join(settings.MEDIA_ROOT, file_name), 'rb') as fh:
        #with open(os.path.join(settings.MEDIA_ROOT, 'test.pdf'), 'rb') as fh:
            response = HttpResponse(fh.read(), content_type="application/pdf")
            response['Content-Disposition'] = 'attachment; filename=download.pdf'
    return response


#def result_form (request):
#    doc= Document.object.all()
#    return render(request , 'wetlab/result_form.html', {'form':doc})

#def results_run_folder (request):

#    return 
    #return render (request, 'results_run_folder.html', {'d_list':[info_data]})



    
'''    
def simple_upload(request):
    if request.method == 'POST' and request.FILES['myfile']:
        myfile = request.FILES['myfile']
        fs = FileSystemStorage()
        filename = fs.save(myfile.name,  myfile)
        uploaded_file_url = fs.url(filename)
        import pdb; pdb.set_trace()
        return render(request, 'wetlab/simple_upload.html', {
            'uploaded_file_url': uploaded_file_url
        })
    return render(request, 'wetlab/simple_upload.html')
'''
''' 
def model_form_upload(request):
    if request.method == 'POST':
        form = DocumentForm(request.POST, request.FILES)
        if form.is_valid():
            
            doc_tmp=str(form.cleaned_data.get('csv_file'))
            run_name_value=str(form.cleaned_data.get('run_name'))
            #import pdb; pdb.set_trace() 
            tmp_name = re.search('(.*\.csv$)',doc_tmp)
            if (tmp_name):
                form.save()
                name_in_file=tmp_name.group(1)
                if (re.search('\.csv$',name_in_file)):
                    #doc=str(name_in_file)
                    doc=str('wetlab/documents/documents/'+ name_in_file)
                    #import pdb; pdb.set_trace()
                    mapped_file=sample_sheet_map_basespace(doc).replace('wetlab/','')
                    #mapped_file=True ## checking the file can upload and download
                    if (mapped_file != 'Error'):
                        space_base = BaseSpaceFile( document=Document.objects.get(run_name=run_name_value), baseSpace_file = mapped_file)
                        space_base.save()
                        
                        #import pdb; pdb.set_trace()
                        ## ejemplo de conseguir el documento de base space con el nombre de la carrera
                        #dd = BaseSpaceFile.objects.get(document=Document.objects.get(run_name='juan run4'))
                        run_data=[]
                        tmp_data=[]
                        d_list=['Run folder name','Project name','User identity','Description of the run', 
                                'User name','Sample Sheet file', 'File was uploaded at date']
                        run_index= Document.objects.filter(run_name__icontains = run_name_value)
                        run_values=run_index[0].get_run_info().split(';')
                        #import pdb; pdb.set_trace()
                        for i in range (len (d_list)):
                            #tmp_data = d_list[i],run_values[i]
                            #run_data.append(tmp_data)
                            run_data.append([d_list[i],run_values[i]])
                            #tmp_data=[]
                        #import pdb; pdb.set_trace()
                        #tmp_data = 'BaseSpace file', mapped_file
                        run_data.append(['BaseSpace file', mapped_file]) 
                        return render (request , 'wetlab/resultsForm.html', {'r_data' : run_data} )

                    else:
                        #import pdb; pdb.set_trace()
                        Document.objects.get(run_name__icontains=run_name_value).delete() ## using django-clenup app to delete the uploaded file
                        return render (request,'wetlab/error_page.html', {'content':['Sample Sheet does not meet with the format']})
                else:
                    Document.objects.get(run_name__icontains=run_name_value).delete() ## using django-clenup app to delete the uploaded file
                    return render (request, 'wetlab/error_page.html',  {'content':['invalid extension of Sample Sheet file' , 'Extension must be csv']})
            else:
                return render (request, 'wetlab/error_page.html', {'content':['invalid extension of Sample Sheet file', 'Extension must be csv']})
    else:
        
        #form = DocumentForm()
        form = Docutres()
    return render(request, 'wetlab/modelForm_upload.html', {'form': form })
'''


def get_run_data(request):
    if request.method =='POST':
        #form = DocumentForm(request.POST)
        run_data=[]
        tmp_data=[]
        d_list=['Run folder name','Project name','User identity','Description of the run', 
                'User name','Sample Sheet file', 'File was uploaded at date'] 
                #'File was uploaded at time:']
        form=request.POST
        r_name = str(form.get('run_name'))
        try:
            run_index= Document.objects.filter(run_name__icontains = r_name)
                          
        except:
            return render (request, 'wetlab/error_page.html', {'content':['The run  folder name   ', r_name, '  does not exist']})
        run_values=run_index[0].get_run_info().split(';')
        #import pdb; pdb.set_trace()
        for i in range (len (d_list)):
            if (d_list[i] == 'Run folder name'):
                run_name_value=run_values[i]
                
            #tmp_data = d_list[i],run_values[i]
            #run_data.append(tmp_data)
            #tmp_data=[]
            run_data.append([d_list[i],run_values[i]])
        #import pdb; pdb.set_trace()
        bs_file= BaseSpaceFile.objects.get(pk=Document.objects.get(run_name=run_name_value).id)
        #tmp_data = 'BaseSpace file', bs_file.baseSpace_file
        #run_data.append(tmp_data) 
        run_data.append(['BaseSpace file', bs_file.baseSpace_file])
        #import pdb; pdb.set_trace()
        return render (request , 'wetlab/results_run_folder.html', {'r_data' : run_data} )
    else:
        #form = DocumentForm()
        #return render (request, 'wetlab/get_run_data.html',{'form': form})
        return render (request, 'wetlab/get_run_data.html')


    

    
def test_stats (request):
    local_working_dir = '/home/bioinfo/web_carlosIII/wetlab/documents/uploadFromServer/'
    local_stats = '/home/bioinfo/web_carlosIII/wetlab/documents/uploadFromServer/Stats/'
    local_interop= '/home/bioinfo/web_carlosIII/wetlab/documents/uploadFromServer/Interop/'
    run_file = local_working_dir + 'RunInfo.xml'
    run_parameter=  local_working_dir + 'RunParameters.xml'
    running_data = get_running_data(run_file,run_parameter)
    ### get the run name to link the run with statistics data
    run_name_value= running_data['RunID']
    store_in_db(running_data, 'running_table',run_name_value)
    xml_statistics = get_statistics_xml(demux_file, conversion_file)
    store_in_db(xml_statistics, 'nextSeqXml_table',run_name_value)
    
def test_graphic (request):
    from .fusioncharts.fusioncharts import FusionCharts
     # Loading Data from a Static JSON String
    # It is a example to show a Pie 3D chart where data is passed as JSON string format.
    # The `chart` method is defined to load chart data from an JSON string.
    test = {}

    # Create an object for the pie3d chart using the FusionCharts class constructor
    pie3d = FusionCharts("pie3d", "ex1" , "100%", "400", "chart-1", "json", 
        # The data is passed as a string in the `dataSource` as parameter.
        """{ 
                "chart": {
                "caption": "Age profile of website visitors",
                "subcaption": "Last Year",
                "startingangle": "120",
                "showlabels": "0",
                "showlegend": "1",
                "enablemultislicing": "0",
                "slicingdistance": "15",
                "showpercentvalues": "1",
                "showpercentintooltip": "0",
                "plottooltext": "Age group : $label Total visit : $datavalue",
                "theme": "ocean"
                },
                "data": [
                    {"label": "Teenage", "value": "1250400"},
                    {"label": "Adult", "value": "1463300"},
                    {"label": "Mid-age", "value": "1050700"},
                    {"label": "Senior", "value": "491000"}
                ]
        }""")
    chart2d = FusionCharts("column2d", "ex2" , "100%", "200", "chart-2", "json", 
        """{ 
                "chart": {
                "caption": "Age profile of website visitors",
                "subcaption": "Last Year",
                "startingangle": "120",
                "showlabels": "0",
                "showlegend": "1",
                "enablemultislicing": "0",
                "slicingdistance": "15",
                "showpercentvalues": "1",
                "showpercentintooltip": "0",
                "plottooltext": "Age group : $label Total visit : $datavalue",
                "theme": "zune"
                },
                "data": [
                    {"label": "Tiinage", "value": "1250400"},
                    {"label": "Adult", "value": "1463300"},
                    {"label": "Mid-age", "value": "1050700"},
                    {"label": "Senior", "value": "491000"}
                ]
        }""")
        
    deviation = FusionCharts("boxandwhisker2d","ex3","90%", "400", "chart-13", "json",
        """{
    "chart": {
        "caption": "Distribution for Q >= 30",
        "subCaption": "By Gender",
        "xAxisName": "Pay Grades",
        "YAxisName": "Q > 30",
        "numberPrefix": "%",
        "theme": "fint",
        "showValues": "0",
        "showSD": "1",
        "SDIconSides": "5",
        "exportEnabled": "1"
    },
    "categories": [
        {
            "category": [
                {
                    "label": "Grade 1"
                },
                {
                    "label": "Grade 2"
                },
                {
                    "label": "Grade 3"
                }
            ]
        }
    ],
    "dataset": [
        {
            "seriesname": "project 3 and  4",
            "lowerBoxColor": "#008ee4",
            "upperBoxColor": "#6baa01",
            "data": [
                {
                    "value": "81,82,79,79"
                },
                {
                    "value": "85,86,84,83"
                },
                {
                    "value": "81,82,79,79"
                }
            ]
        },
        {
            "seriesname": "project-2 and 1",
            "lowerBoxColor": "#e44a00",
            "upperBoxColor": "#f8bd19",
            "data": [
                {
                    "value": "81,82,79,79"
                },
                {
                    "value": "79,80,77,78"
                },
                {
                    "value": "81,82,79,79"
                }
            ]
        }
    ]
}""")
        
    test ['pie3d'] = pie3d.render()
    test ['chart2d'] = chart2d.render()
    test ['deviation'] = deviation.render() 
    #import pdb; pdb.set_trace()
        # returning complete JavaScript and HTML code, which is used to generate chart in the browsers. 
    return  render(request, 'wetlab/graphic.html', {'output' : test})
    #return  render(request, 'wetlab/graphic.html', {'output' : pie3d.render()})

    
  



    
    

