# -*- coding: utf-8 -*-
## import django
from django.shortcuts import get_object_or_404, render, redirect
from django.http import HttpResponse
from django.template import loader
from django.conf import settings
from django.core.files.storage import FileSystemStorage
from django.contrib.auth.models import User
from django.contrib.auth.decorators import login_required
from django.contrib.auth.models import Group

from iSkyLIMS_wetlab import wetlab_config
## import methods defined on utils.py
from .utils.sample_convertion import *
from .utils.stats_calculation import *
from .utils.stats_graphics import *
from .utils.email_features import *
from .utils.library_kits import *

from django_utils.models import Profile, Center

from .models import *

from .fusioncharts.fusioncharts import FusionCharts
import statistics

import re, os, shutil
import datetime, time

#import pdb; pdb.set_trace()

def index(request):
    #import pdb; pdb.set_trace()
    return render(request, 'iSkyLIMS_wetlab/index.html')

@login_required
def register_wetlab(request):
    #import pdb; pdb.set_trace()
    return render(request, 'iSkyLIMS_wetlab/index.html')

@login_required
def get_sample_file (request):
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    if request.method == 'POST' and (request.POST['action']=='uploadFile'):
        ### First step in collecting data from the NextSeq run. Sample Sheet and experiment name are required
        get_user_names={}
        projects=[]
        #run_name=request.POST['runname']
        myfile = request.FILES['myfile']

        ## check if file contains the extension. Error page is showed if file does not contain any extension
        try:
            split_filename=re.search('(.*)(\.\w+$)',myfile.name)
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Uploaded file does not containt extension', 'Sample Sheet must have a csv extension','',
                                                            'ADVICE:','Select the Sample file generated by Illumina Experient Manager (IEM)']})
        ext_file=split_filename.group(2)
        ## check if file contains the csv extension. Error page is showed if file does not contain the csv extension
        if ext_file != '.csv':
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Sample Sheet must have a csv extension','',
                                                            'ADVICE:','Select the Sample file generated by Illumina Experient Manager (IEM)']})
        fs = FileSystemStorage()
        timestr = time.strftime("%Y%m%d-%H%M%S")
        ## including the timestamp to the sample sheet file
        #import pdb; pdb.set_trace()
        # do not need to include the absolute path because django use the MEDIA_ROOT variable defined on settings to upload the file
        file_name=str(wetlab_config.RUN_SAMPLE_SHEET_DIRECTORY +  split_filename.group(1) + timestr + ext_file)
        filename = fs.save(file_name,  myfile)
        uploaded_file_url = fs.url(filename)

        ### add the document directory to read the csv file
        stored_file = os.path.join(settings.MEDIA_ROOT, file_name)
        #import pdb; pdb.set_trace()
        ## Fetch the experiment name and the library name from the sample sheet file
        run_name, index_library_name = get_experiment_library_name(stored_file)
        if run_name == '':
            run_name = timestr  ## define an unique value for the run name until the real value is get from the form
        ## check that runName is not already used in the database. Error page is showed if runName is already  defined
        #import pdb; pdb.set_trace()
        if (RunProcess.objects.filter(runName = run_name)).exists():
            if RunProcess.objects.filter(runName = run_name, runState__exact ='Pre-Recorded'):
                ## Delete the Sample Sheet file and the row in database
                delete_run = RunProcess.objects.filter(runName = run_name, runState__exact ='Pre-Recorded')
                sample_sheet_file = str(delete_run[0].sampleSheet)
                #import pdb; pdb.set_trace()
                full_path_sample_sheet_file = os.path.join(settings.MEDIA_ROOT, sample_sheet_file)
                os.remove(full_path_sample_sheet_file)
                delete_run[0].delete()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Run Name is already used. ','Run Name must be unique in database.',' ',
                                                            'ADVICE:','Change the value in the Sample Sheet  file ']})


        ## Fetch from the Sample Sheet file the projects included in the run and the user. Error page is showed if not project/description colunms are found
        project_list=get_projects_in_run(stored_file)

        if len (project_list) == 0 :
            ## delete sample sheet file
            fs.delete(file_name)
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Sample Sheet does not contain "Sample project" and/or "Description" fields','',
                                                            'ADVICE:','Check that csv file generated by Illumina Experient Manager (IEM) includes these columns']})
        ## Check if the users are already defined on database. Error page is showed if users are not defined on database
        user_not_defined=[]
        for key, val  in project_list.items():
            if ( not User.objects.filter(username__icontains = val).exists()):
                user_not_defined.append(val)
        if (len(user_not_defined)>0):
            if (len(user_not_defined)>1):
                head_text='The following users are not defined in database:'
            else:
                head_text='The following user is not defined in database:'
            ## convert the list into string to display the user names on error page
            display_user= ' ,  '.join(user_not_defined)
            ## delete sample sheet file before showing the error page
            fs.delete(file_name)

            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[ head_text,'', display_user,'',
                           'Researcher names must be installed in database before uploading the Sample sheet']})
        ## Check if the projects are already defined on database. Error page is showed if projects are already defined on database
        #import pdb; pdb.set_trace()
        project_already_defined=[]
        for key, val  in project_list.items():
            # check if project was already saved in database in Not Started State.
            # if found delete the projects, because the previous attempt to complete the run was unsuccessful
            if ( Projects.objects.filter(projectName__icontains = key).exists()):
                if ( Projects.objects.filter(projectName__icontains = key, procState__exact = 'Not Started').exists()):
                    delete_project = Projects.objects.filter(projectName__icontains = key , procState__exact = 'Not Started')
                    delete_project[0].delete()
                else:
                    project_already_defined.append(key)
        if (len(project_already_defined)>0):
            if (len(project_already_defined)>1):
                head_text='The following projects are already defined in database:'
            else:
                head_text='The following project is already defined in database:'
            ## convert the list into string to display the user names on error page
            display_project= '  '.join(project_already_defined)
                ## delete sample sheet file before showing the error page
            fs.delete(file_name)
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[ head_text,'', display_project,'',
                          'Project names must be unique','', 'ADVICE:','Edit the Sample Sheet file to correct this error']})
        ##Once the information looks good. it will be stores in runProcess and projects table

        ## store data in runProcess table, run is in pre-recorded state
        #import pdb; pdb.set_trace()
        center_requested_id = Profile.objects.get(profileUserID = request.user).profileCenter.id
        center_requested_by = Center.objects.get(pk = center_requested_id)
        run_proc_data = RunProcess(runName=run_name,sampleSheet= file_name, runState='Pre-Recorded', centerRequestedBy = center_requested_by)
        run_proc_data.save()
        experiment_name = '' if run_name == timestr else run_name

        ## create new project tables based on the project involved in the run and
        ## include the project information in projects variable to build the new FORM

        run_info_values ={}
        run_info_values['experiment_name'] = experiment_name
        run_info_values['index_library_name'] = index_library_name
        for key, val  in project_list.items():
            userid=User.objects.get(username__exact = val)
            p_data=Projects(runprocess_id=RunProcess.objects.get(runName =run_name), projectName=key, user_id=userid)
            p_data.save()
            projects.append([key, val])
        run_info_values['projects_user'] = projects
        run_info_values['runname']= run_name
        ## Get the list of the library kit used (libraryKit)
        #import pdb; pdb.set_trace()
        used_libraries = []
        list_libraries = LibraryKit.objects.order_by().values_list('libraryName', flat=True)
        run_info_values['used_libraryKit'] =  list_libraries

        ## displays the list of projects and the user names found on Sample Sheet
        return render(request, 'iSkyLIMS_wetlab/getSampleSheet.html', {'get_user_names': run_info_values })

    elif request.method=='POST' and (request.POST['action']=='displayResult'):
        experiment_name = request.POST['experimentname']
        run_index_library_name = request.POST['runindexlibraryname']
        run_name= request.POST['runname']
        projects=request.POST.getlist('project')
        user_name=request.POST.getlist('username')
        library_kit=request.POST.getlist('libraryKit')
        project_index_kit=request.POST.getlist('projectindexlibraryname')

        ## get the sample sheet used in the run
        if not RunProcess.objects.filter (runName__exact = run_name).exists():
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['You get this error page because you use the back Buttom to return to previous page where asking for library kit name',
                            'To upload again the shample sheet, use the "Upload the Run" option from the top menu']})
        run_p = RunProcess.objects.get(runName__exact = run_name)
        s_file=run_p.get_sample_file()
        ## get the different type of library kit used in the run and
        ## convert the sample sheet into Base Space. Number of converted
        ## file will be the same as the number of different lybraries use in the run
        library={}
        bs_file={}
        results=[]

        in_file = os.path.join(settings.MEDIA_ROOT,s_file)
        # Set unique Sample_ID in the sample sheet
        index_file = os.path.join(settings.MEDIA_ROOT,'wetlab', 'index_file')
        create_unique_sample_id_values (in_file, index_file)
        #in_file=str('documents/' + s_file)
        #import pdb; pdb.set_trace()
        ## build the project list for each project_library kit
        for x in range(len(project_index_kit)):
            if project_index_kit[x] in library :
                library[project_index_kit[x]].append(projects[x])
            else:
                library[project_index_kit[x]]= [projects[x]]
        ## convert the sample sheet to base space format and have different files according the library kit
        #import pdb; pdb.set_trace()
        for key, value in library.items():
            lib_kit_file =key.replace(' ', '_')
            library_file = sample_sheet_map_basespace(in_file, key, lib_kit_file, value,'Plate96')
            if library_file == 'ERROR':
                # deleting the sample sheet file
                os.remove(in_file)
                # Deleting projects related to the shample sheet
                for p in range(len( projects)):
                    my_project = projects [p]
                    delete_proj=Projects.objects.get(projectName = my_project)
                    delete_proj.delete()
                # delete the run used when uploading the sample sheet
                run_p.delete()
                # show the error page
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[ 'The information on  the Library kit ', key,' For the project ', value,
                          'Does not meet the requirements to perform the conversion to import to Base Space','ADVICE', 'Check the sample sheet that was uploaded ']})
            else:
                bs_file[key] = library_file
                results.append([key, bs_file[key]])

        ## save the project information on database

        for p in range(len( projects)):
            my_project = projects [p]
            my_name = user_name[p]
            my_libkit = library_kit[p]
            library_kit_id = LibraryKit.objects.get(libraryName__exact = library_kit[p])
            update_info_proj=Projects.objects.get(projectName = my_project)
            update_info_proj.libraryKit=project_index_kit[p]
            update_info_proj.baseSpaceFile=bs_file[project_index_kit[p]]
            update_info_proj.LibraryKit_id = library_kit_id
            update_info_proj.proState='Recorded'
            update_info_proj.save()
        results.append(['runname', experiment_name])
        ## save the sample sheet file under tmp/recorded to be processed when run folder was created
        subfolder_name=str(run_p.id)
        #base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        temp_directory = os.path.join(settings.MEDIA_ROOT , wetlab_config.RUN_TEMP_DIRECTORY_RECORDED, subfolder_name)
        os.mkdir(temp_directory)
        # set group writing permission to the temporary directory
        os.chmod(temp_directory, 0o774)
        #os.mkdir(os.path.join(settings.MEDIA_ROOT, 'wetlab/tmp/recorded', subfolder_name ))
        sample_sheet_copy= os.path.join(temp_directory, 'samplesheet.csv' )
        shutil.copy(in_file,sample_sheet_copy)
        # set the group write permission to the Sample Sheet File
        os.chmod(sample_sheet_copy, 0o664)
        # update the sample sheet with the experiment name
        if run_name != experiment_name :
            update_sample_sheet (in_file, experiment_name)
        ## update the Experiment name and the state of the run to 'Recorded'
        run_p.runName = experiment_name
        run_p.index_library = run_index_library_name
        run_p.runState='Recorded'
        run_p.save()
        ## update the project state to Recorded
        project_to_be_updated = Projects.objects.filter(runprocess_id__exact = run_p.id)
        for project in project_to_be_updated :
            project.procState='Recorded'
            project.save()

        #import pdb; pdb.set_trace()
        return render (request, 'iSkyLIMS_wetlab/getSampleSheet.html', {'completed_form':results})


    return render(request, 'iSkyLIMS_wetlab/getSampleSheet.html')

@login_required
def add_library_kit (request):
    #get the list of the already loaded library kits to be displayed
    libraries_information ={}
    libraryKit_list = LibraryKit.objects.all()
    libraryKit_dict = []
    if len(libraryKit_list) >0 :
        for library in libraryKit_list :
            libraryKit_dict.append(library.libraryName)

    if request.method == 'POST' and request.POST['action'] == 'addNewLibraryKit':
        new_library_kit_name = request.POST['newLibraryKit']
        #new_index_number = request.POST['indexLibraryKit']
        #new_sample_number = request.POST['samplesLibraryKit']
        ## Check that library kit is not already defined in database
        if LibraryKit.objects.filter(libraryName__icontains = new_library_kit_name).exists():
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['The Library Kit ', new_library_kit_name, 'is already defined on the system']})
        library_kit_information ={}
        library_kit_information['new_library_kit'] = new_library_kit_name
        #library_kit_information['index_number'] = new_index_number
        #library_kit_information['sample_number'] = new_sample_number
        #import pdb; pdb.set_trace()
        library_kit_information ['libraries']  = libraryKit_dict
        #save the new library on database
        library = LibraryKit(libraryName= new_library_kit_name)
        library.save()
        return render (request, 'iSkyLIMS_wetlab/AddLibraryKit.html',{'library_kit_info':library_kit_information})
    else:

        libraries_information ['libraries'] = libraryKit_dict
        return render(request,'iSkyLIMS_wetlab/AddLibraryKit.html',{'list_of_libraries': libraries_information})

@login_required
def add_index_library (request):
    #get the list of the already loaded index library to be displayed
    index_libraries_information ={}
    index_library_list = IndexLibraryKit.objects.all()
    index_library_dict = []
    if len(index_library_list) >0 :
        for library in index_library_list :
            index_library_dict.append([library.id, library.indexLibraryName])

    if request.method == 'POST' and request.POST['action'] == 'addNewIndexLibraryFile':

        index_library_file = request.FILES['newIndexLibraryFile']

        split_filename=re.search('(.*)(\.\w+$)',index_library_file.name)
        f_name = split_filename[1]
        f_extension = split_filename[2]

        fs = FileSystemStorage()
        timestr = time.strftime("%Y%m%d-%H%M%S")
        ## including the timestamp to the index library file
        #import pdb; pdb.set_trace()
        # do not need to include the absolute path because django use the MEDIA_ROOT variable defined on settings to upload the file
        file_name=os.path.join(wetlab_config.LIBRARY_KITS_DIRECTORY ,  str(f_name + '_' +timestr + f_extension))
        filename = fs.save(file_name,  index_library_file)
        saved_file = os.path.join(settings.MEDIA_ROOT, file_name)
        # check the file is not bigger that maximum allowed size file for index library
        file_stat = os.stat(saved_file)
        if file_stat.st_size > int(wetlab_config.LIBRARY_MAXIMUM_SIZE) :
            # removing the uploaded file
            os.remove(saved_file)
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['The Index Library Kit file ', split_filename[0], 'exceed from the maximum allowed size']})
        uploaded_file_url = fs.url(filename)

        ### add the document directory to read the csv file

        #import pdb; pdb.set_trace()
        ## check format file

        if not check_index_library_file_format(saved_file):
            # removing the uploaded file
            os.remove(saved_file)
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['The Index Library Kit file', split_filename[0], 'does not have the right format']})
        library_name = getting_index_library_name(saved_file)
        if library_name == '' :
            # removing the uploaded file
            os.remove(saved_file)
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['The Index Library Kit file', split_filename[0], 'does not contain the library name']})
        # check if library name is already defined on database
        if IndexLibraryKit.objects.filter (indexLibraryName__exact = library_name).exists():
            # removing the uploaded file
            os.remove(saved_file)
            return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['The Library Kit Name ', library_name, 'is already defined on iSkyLIMS']})
        # Get the library settings included in the file
        library_settings = get_library_settings(saved_file)

        # get the index name and index bases for the library
        library_index = get_index_values(saved_file)
        # saving library settings into database
        if len(library_settings['adapters']) == 1:
            adapter_2 = ''
        else :
            adapter_2 = library_settings['adapters'][1]
        lib_settings_to_store = IndexLibraryKit(indexLibraryName = library_settings['name'], version =  library_settings ['version'],
                    plateExtension = library_settings['plate_extension'] , adapter1 = library_settings['adapters'][0], adapter2 = adapter_2,
                    indexLibraryFile = file_name)
        lib_settings_to_store.save()
        # saving index values into database
        for index_7 in library_index['I7'] :
            index_name, index_base = index_7
            index_to_store = IndexLibraryValues(indexLibraryKit_id = lib_settings_to_store, indexNumber = 'I7',
                        indexName = index_name, indexBase = index_base)
            index_to_store.save()
        for index_5 in library_index['I5'] :
            index_name, index_base = index_5
            index_to_store = IndexLibraryValues(indexLibraryKit_id = lib_settings_to_store, indexNumber = 'I5',
                        indexName = index_name, indexBase = index_base)
            index_to_store.save()

        index_libraries_information['new_index_library'] = library_settings['name']
        index_libraries_information ['index_libraries'] = index_library_dict
        #import pdb; pdb.set_trace()
        return render (request, 'iSkyLIMS_wetlab/AddIndexLibrary.html',{'index_library_info': index_libraries_information })
    else:
        index_libraries_information ['index_libraries'] = index_library_dict
        return render (request, 'iSkyLIMS_wetlab/AddIndexLibrary.html',{'list_of_index_libraries': index_libraries_information })

def normalized_data (run_data, all_data) :
    normalized_run_data, normalized_all_data = [] , []
    min_value = min(min(run_data),min(all_data))
    max_value = max(max(run_data), max(all_data))
    for value in run_data :
        normalized_run_data.append(format((value - min_value)/max_value,'.2f'))
    for value in all_data :
        normalized_all_data.append(format((value - min_value)/max_value,'.2f'))
    
    return normalized_run_data, normalized_all_data
    
    
    
    

def get_information_run(run_name_found,run_id):
    info_dict={}
    ## collect the state to get the valid information of run that matches the run name
    run_state=run_name_found.get_state()
    # allow to change the run name in case that run state was recorded or Sample Sent
    if run_state == 'Recorded' or run_state == 'Sample Sent':
        info_dict['change_run_name'] = [[run_name_found.runName, run_id]]
    if (run_state != 'Completed'):
        d_list=['Run name','State of the Run is','Run was requested by','Run was recorded on date', 'Run date', 'Run Finish Date','RunID']
    else:
        d_list=['Run name','State of the Run is','Run was requested by',
                'Disk space used for Images(in MB)','Disk space used for Fasta Files(in MB)',
                'Disk space used for other Files(in MB)','Run recorded date','Run date', 'Run Finish Date',
                'Bcl2Fastq finish Date','Run Completion Date']
    run_info_data=run_name_found.get_info_process().split(';')
    info_dict['Sample_Sheet'] = [['Sample Sheet File', run_name_found.get_sample_file()]]
    r_data_display=[]
    for i in range (len (d_list)):
        r_data_display.append([d_list[i],run_info_data[i]])
    info_dict['data']=r_data_display
    info_dict['run_state'] = run_state
    if (run_state.startswith('ERROR')):
        info_dict['graphic_value']=10
        info_dict['graphic_color']= 'red'
    if (run_state == 'Recorded'):
        info_dict['graphic_value']=25
        info_dict['graphic_color']= 'violet'
    if (run_state == 'Sample Sent'):
        info_dict['graphic_value']=40
        info_dict['graphic_color']= 'pink'
    if (run_state == 'Process Running'):
        info_dict['graphic_value']=50
        info_dict['graphic_color']= 'brown'
    if (run_state == 'Bcl2Fastq Executed'):
        info_dict['graphic_value']=60
        info_dict['graphic_color']= 'orange'
    if (run_state == 'Running Stats'):
        info_dict['graphic_value']=75
        info_dict['graphic_color']= 'yellow'
    if (run_state == 'Completed'):
        info_dict['graphic_value']=100
        info_dict['graphic_color']= 'green'
        # finding the running parameters index for the run
        runName_id=RunningParameters.objects.get(pk=run_id)
        # Adding the Run Parameters information
        rp_list=['Run ID','Experiment Name ','RTA version ','System Suite Version','Library ID ','Chemistry','Run Start Date', 'Analysis Work Flow Type','Run Management Type','Planned Read1 Cycles',
                'Planned Read2 Cycles','Planned Index1 Read Cycles','Planned Index2 Read Cycles','Application Version','Num Tiles per Swatch','Image Channel',
                'Flowcel','Image Dimensions', 'Flowcell Layout']
        rp_data=runName_id.get_run_parameters_info().split(';')
        r_rp_display=[]
        for i in range (len(rp_list)):
            if i == 'Image Channel':
                img_data_list=rp_data[i].split(',')
                r_rp_display.append([rp_list[i],[img_data_list]])
            else:
                r_rp_display.append([rp_list[i], rp_data[i]])
        info_dict['parameters']=r_rp_display
        ### BaseSpaceFile.objects.get(pk=Document.objects.get(run_name=run_name_value).id)

    p_list= Projects.objects.filter(runprocess_id=run_id)
    if p_list !='':
        p_data_list=[]
        p_library_kit_list = []
        for p in range (len(p_list)):
            p_data_list.append([p_list[p].projectName,p_list[p].id])
            # get information about the library kits used for this run
            lib_kit = p_list[p].libraryKit
            if not lib_kit in p_library_kit_list :
                p_library_kit_list.append(lib_kit)
        info_dict['projects']=p_data_list
        info_dict['library_kit'] = p_library_kit_list
        info_dict['run_id'] = run_id

    ## get the stats information if run is completed
    if run_state == 'Completed':
        # prepare the data for q-means
        # fetch Q>30 , mean_q and yield mb for all projects per lane to create the boxplot
        run_lane_summary = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id ).exclude(defaultAll__isnull = False)
        q_30_value_list, mean_value_list = [] , []
        q_30_run_value , mean_run_value = [] , []
        q_30_run_value_float , mean_run_value_float , yield_mb_run_value_float, cluster_pf_run_value_float = [] , [], [] , []
        q_30_all_value_float , mean_all_value_float , yield_mb_all_value_float , cluster_pf_all_value_float = [] , [] , [], []
        
        for item in run_lane_summary:
            q_30_value, mean_value , yield_mb_value , cluster_pf_value, = item.get_stats_info().split(';')

            q_30_run_value_float.append(float(q_30_value))
            mean_run_value_float.append(float(mean_value))
            yield_mb_run_value_float.append(float(yield_mb_value.replace(',','')))
            cluster_pf_run_value_float.append(float(cluster_pf_value.replace(',','')))
            
        # get the chemistry type for the run, that will be used to compare runs with the same chemistry value
        chem_high_mid = RunningParameters.objects.get(runName_id__exact = run_id).Chemistry
        run_different_chemistry = RunningParameters.objects.all(). exclude(Chemistry__exact = chem_high_mid)
        run_year = run_name_found.run_date.timetuple().tm_year
        
        start_date = str(run_year) + '-1-1'
        end_date = str(run_year) +'-12-31'
        same_run_in_year = RunProcess.objects.filter(run_date__range=(start_date, end_date)).exclude(runName__in = run_different_chemistry)
        
        same_runs_in_year_list = []
        for run in same_run_in_year :
            same_runs_in_year_list.append(run.id)
        
        
        
        all_lane_summary = NextSeqStatsLaneSummary.objects.filter(runprocess_id__in = same_runs_in_year_list).exclude(defaultAll__isnull = False).exclude(runprocess_id__exact =run_id)
        for item in all_lane_summary:
            q_30_value, mean_value , yield_mb_value , cluster_pf_value = item.get_stats_info().split(';')
            '''
            q_30_all_value.append(format(float(q_30_value)/100,'.2f'))
            mean_all_value.append(format(float(mean_value)/36,'.2f'))
            '''
            q_30_all_value_float.append(float(q_30_value))
            mean_all_value_float.append(float(mean_value))
            yield_mb_all_value_float.append(float(yield_mb_value.replace(',','')))
            cluster_pf_all_value_float.append(float(cluster_pf_value.replace(',','')))

        q_30_run_normalized , q_30_all_normalized = normalized_data (q_30_run_value_float, q_30_all_value_float)
        mean_run_normalized , mean_all_normalized = normalized_data (mean_run_value_float, mean_all_value_float)
        yield_mb_run_normalized , yield_mb_all_normalized = normalized_data (yield_mb_run_value_float, yield_mb_all_value_float)
        cluster_pf_run_normalized , cluster_pf_all_normalized = normalized_data (cluster_pf_run_value_float, cluster_pf_all_value_float)
        q30_run_str = ','.join(q_30_run_normalized)
        mean_run_str = ','.join(mean_run_normalized)
        yield_mb_run_str = ','.join(yield_mb_run_normalized)
        cluster_pf_run_str = ','.join(cluster_pf_run_normalized)
        
        q_30_all_str = ','.join(q_30_all_normalized)
        mean_all_str = ','.join(mean_all_normalized)
        yield_mb_all_str = ','.join(yield_mb_all_normalized)
        cluster_pf_all_str = ','.join(cluster_pf_all_normalized)
     

        
        heading =  run_name_found.runName +' versus runs executed on '
        sub_caption = str( 'year ' + str(run_year))
        theme = 'fint'
        x_axis_name = 'Quatilty measures (normalized data)'
        y_axis_name = 'Normalized values '
        series = [[run_name_found.runName,'#0075c2', '#1aaf5d'],['All runs','#f45b00','#f2c500']]
        data = [[q30_run_str,mean_run_str, yield_mb_run_str, cluster_pf_run_str],[q_30_all_str, mean_all_str, yield_mb_all_str, cluster_pf_all_str]]
        
        
        categories = ['Q > 30', 'Mean Quality Score', 'Yield MB', 'Cluster PF']
        #import pdb; pdb.set_trace()
        data_source = bloxplot_graphic(heading, sub_caption, x_axis_name, y_axis_name, theme, categories, series, data)
        #import pdb; pdb.set_trace()
        #data_source = bloxplot_graphic()
        #data_source = json_2_column_graphic('Comparison of bases with Q value bigger than 30', q_30_project_lane,q_30_media)
        info_dict ['boxplot'] = FusionCharts("boxandwhisker2d", "box1" , "800", "400", "box_chart1", "json", data_source).render()
        
        
        series =[]
        data = []
        # get the demultiplexion information from the all lanes in run
        #run_lanes_default_all = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id , defaultAll = 'all')
        #for run_lane_default_all in  run_lanes_default_all :
        #    q_30_default_all, mean_default_all, yield_mb_default_all = item.get_stats_info().split(';')
        series = []
        data = []
        # get the demultiplexion information for projects included in the run
        for project_demultiplexion in p_list :
            percent_lane = []
            #import pdb; pdb.set_trace()
            for index_lane in range (1,5) :
                lanes_for_percent_graphic = NextSeqStatsLaneSummary.objects.get(runprocess_id__exact = run_id, project_id = project_demultiplexion.id, lane = index_lane )
                percent_lane.append(lanes_for_percent_graphic.percentLane)
            #for project_for_percent_graphic in projects_for_percent_graphic :
            data.append(percent_lane)    
            series.append(project_demultiplexion.projectName)

        # get the demultiplexion information for the default
        
        percent_default_lane = []
        for index_lane in range(1,5):
            default_for_percent_graphic = NextSeqStatsLaneSummary.objects.get(runprocess_id__exact = run_id, defaultAll__exact = 'default', lane =index_lane)
            percent_default_lane.append(default_for_percent_graphic.percentLane)
        series.append('Unable to identify the project')
        data.append(percent_default_lane)
        heading = 'Percentage of each project in the Run'
        sub_caption = ''
        theme = 'fint'
        x_axis_name = 'Lanes'
        y_axis_name = 'Percentage '
        categories = ['Lane 1', 'Lane 2', 'Lane 3','Lane 4']
        data_source = column_graphic_with_categories(heading, sub_caption, x_axis_name, y_axis_name, theme, categories, series, data)
        info_dict ['run_project_comparation'] = FusionCharts("mscolumn3d", "column1" , "600", "400", "column_chart1", "json", data_source).render()
        
        fl_data_display=[]
        #import pdb; pdb.set_trace()
        fl_summary_id = NextSeqStatsFlSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='all')
        fl_list = ['Cluster (Raw)', 'Cluster (PF)', 'Yield (MBases)', 'Number of Samples']
        fl_data_display.append(fl_list)
        fl_values = fl_summary_id[0].get_fl_summary().split(';')
        fl_data_display.append(fl_values)
        info_dict['fl_summary']=fl_data_display

        # prepare the data for Lane Summary
        lane_data_display = []
        lane_summary_id = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='all')
        lane_list = ['Lane', 'PF Clusters', '% of the lane','% Perfect barcode',
                    '% One mismatch barcode','Yield (Mbases)','% >= Q30 bases',
                    'Mean Quality Score']
        lane_data_display.append(lane_list)
        for lane_sum in lane_summary_id:
            lane_values = lane_sum.get_lane_summary().split(';')
            lane_data_display.append(lane_values)
        info_dict['lane_summary'] = lane_data_display

        # prepare the data for default Flowcell summary
        default_fl_data_display=[]
        #import pdb; pdb.set_trace()
        default_fl_summary_id = NextSeqStatsFlSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='default')
        default_fl_data_display.append(fl_list)
        default_fl_values = default_fl_summary_id[0].get_fl_summary().split(';')
        default_fl_data_display.append(default_fl_values)
        info_dict['default_fl_summary']=default_fl_data_display

        # prepare the data for default Lane Summary
        default_lane_data_display = []
        default_lane_summary_id = NextSeqStatsLaneSummary.objects.filter(runprocess_id__exact =run_id , project_id__isnull=True, defaultAll='default')
        default_lane_data_display.append(lane_list)
        for default_lane_sum in default_lane_summary_id:
            default_lane_values = default_lane_sum.get_lane_summary().split(';')
            default_lane_data_display.append(default_lane_values)
        info_dict['default_lane_summary'] = default_lane_data_display

        # prepare the data for top unknown barcode
        unknow_dict = {}
        for lane_un in range (4):
            lane_unknow_barcode = []
            lane_number=str(lane_un +1)

            unknow_bar_id = RawTopUnknowBarcodes.objects.filter(runprocess_id__exact =run_id , lane_number__exact = lane_number)
            #import pdb; pdb.set_trace()
            for item_id in unknow_bar_id:
                #import pdb; pdb.set_trace()
                unknow_values = item_id.get_unknow_barcodes().split(';')
                lane_unknow_barcode.append(unknow_values)
                unknow_bar_value = int(unknow_values[0].replace(',',''))
                if unknow_values[1] in unknow_dict:
                    unknow_dict [unknow_values[1]] += unknow_bar_value
                else:
                    unknow_dict [unknow_values[1]] = unknow_bar_value

            lane_number=str('unknow_bar_'+ str(lane_un))
            info_dict[lane_number] = lane_unknow_barcode
            #import pdb; pdb.set_trace()
            # keep the top 10 unknow bar by deleting the lowest values
            unknow_dict_len = len (unknow_dict)

        # create chart with the top unknown barcode in the run
        data_source = json_unknow_barcode_graphic('Unknow Sequence', unknow_dict)
        #data_source = json_unknow_barcode_graphic('Unknow Sequence', list(unknow_dict.keys()),list(unknow_dict.values()))
        unknow_pie3d = FusionCharts("pie3d", "ex1" , "600", "400", "chart-1", "json", data_source)

        info_dict ['unknow_pie3d'] = unknow_pie3d.render()

        # prepare the data to match unknow barcodes against the index base sequence
        index_match_list = []
        for key , value in unknow_dict.items():
            found_unknow_index = []
            found_unknow_index.append(key)
            index_temp = ''
            library_info = []
            #import pdb; pdb.set_trace()
            if '+' in key:
                split_base = key.split('+')

                if IndexLibraryValues.objects.filter(indexBase__exact = split_base[0]).exists():
                    libraries_using_base = IndexLibraryValues.objects.filter(indexBase__exact = split_base[0])
                    index_temp = split_base[0]
                    for library in libraries_using_base :
                        library_info.append([library.indexName,library.indexLibraryKit_id.indexLibraryName])


                if IndexLibraryValues.objects.filter(indexBase__exact = split_base[1]).exists():
                    if len(index_temp) == 1:
                        index_temp += (str (' + ' + split_base[1]))
                    else:
                        index_temp = split_base[1]
                    libraries_using_base = IndexLibraryValues.objects.filter(indexBase__exact = split_base[1])
                    for library in libraries_using_base :
                        library_info.append([library.indexName,library.indexLibraryKit_id.indexLibraryName])
                    
            else:
                if IndexLibraryValues.objects.filter(indexBase__exact = key).exists():
                    found_unknow_index.append(key)
                    libraries_using_base = IndexLibraryValues.objects.filter(indexBase__exact = key)
                    for library in libraries_using_base :
                        library_info.append([library.indexName,library.indexLibraryKit_id.indexLibraryName])

            if len (index_temp) == 0 :
                index_temp= 'Index not match '
            if len (library_info) == 0 :
                library_info = ['Index bases not found in library']
                #libraries_using_base = IndexLibraryValues.objects.filter(indexBase__exact = split_base[1])
                #for library in libraries_using_base :
                #    found_unknow_index.append(library.indexBase)
            #index_item = 5
            found_unknow_index.append(index_temp)
            found_unknow_index.append(library_info)
            index_match_list.append(found_unknow_index)
        #import pdb; pdb.set_trace()

        info_dict['match_unknows']= index_match_list

        # prepare data for Run Binary summary stats

        run_parameters = RunningParameters.objects.get(runName_id__exact = run_id)
        num_of_reads = run_parameters.get_number_of_reads ()
        index_run_summary = [i +1 for i in range(num_of_reads)]
        index_run_summary.append('Non Index')
        index_run_summary.append('Total')
        #index_run_summary = ['1','2','3','4', 'Non Index', 'Total']
        info_dict ['runSummaryHeading']= ['Level','Yield','Projected Yield','Aligned (%)','Error Rate (%)','Intensity Cycle 1','Quality >=30 (%)']
        line_description = ['Read ' +str( i+1) for i in range (num_of_reads)]
        line_description.append('Non Index')
        line_description.append('Totals')

        #line_description=['Read 1','Read 2','Read 3','Read 4','Non Index','Totals']
        line_run_summary = []
        for index in range (len(index_run_summary)):
            #import pdb; pdb.set_trace()
            run_summary_id = NextSeqStatsBinRunSummary.objects.filter(runprocess_id__exact =run_id , level__exact = index_run_summary[index])
            run_summary_values = run_summary_id[0].get_bin_run_summary().split(';')
            run_summary_values.insert(0, line_description[index])
            if index_run_summary[index] == 'Total':
                info_dict ['runSummaryTotal'] = run_summary_values
            else:
                line_run_summary.append(run_summary_values)
        #import pdb; pdb.set_trace()
        info_dict ['runSummary'] = line_run_summary

        # prepare the data for Reads Binary summary stats
        info_dict ['laneSummaryHeading']= ['Lane','Tiles','Density (K/mm2)','Cluster PF (%)','Phas/Prephas (%)',
                    'Reads (M)','Reads PF (M)','%>= Q30','Tield (G)','Cycles Err Rate',
                    'Aligned (%)','Error Rate (%)','Error Rate 35 cycle (%)',
                    'Error Rate 50 cycle (%)','Error Rate 75 cycle (%)',
                    'Error Rate 100 cycle (%)','Intensity Cycle 1']
        info_reads_dict ={}
        for read_number in range (1, num_of_reads +1) :
        #for read_number in range (1, 5):
            read_summary_values=[]
            for lane_number in range(1, 5):
                read_lane_id= NextSeqStatsBinRunRead.objects.filter(runprocess_id__exact =run_id, read__exact = read_number, lane__exact = lane_number)
                lane_values=read_lane_id[0].get_bin_run_read().split(';')
                read_summary_values.append(lane_values)
            #read_number_index = str('laneSummary'+str(read_number))
            read_number_index2 = str('Read '+str(read_number))
            info_reads_dict[read_number_index2] = read_summary_values
            #info_dict[read_number_index] = read_summary_values
        info_dict['reads']= info_reads_dict

        # prepare the graphics for the run
        folder_for_plot='/documents/wetlab/images_plot/'

        run_graphics_id = NextSeqGraphicsStats.objects.filter(runprocess_id__exact =run_id)
        folder_graphic = folder_for_plot + run_graphics_id[0].get_folder_graphic()+ '/'
        graphics = run_graphics_id[0].get_graphics().split(';')
        graphic_text= ['Data By Lane','Flow Cell Chart','Data By Cycle','QScore Heatmap','QScore Distribution','Indexing QC']
        for index_graph in range (len(graphics)):
            tmp_value = graphics[index_graph]
            graphics[index_graph] = [graphic_text[index_graph], folder_graphic + tmp_value]

        info_dict['runGraphic'] = graphics
    return info_dict

@login_required
def search_nextSeq (request):
    # check user privileges
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                allowed_all_runs = False
               #return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
            else:
                allowed_all_runs = True
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')
    #############################################################
    ## Search for runs that fullfil the input values
    #############################################################
    if request.method=='POST' and (request.POST['action']=='runsearch'):
        #import pdb; pdb.set_trace()
        run_name=request.POST['runname']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        run_state=request.POST['runstate']
        # check that some values are in the request if not return the form
        if run_name == '' and start_date == '' and end_date == '' and run_state == '':
            return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html')

        ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        ### Get all the available runs to start the filtering
        if allowed_all_runs :
            runs_found=RunProcess.objects.all().order_by('runName')
        else:
            
            user_projects = Projects.objects.filter(user_id__exact = request.user.id)
            #import pdb; pdb.set_trace()
            run_list =[]
            for user_project in user_projects :
                run_list.append(user_project.runprocess_id.id)
            #import pdb; pdb.set_trace()
            if RunProcess.objects.filter(pk__in = run_list).exists():
                runs_found = RunProcess.objects.filter(pk__in = run_list)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are not run where ', request.user.username , 'was involved' ]})

        ### Get runs when run name is not empty
        if run_name !='':
            if (RunProcess.objects.filter(runName__exact =run_name).exists()):
                run_name_found=RunProcess.objects.filter(runName__exact =run_name)
                if (len(run_name_found)>1):
                    return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Too many matches found when searching for the run name ', run_name ,
                                                                    'ADVICE:', 'Select additional filter to find the run that you are looking for']})
                r_data_display= get_information_run(run_name_found[0],run_name_found[0].id)

                return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
            #import pdb; pdb.set_trace()

            if (runs_found.filter(runName__icontains =run_name).exists()):
                runs_found=runs_found.filter(runName__icontains =run_name).order_by('runName')
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the run name ', run_name ]})

        ### Check if state is not empty
        if run_state != '':
            if runs_found.filter(runState__exact = run_state).exists():
                runs_found = runs_found.filter(runState__exact = run_state).order_by('runName')
            else :
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the run name ', run_name ,
                                                                    'and the state', run_state ]})
        ### Check if start_date is not empty
        if start_date !='' and end_date != '':

            if runs_found.filter(run_date__range=(start_date, end_date)).exists():
                 runs_found = runs_found.filter(run_date__range=(start_date, end_date))
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no runs containing ', run_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if runs_found.filter(run_date__gte = start_date).exists():
                 runs_found = runs_found.filter(run_date__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', run_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if runs_found.filter(run_date__lte = end_date).exists():
                 runs_found = runs_found.filter(run_date__lte = end_date)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', run_name,
                                        ' finish before ', end_date]})
        #If only 1 run mathes the user conditions, then get the project information

        if (len(runs_found)== 1) :
            r_data_display= get_information_run(runs_found[0],runs_found[0].id)
            #import pdb; pdb.set_trace()
            return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
        else:
            ## collect the list of run that matches the run date
            run_list=[]
            for i in range(len(runs_found)):
                run_list.append([runs_found[i],runs_found[i].id])
                #import pdb; pdb.set_trace()
            return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html', {'display_run_list': run_list })
    else:

        return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html')

@login_required
def search_nextProject (request):

    #############################################################
    ###  Find the projects that match the input values
    #############################################################

    if request.method=='POST' and (request.POST['action']=='searchproject'):
        project_name=request.POST['projectname']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        project_state=request.POST['projectstate']
        user_name = request.POST['username']
        # check that some values are in the request if not return the form
        if project_name == '' and start_date == '' and end_date == '' and user_name =='' and project_state == '':
            return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html')
        if user_name !=''  and len(user_name) <5 :
             return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The user name must contains at least 5 caracters ',
                                                                    'ADVICE:', 'write the full user name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        ### Get projects when project name is not empty
        if project_name != '' :

            if Projects.objects.filter(projectName__exact = project_name).exists():
                project_id = Projects.objects.get (projectName__exact = project_name).id
                project_found_id = Projects.objects.get(pk=project_id)
                p_data_display  = get_information_project(project_found_id, request)
                return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html', {'display_one_project': p_data_display })
            if  Projects.objects.filter (projectName__contains = project_name).exists():
                #import pdb; pdb.set_trace()
                projects_found = Projects.objects.filter (projectName__contains = project_name)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No Project found with the string , ', project_name ]})
        ### if there is no project name, then get all which will be filtered by other conditions set by user
        #import pdb; pdb.set_trace()
        if project_name == '':
            projects_found = Projects.objects.all()
                # check if user name is not empty
        if user_name != '':
            if User.objects.filter(username__icontains = user_name).exists():
                r_name_id = User.objects.get(username__icontains = user_name).id
                if projects_found.filter(user_id__exact =r_name_id).exists():
                    projects_found = projects_found.filter(user_id__exact =r_name_id)
                else:
                     return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The Project found does not belong to the user, ', user_name ]})
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The Project found does not belong to the user, ', user_name ]})

                    # check if the date in the form match in project database
        if (project_state !='' ):
            if projects_found.filter(procState__exact = project_state):
                projects_found = projects_found.filter(procState__exact = project_state)
            else :
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There ane not Projects containing ', project_name,
                                               'in state', project_state ]})
        if start_date !='' and end_date != '':

            if projects_found.filter(project_run_date__range=(start_date, end_date)).exists():
                 projects_found = projects_found.filter(project_run_date__range=(start_date, end_date))
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if projects_found.filter(project_run_date__gte = start_date).exists():
                 projects_found = projects_found.filter(project_run_date__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if projects_found.filter(project_run_date__lte = end_date).exists():
                 projects_found = projects_found.filter(project_run_date__lte = end_date)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', project_name,
                                        ' finish before ', end_date]})
        #If only 1 project mathes the user conditions, then get the project information

        if len (projects_found) == 1:
            project_id = projects_found[0].id
            project_found_id = Projects.objects.get(pk=project_id)
            p_data_display  = get_information_project(project_found_id, request)
            return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html', {'display_one_project': p_data_display })
        else :
            # Display a list with all projects that matches the conditions
            project_list_dict = {}
            project_list = []
            for project in projects_found :
                p_name = project.get_project_name()
                p_name_id = project.id
                project_list.append([p_name, p_name_id])
            project_list_dict ['projects'] = project_list
            return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html', {'display_project_list': project_list_dict })


    else:
    #import pdb; pdb.set_trace()
        return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html')


def get_info_sample (sample_id):
    sample_info_dict ={}
    #collect the general information from the Sample
    sample_info_dict['sample_name'] = sample_id.sampleName
    sample_info_dict['project_name'] = sample_id.get_project_name()
    project_id= sample_id.project_id.id
    sample_info_dict['project_id'] = project_id
    #import pdb; pdb.set_trace()
    sample_info_dict['run_id'] = sample_id.project_id.runprocess_id.id
    sample_info_dict['run_name'] = sample_id.project_id.runprocess_id.runName
    user_name_id = sample_id.project_id.user_id
    sample_info_dict['investigator_name'] = user_name_id.username
    # collect the Sample information
    sample_info_dict['heading_samples_info'] = ['Sample', 'Barcode', 'PF Cluster', '% of Project','Yield (Mbases)','>= Q30 bases','Mean Quality Score']
    sample_info_dict['data_samples_info'] = sample_id.get_sample_information().split(';')
    # Quality graphic
    quality_sample = sample_id.get_quality_sample()
    heading_chart_quality = 'Quality for the Sample ' + sample_id.sampleName
    data_source = graphic_for_quality_angular(heading_chart_quality, quality_sample)
    quality_sample_angular = FusionCharts("angulargauge", "ex1" , "350", "200", "chart-1", "json", data_source)
    sample_info_dict['quality_chart1'] = quality_sample_angular.render()
    percentage_in_project ={}
    samples_in_project = SamplesInProject.objects.filter(project_id__exact = project_id)
    for sample in samples_in_project:
        percentage_in_project[sample.sampleName] = sample.percentInProject
    heading_samples_in_project = 'Samples belonging to the same project'
    sub_caption = ''
    x_axis_name = 'Samples in project ' + sample_id.get_project_name()
    y_axis_name = '% of Project '
    theme = 'fint'
    data_source = column_graphic_samples_in_project (heading_samples_in_project, sub_caption, x_axis_name, y_axis_name, theme, percentage_in_project, sample_id.sampleName)
    #import pdb; pdb.set_trace()
    percentage_chart = FusionCharts("column3d", 'samplesProject' , "750", "300", 'samples-chart-2', "json", data_source)
    sample_info_dict['percentage_chart'] = percentage_chart.render()
    return sample_info_dict


@login_required
def search_nextSample (request):
    #############################################################
    ###  Find the projects that match the input values
    #############################################################

    if request.method=='POST' and (request.POST['action']=='searchsample'):
        sample_name=request.POST['samplename']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        user_name = request.POST['username']

        # check that some values are in the request if not return the form
        if user_name == '' and start_date == '' and end_date == '' and sample_name =='':
            return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html')

        if user_name !=''  and len(user_name) <5 :
             return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The user name must contains at least 5 caracters ',
                                                                    'ADVICE:', 'write the full user name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        ### Get projects when sample name is not empty
        if sample_name != '' :

            if SamplesInProject.objects.filter(sampleName__exact = sample_name).exists():
                sample_found = SamplesInProject.objects.filter(sampleName__exact = sample_name)
                if len(sample_found) == 1:
                    # get information from the sample found
                    ########################################
                    sample_data_information = get_info_sample (sample_found[0])
                    return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html',{'display_one_sample': sample_data_information })
            elif SamplesInProject.objects.filter(sampleName__contains = sample_name).exists():
                sample_found = SamplesInProject.objects.filter(sampleName__contains = sample_name)
                #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No sample found with the string , ', sample_name ]})

        ### if there is no project name, then get all which will be filtered by other conditions set by user
        #import pdb; pdb.set_trace()
        else :
            sample_found = SamplesInProject.objects.all()
        # Check the start and end date
        if start_date !='' and end_date != '':

            if sample_found.filter(generated_at__range=(start_date, end_date)).exists():
                 sample_found = sample_found.filter(generated_at__range=(start_date, end_date))
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if sample_found.filter(generated_at__gte = start_date).exists():
                 sample_found = sample_found.filter(generated_at__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if sample_found.filter(generated_at__lte = end_date).exists():
                 sample_found = sample_found.filter(generated_at__lte = end_date)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Projects containing ', sample_name,
                                        ' finish before ', end_date]})
                # check if user name is not empty
        if user_name != '':
            #import pdb; pdb.set_trace()
            if User.objects.filter(username__contains = user_name).exists():
                users = User.objects.filter (username__contains = user_name)
                if len(users) == 1:
                    user_id= users[0].id
                    project_id_list = Projects.objects.prefetch_related('user_id').filter(user_id = user_id)
                    sample_found = sample_found.filter(project_id__in = project_id_list)

                else:
                    text_error= 'There are too many users names containing ' + sample_name  + '  which match your query'
                    return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[text_error,
                                        'ADVICE:', 'Fill in the user name field the full name of the user' ]})

                #r_name_id = User.objects.get(username__icontains = user_name).id

            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The samples found did not belong to the user, ', user_name ]})

        if len(sample_found) == 0:
            text_error = 'User ' + user_name +' does not have yet any samples'
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[text_error,
                            'ADVICE:', 'Contact with your administrator to find out the reason for not matching any result' ]})
        if len(sample_found) == 1:
            sample_data_information = get_info_sample (sample_found[0])
            return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html',{'display_one_sample': sample_data_information })

        else:
            sample_list= {}
            s_list  = {}
            for sample in sample_found:
                sample_project =  sample.get_project_name()
                s_list [sample.id] = [[sample.sampleName, sample_project]]
            sample_list ['s_list'] = s_list

            #import pdb; pdb.set_trace()

            return render (request, 'iSkyLIMS_wetlab/SearchNextSample.html', {'multiple_samples': sample_list})
    else:
    #import pdb; pdb.set_trace()
        return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html')

'''
        if len(project_id_list) == 1:

            # get the project  name for the match
            #import pdb; pdb.set_trace()
            project_name = Projects.objects.get(pk = project_id_list[0].id).get_project_name()

            sample_found_count = sample_found.count()
            if sample_found_count == 1:
                sample_data_information = get_sample_information (sample_found.id)
                return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html',{'display_one_sample': sample_data_information })

            elif sample_found_count < 20 :
                multiple_samples ={}
                multiple_samples['project_name'] = project_name
                samples_list_in_project =[]
                #import pdb; pdb.set_trace()
                for sample_item in sample_found :
                    sample_name = sample_item.get_sample_name()
                    sample_id = sample_item.id
                    samples_list_in_project.append([sample_name, sample_id])
                multiple_samples['samples'] = samples_list_in_project
                return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html',{'multiple_sample_one_project': multiple_samples })
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are too many samples that match your query',
                            'ADVICE:', 'Include more caracters in the Sample Name field']})
        return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html')
'''

@login_required
def search_run (request, run_id):
    # check user privileges
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                # check if user is owner of the run
                if Projects.objects.filter(runprocess_id__exact = run_id).exists():
                    projects = Projects.objects.filter(runprocess_id__exact = run_id)
                    user_list =[]
                    for project in projects:
                        user_list.append(project.user_id.id)
                    
                    if  not request.user.id in user_list :
                        import pdb; pdb.set_trace()

                        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})

                else:
                    return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the run  ']})
                    
                #return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            import pdb; pdb.set_trace()
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    #import pdb; pdb.set_trace()
    if (RunProcess.objects.filter(pk=run_id).exists()):
        run_name_found = RunProcess.objects.filter(pk=run_id)
        r_data_display  = get_information_run(run_name_found[0],run_id)
        return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the run  ']})

@login_required
def latest_run (request) :
    # check user privileges
    if request.user.is_authenticated:

        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    latest_run = RunProcess.objects.order_by('id').last()
    #import pdb; pdb.set_trace()
    run_id = latest_run.id
    r_data_display  = get_information_run(latest_run,run_id)
    return render(request, 'iSkyLIMS_wetlab/SearchNextSeq.html', {'display_one_run': r_data_display })

@login_required
def incompleted_runs (request) :
    # check user privileges
    if request.user.is_authenticated:

        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    if RunProcess.objects.all().exclude(runState = 'Completed').exists() :
        display_incomplete_run_list = {}
        unfinished_runs = RunProcess.objects.all().exclude(runState = 'Completed').order_by('runName')
        for run in unfinished_runs:
            display_incomplete_run_list[run.id] = [[run.runName, run.get_state()]]
    else:
        return render (request,'iSkyLIMS_wetlab/info_page.html', {'content':['There is no project in incompleted state' , 'All Runs are finished']})

    return render (request, 'iSkyLIMS_wetlab/incompletedRuns.html',{'display_incomplete_run_list':display_incomplete_run_list})


#### login not required because is called from internal function
def get_information_project (project_id, request):
    project_info_dict = {}
    p_data = []
    project_info_dict['project_id'] = project_id.id
    project_info_text = ['Project Name','Library Kit','File to upload to BaseSpace','Project Recorder date', 'Project date','Run name']
    project_values = project_id.get_project_info().split(';')
    run_name = project_id.runprocess_id.runName
    groups = Group.objects.get(name='WetlabManager')
    #import pdb; pdb.set_trace()
    if groups not in request.user.groups.all():
        project_info_dict['run_id'] = ''
    else:
        project_info_dict['run_id'] = project_id.runprocess_id.id
    project_values.append(run_name )
    for item in range(len(project_info_text)):
        p_data.append([project_info_text[item], project_values[item]])
    project_info_dict['p_data'] = p_data
    #import pdb; pdb.set_trace()
    project_info_dict ['user_name'] = project_id.get_user_name()
    p_state = project_id.get_state()
    project_info_dict['state'] = p_state
    if p_state.startswith('ERROR'):
        project_info_dict['graphic_value']=10
        project_info_dict['graphic_color']='red'
    if p_state == 'Recorded':
        project_info_dict['graphic_value']=25
        project_info_dict['graphic_color']='violet'
    if p_state == 'Sample Sent':
        project_info_dict['graphic_value']= 50
        project_info_dict['graphic_color']='brown'
    if p_state == 'B2FqExecuted':
        project_info_dict['graphic_value']= 75
        project_info_dict['graphic_color']='yellow'
    if p_state == 'Completed':
        project_info_dict['graphic_value']= 100
        project_info_dict['graphic_color']='green'
        fl_data_display=[]
        #import pdb; pdb.set_trace()
        # prepare the data for Flowcell Summary
        fl_summary_id = NextSeqStatsFlSummary.objects.get(project_id__exact = project_id)
        fl_list = ['Cluster (Raw)', 'Cluster (PF)', 'Yield (MBases)', 'Number of Samples']
        fl_data_display.append(fl_list)
        fl_values = fl_summary_id.get_fl_summary().split(';')
        fl_data_display.append(fl_values)
        project_info_dict['fl_summary']=fl_data_display

        # prepare the data for Lane Summary
        lane_data_display = []
        lane_summary_id = NextSeqStatsLaneSummary.objects.filter(project_id__exact = project_id)
        lane_list = ['Lane', 'PF Clusters', '% of the lane','% Perfect barcode',
                    '% One mismatch barcode','Yield (Mbases)','% >= Q30 bases',
                    'Mean Quality Score']
        lane_data_display.append(lane_list)
        for lane_sum in lane_summary_id:
            lane_values = lane_sum.get_lane_summary().split(';')
            lane_data_display.append(lane_values)
        project_info_dict['lane_summary'] = lane_data_display

        # prepare the data for sample information

        sample_found_list = SamplesInProject.objects.filter(project_id__exact = project_id)
        sample_heading_list = ['Sample','Barcode','PF Clusters','Percent of Project', 'Yield (Mbases)','% >= Q30 bases', 'Mean Quality Score']
        project_info_dict['sample_heading'] = sample_heading_list
        sample_list ={}
        for sample_item in sample_found_list :
        #for sample_item in range(len(sample_found_list)) :
            sample_line = sample_item.get_sample_information().split(';')

            #sample_line = sample_found_list[sample_item].get_sample_information().split(';')
            #sample_list.append(sample_line)
            sample_list[sample_item.id] = [sample_line]
        #import pdb; pdb.set_trace()
        project_info_dict['sample_table'] = sample_list
    return project_info_dict

def check_user_access (request, project_found_id ) :

    groups = Group.objects.get(name='wetlabManager')
    # check if user belongs to WetlabManager . If true allow to see the page
    if groups not in request.user.groups.all():
        #check if project belongs to the same user as the one requesting the page
        if project_found_id.user_id.id != request.user.id :
           return False
    return True

def check_user_group (request, group_name):
    group = Group.objects.get(name=group_name)
    if group not in request.user.groups.all():
        return False
    return True

@login_required
def search_project (request, project_id):

    if (Projects.objects.filter(pk=project_id).exists()):
        project_found_id = Projects.objects.get(pk=project_id)
        if request.user.is_authenticated:
            # check that user is allow to make the change
            allowed_access = check_user_access (request, project_found_id)
            if not allowed_access :
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        else:
            #redirect to login webpage
            return redirect ('/accounts/login')
        # Display the proyect information
        p_data_display  = get_information_project(project_found_id, request)
        return render(request, 'iSkyLIMS_wetlab/NextSearchProject.html', {'display_one_project': p_data_display })
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the project  ' ]})

@login_required
def search_sample (request, sample_id):

    if (SamplesInProject.objects.filter(pk=sample_id).exists()):
        sample_found_id = SamplesInProject.objects.get(pk=sample_id)
        sample_data_information = get_info_sample (sample_found_id)
        return render(request, 'iSkyLIMS_wetlab/SearchNextSample.html',{'display_one_sample': sample_data_information })
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the sample  ' ]})


def index_library_information (index_library_id) :

    index_library_dict ={}
    index_library_found = IndexLibraryKit.objects.get(pk=index_library_id)
    general_information = [index_library_found.get_index_library_information().split(';')]
    index_library_dict['general_information'] = general_information

    if IndexLibraryValues.objects.filter(indexLibraryKit_id__exact = index_library_id).exists():
        index_list = IndexLibraryValues.objects.filter(indexLibraryKit_id__exact = index_library_id)

        I7_indexes, I5_indexes = [], []
        for index in index_list :
            # get all I7 index defined on the library
            if index.indexNumber == 'I7':
                I7_indexes.append(index.get_index_information().split(';'))
            elif index.indexNumber == 'I5':
                #get all I5 index defined on the library
                I5_indexes.append(index.get_index_information().split(';'))
            else:
                pass
        index_library_dict['I7_indexes'] = I7_indexes
        index_library_dict['I5_indexes'] = I5_indexes
        return index_library_dict
    else:
        return False



@login_required
def display_index_library (request, index_library_id):
    if (IndexLibraryKit.objects.filter(pk=index_library_id).exists()) :

        index_library_dict = index_library_information (index_library_id)
        if index_library_dict != False:
            return render (request, 'iSkyLIMS_wetlab/DisplayIndexLibrary.html', {'display_one_index_library': index_library_dict})
        else:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are recorded information for the index library for ',  index_library_id]})

    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for the index Library  ' ]})




@login_required
def search_index_library (request):

    if request.method == 'POST' and (request.POST['action'] == 'searchindexlibrary') :
        index_library_name=request.POST['indexlibraryname']
        adapter_1=request.POST['adapter1']
        adapter_2=request.POST['adapter2']
        index_name=request.POST['indexname']
        index_base=request.POST['indexbase']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']

        # check that some values are in the request if not return the form
        if index_library_name == '' and start_date == '' and end_date == '' and adapter_1 =='' and adapter_2 == '' and index_name == '' and index_base == '' :
            return render(request, 'iSkyLIMS_wetlab/searchIndexLibrary.html')

        if index_base !=''  and len(index_base) < 6 :
             return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Index Sequence must contains at leat 6  caracters ']})
        ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (DD-MM-YYYY)']})

        index_library_found = IndexLibraryKit.objects.all()
        if index_library_name != '':
            if index_library_found.filter(indexLibraryName__contains = index_library_name).exists():
                index_library_found = index_library_found.filter(indexLibraryName__contains = index_library_name)
                if len (index_library_found) == 1:
                    index_library_dict = index_library_information (index_library_found[0].id)
                    if index_library_dict != False:
                        return render (request, 'iSkyLIMS_wetlab/DisplayIndexLibrary.html', {'display_one_index_library': index_library_dict})
                    else:
                        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no recorded information for the index library for ',  index_library_id]})
        if adapter_1 != '':
            if index_library_found.filter(adapter1__contains =adapter_1).exists():
                index_library_found = index_library_found.filter(adapter1__contains =adapter_1)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries contaning Adapter 1 ', adapter_1]})
        if adapter_2 != '':
            if index_library_found.filter(adapter1__contains =adapter_2).exists():
                index_library_found = index_library_found.filter(adapter2__contains =adapter_2)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries contaning Adapter 2 ', adapter_2]})



        # Check the start and end date
        if start_date !='' and end_date != '':

            if index_library_found.filter(generatedat__range=(start_date, end_date)).exists():
                 index_library_found = index_library_found.filter(generatedat__range=(start_date, end_date))
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries ',
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if index_library_found.filter(generatedat__gte = start_date).exists():
                 index_library_found = index_library_found.filter(generatedat__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries ',
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if index_library_found.filter(generatedat__lte = end_date).exists():
                 index_library_found = index_library_found.filter(generatedat__lte = end_date)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries ',
                                        ' finish before ', end_date]})

        if index_name != '':
            if IndexLibraryValues.objects.filter(indexName__exact =index_name).exists():
                index_name_list = IndexLibraryValues.objects.prefetch_related('indexLibraryKit_id').filter(indexName = index_name)
                index_library_found = index_library_found.filter(indexlibraryvalues__in = index_name_list)

                #index_library_found = index_library_found.filter(
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries contaning index_name ', index_name]})

        if index_base != '':
            if IndexLibraryValues.objects.filter(indexBase__exact =index_base).exists():
                index_base_list = IndexLibraryValues.objects.prefetch_related('indexLibraryKit_id').filter(indexBase = index_base)
                index_library_found = index_library_found.filter(indexlibraryvalues__in = index_base_list)
                #index_library_found = index_library_found.filter(
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no libraries contaning Base Sequence ', index_base]})

        if len(index_library_found) == 1 :
            index_library_dict = index_library_information (index_library_found[0].id)
            if index_library_dict != False:
                return render (request, 'iSkyLIMS_wetlab/DisplayIndexLibrary.html', {'display_one_index_library': index_library_dict})
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no recorded information for the index library for ',  index_library_id]})

        else:
            # generate the list with all library that matches conditions
            index_library_dict = {}
            index_values = []
            for index_library in index_library_found:
                values = []
                values.append(index_library.id)
                values.append(index_library.indexLibraryName)
                values.append(index_library.version)
                index_values.append(values)
            index_library_dict['index_values'] = index_values

            return render (request, 'iSkyLIMS_wetlab/searchIndexLibrary.html', {'display_list_index_library': index_library_dict})


    else:
        return render (request, 'iSkyLIMS_wetlab/searchIndexLibrary.html')


@login_required
def change_run_name (request, run_id):
    if RunProcess.objects.filter(pk=run_id).exists():
        run = RunProcess.objects.get(pk = run_id)
        if not request.user.is_authenticated :
            return redirect ('/accounts/login')
        # check if user is allow to make the change
        groups = Group.objects.get(name='WetlabManager')
        # check if user belongs to WetlabManager . If true allow to see the page
        if groups not in request.user.groups.all():
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        if request.method == 'POST' and request.POST['action'] == 'change_run_name':
            new_run_name = request.POST['runName']
            if new_run_name == '':
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Empty value is not allowed for the Run Name ']})
            if RunProcess.objects.filter(runName__exact = new_run_name).exists():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The given Run Name is already in use', 'Go back to the previous page and change the run name']})
            changed_run_name ={}
            old_run_name = run.runName
            run.runName = new_run_name
            run.save()
            changed_run_name ['new_run_name'] = [[new_run_name, run_id]]
            changed_run_name ['old_run_name'] = old_run_name

            return render (request, 'iSkyLIMS_wetlab/ChangeRunName.html', {'changed_run_name': changed_run_name})
        else:
            form_change_run_name ={}
            form_change_run_name['run_name'] = run.runName
            return render (request, 'iSkyLIMS_wetlab/ChangeRunName.html', {'form_change_run_name':form_change_run_name})
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There is no Run for your query  ' ]})

@login_required
def change_project_libKit (request, project_id) :
    # check if project exists
    if Projects.objects.filter(pk = project_id).exists():
        project = Projects.objects.get(pk = project_id)
        if not request.user.is_authenticated:
            #redirect to login webpage
            return redirect ('/accounts/login')
        # check that user is allow to make the change
        allowed_access = check_user_access (request, project)
        if not allowed_access :
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})


        if request.method == 'POST' and request.POST['action'] == 'change_project_libKit':
            new_library_name = request.POST['projectlibkit']
            old_library_name = project.get_library_name()
            if old_library_name == new_library_name :
                return render (request, 'iSkyLIMS_wetlab/info_page.html', {'content': ['The library kit from the input text is the same to the existing defined for this project', 'No change is done']})
            # check if there is no other project in the same Run with the same Library Kit
            # if the library is shared with other project then error message is displayed

            if not check_user_group (request, 'WetlabManager') :
                project_run_id = project.runprocess_id.id
                project_lib_kit = project.libraryKit
                if Projects.objects.filter(runprocess_id = project_run_id).exclude(pk = project_id).exists():
                    all_project_with_same_run_id = Projects.objects.filter(runprocess_id = project_run_id).exclude(pk = project_id)
                    # there are more than 1 project on the same Run.
                    # check if these projects have in common the same library kit
                    other_lib_kits = []
                    for other_project in all_project_with_same_run_id:
                        other_lib_kits.append(other_project.libraryKit)
                    if  project_lib_kit in other_lib_kits:
                        message = str('The library Kit ' + old_library_name + 'is shared with other projects in the same Run ')
                        import pdb; pdb.set_trace()
                        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[message, '', 'Contact with your administrator .']})
            old_lib_kit_file = project.baseSpaceFile
            new_file_name = new_library_name.replace(' ' , '_')
            #import pdb; pdb.set_trace()
            new_file = update_library_kit_field(old_lib_kit_file,new_file_name,new_library_name)
            if new_file == 'ERROR':
                return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['']})
            # update the database with new file
            project.baseSpaceFile = new_file
            project.libraryKit = new_library_name
            project.save()
            # Preparing the data to show in the web page
            new_file = project.baseSpaceFile
            change_library_kit_dict ={}
            change_library_kit_dict['project']= project.projectName
            change_library_kit_dict['library_name'] = new_library_name
            change_library_kit_dict['file_to_download'] = new_file

            #import pdb; pdb.set_trace()
            return render (request, 'iSkyLIMS_wetlab/ChangeProjectLibraryKit.html',{'changed_lib_kit':change_library_kit_dict})
        else:
            form_change_lib_kit ={}
            project_data =[]
            project_name = project.projectName
            form_change_lib_kit['project_name'] = project_name

            project_info_text = ['Run Name', 'Project Name', 'Project date', 'User Name', 'Library Kit']
            project_values = project.get_p_info_change_library().split(';')

            for item in range (len(project_info_text)):
                project_data.append([project_info_text[item], project_values[item]])
                form_change_lib_kit['project_data'] = project_data
            return render (request, 'iSkyLIMS_wetlab/ChangeProjectLibraryKit.html',{'form_change_lib_kit': form_change_lib_kit})
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No project has been found for changing the library Kit ' ]})


@login_required
def change_run_libKit (request, run_id):
    #check if run exist
    if RunProcess.objects.filter(pk = run_id).exists():
        run = RunProcess.objects.get(pk = run_id)
        if not request.user.is_authenticated :
            return redirect ('/accounts/login')
        # check if user is allow to make the change
        groups = Group.objects.get(name='WetlabManager')
        # check if user belongs to WetlabManager . If true allow to see the page
        if groups not in request.user.groups.all():
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        if request.method == 'POST' and request.POST['action'] == 'change_run_libKit':
            new_library_kit = request.POST.getlist('runlibraryKit')
            projects_name = request.POST.getlist('projectInRun')
            changed_lib_kit_dict = {}

            # check if there is only one library kit associated to the run
            if len(new_library_kit) == 1 :
                # Check if new library kit was set in the form
                project = Projects.objects.get(projectName__exact = projects_name[0])
                old_library_kit = project.get_library_name()
                if new_library_kit[0] == old_library_kit :
                    return render (request, 'iSkyLIMS_wetlab/info_page.html', {'content': ['The library kit from the input text is the same to the existing defined for this project', 'No change is done']})
                # change the library name
                old_lib_kit_file = project.baseSpaceFile
                new_file_name = new_library_kit[0].replace(' ' , '_')
                #import pdb; pdb.set_trace()

                new_file = update_library_kit_field(old_lib_kit_file,new_file_name,new_library_kit[0])
                if new_file == 'ERROR':
                    return render (request, 'iSkyLIMS_wetlab/error_page.html', {'content':['']})
                # update the database with new file
                project.baseSpaceFile = new_file
                project.libraryKit = new_library_kit[0]
                project.save()

            else:
                old_files_to_be_deleted = []
                # check if any of the library has change
                need_to_be_updated = False
                for item in range(len(projects_name)):
                    project = Projects.objects.get(projectName__exact = projects_name[item])
                    old_library_kit = project.libraryKit
                    # get the library kit file name to delete it later
                    old_file = project.baseSpaceFile
                    # build the list to delete later the old library kit files
                    if old_file not in old_files_to_be_deleted :
                        old_files_to_be_deleted.append(old_file)
                    if new_library_kit[item] != old_library_kit:
                        need_to_be_updated = True
                if not need_to_be_updated:
                    return render (request, 'iSkyLIMS_wetlab/info_page.html', {'content': ['The library kits from the input text are the same to the existing ones defined for the Run', 'No change is done']})
                # get the Sample Sheet file related to the run
                sample_file = run.get_sample_file()

                lib_kit_dict = {}
                in_file=str('documents/' + sample_file)
                #import pdb; pdb.set_trace()
                ## build the project list for each library kit
                for x in range(len(new_library_kit)):
                    if new_library_kit[x] in lib_kit_dict :
                        lib_kit_dict[new_library_kit[x]].append(projects_name[x])
                    else:
                        lib_kit_dict[new_library_kit[x]]= [projects_name[x]]

                ## convert the sample sheet to base space format and have different files according the library kit
                #import pdb; pdb.set_trace()

                for key, value in lib_kit_dict.items():
                    lib_kit_file =key.replace(' ', '_')
                    library_file = sample_sheet_map_basespace(in_file, key, lib_kit_file, value,'Plate96')
                    if library_file == 'ERROR':
                        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':[ 'The information on  the Library kit ', key,' For the project ', value,
                          'could not be changed to the new value of the library kit ','ADVICE', 'Contact your administrator']})
                    for updated_project_name in value :
                        p_updated = Projects.objects.get(projectName__exact = updated_project_name)
                        p_updated.libraryKit = key
                        p_updated.baseSpaceFile = library_file
                        p_updated.save()
                # delete old library kit files
                for delete_file in old_files_to_be_deleted :
                    os.remove(delete_file)
                # prepare the information to be displayed
            changed_lib_kit_dict = {}
            run_data = {}
            for item in range(len(projects_name)) :
                project = Projects.objects.get(projectName__exact = projects_name[item])
                p_name =project.projectName
                lib_name = project.libraryKit
                lib_file = project.baseSpaceFile
                run_data[p_name] = ([[lib_name, lib_file]])

            changed_lib_kit_dict['run_name'] = run.get_run_name()
            changed_lib_kit_dict['run_data'] = run_data

            return render (request, 'iSkyLIMS_wetlab/ChangeRunLibraryKit.html',{'changed_lib_kit': changed_lib_kit_dict})

        else:
            form_change_lib_kit = {}
            run_library_data = []
            project_list = []
            #library_kit_list = []
            library_kit_dict = {}
            form_change_lib_kit['run_name'] = run.get_run_name()
            # get the projects and the library Kits used in each project
            project_list = Projects.objects.filter(runprocess_id = run_id)
            for project in project_list :
                lib_kit = project.libraryKit
                run_library_data.append([project.projectName, lib_kit])
                if lib_kit in library_kit_dict :
                    library_kit_dict[project.libraryKit].append(project.projectName)
                else :
                    library_kit_dict[project.libraryKit] = [project.projectName]

            form_change_lib_kit['run_data'] = library_kit_dict
            form_change_lib_kit['run_library_data'] = run_library_data

            return render (request, 'iSkyLIMS_wetlab/ChangeRunLibraryKit.html',{'form_change_lib_kit': form_change_lib_kit})
    else:
        return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No run has been found for changing the library Kit ' ]})

@login_required
def next_seq_stats_experiment (request):
    return render (request, 'iSkyLIMS_wetlab/NextSeqStatistics.html', {})

@login_required
def nextSeqStats_per_researcher (request):
    if request.method == 'POST':

        #import pdb; pdb.set_trace()
        r_name = request.POST['researchername']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']

        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "From Start Date" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date !='' :
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if len(r_name) < 5 :
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['researcher name is too sort fo fined a match', 'Name must be at least 6 characters long'
                                                            'ADVICE:', 'write a longer name in the researcher field ']})

        if User.objects.filter(username__icontains = r_name).exists():
            r_name = User.objects.get(username__icontains = r_name).username
            r_name_id = User.objects.get(username__icontains = r_name).id
            #import pdb; pdb.set_trace()
            if Projects.objects.filter(user_id__exact =r_name_id).exists():
                if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed").exists():
                    r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed")

                # check if start and end date are present in the form
                    if start_date != '' and end_date !='':
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__range=(start_date, end_date)).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__range=(start_date, end_date))
                            #r_project_by_researcher = r_project_by_researcher.filter(generatedat__range=(start_date, end_date))
                        else:
                            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'starting date  = ', start_date, 'and with ending date = ', end_date,
                                                                'ADVICE:', 'Contact with your administrator']})
                    if start_date != '' and end_date =='':
                        end_date = str(datetime.datetime.now().date())
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__range=(start_date, end_date)).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__range=(start_date, end_date))
                        else:
                            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'starting date  = ', start_date,
                                                                'ADVICE:', 'Contact with your administrator']})
                    if start_date == '' and end_date !='':
                        if Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__lte= end_date).exists():
                            r_project_by_researcher = Projects.objects.filter(user_id__exact =r_name_id, procState__exact = "Completed", project_run_date__lte = end_date)
                        else:
                            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Researcher does not have projects associated for the period ',
                                                    'ending date  = ', end_date,
                                                                'ADVICE:', 'Contact with your administrator']})


                    if len (r_project_by_researcher) ==1:
                        # get researcher_project id
                        researcher_project_id = Projects.objects.get(user_id__exact =r_name_id, procState__exact = "Completed").id
                        project_name = r_project_by_researcher[0].get_project_name()
                        r_name = r_project_by_researcher[0].get_user_name()
                        #import pdb; pdb.set_trace()
                        # fetch percent of Q>30 and mean_q for all projects per lane to create the median
                        # to be compared with the percent of this project
                        q_30_media, mean_q_media = [] , []
                        q_30_media_in_float, mean_q_media_in_float = [] , []
                        for lane in range (1,5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane).exclude(defaultAll__isnull = False).exclude (project_id__exact = researcher_project_id)
                            q_30_list , mean_q_list = [] , []
                            for item_lane in found_lane:
                                q_30_value, mean_q_value , yield_mb , cluster_pf = item_lane.get_stats_info().split(';')
                                q_30_list.append(float(q_30_value))
                                mean_q_list.append(float(mean_q_value))
                            #import pdb; pdb.set_trace()

                            q_30_media.append(format(statistics.mean (q_30_list), '.2f'))
                            q_30_media_in_float.append(statistics.mean (q_30_list))

                            mean_q_media.append(format(statistics.mean (mean_q_list), '.2f'))
                            mean_q_media_in_float.append(statistics.mean (mean_q_list))
                        overall_q30_average = format(statistics.mean(q_30_media_in_float), '.2f')
                        overall_mean_average = format(statistics.mean(mean_q_media_in_float), '.2f')

                        # fetch the Q>30 and mean_q for the researcher project per lane
                        q_30_project_lane, mean_q_project_lane = [] , []
                        for lane in range (1, 5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane , project_id__exact = researcher_project_id )
                            #import pdb; pdb.set_trace()
                            q_30_value, mean_q_value , yield_mb, cluster_pf  = found_lane[0].get_stats_info().split(';')
                            q_30_project_lane.append(float(q_30_value))
                            mean_q_project_lane.append(float(mean_q_value))
                        user_q30_average = format(statistics.mean(q_30_project_lane), '.2f')
                        user_mean_average = format(statistics.mean(mean_q_project_lane), '.2f')
                        #import pdb; pdb.set_trace()
                        heading = 'Comparison of bases with Q value bigger than 30'
                        x_axis_name = 'Lanes'
                        y_axis_name = 'Q > 30 (in %)'

                        data_source = researcher_project_mean_column_graphic(heading, x_axis_name, y_axis_name , q_30_project_lane , q_30_media, user_q30_average,overall_q30_average, r_name)

                        #data_source = json_2_column_graphic('Comparison of bases with Q value bigger than 30', q_30_project_lane,q_30_media)
                        q_30_mscol2D = FusionCharts("mscolumn3d", "ex1" , "600", "400", "chart-1", "json", data_source)
                        heading = 'Comparison of bases with Mean Quality'
                        y_axis_name = 'Mean in %'

                        data_source = researcher_project_mean_column_graphic(heading, x_axis_name, y_axis_name , mean_q_project_lane , mean_q_media, user_mean_average, overall_mean_average, r_name)
                        #data_source = json_2_column_graphic('Comparison of mean Quality Score', mean_q_project_lane,mean_q_media)
                        mean_q_mscol2D = FusionCharts("mscolumn3d", "ex2" , "600", "400", "chart-2", "json", data_source)
                        #import pdb; pdb.set_trace()
                        project_chart ={}
                        project_chart ['project_name'] = project_name
                        project_chart ['user_name'] = r_name
                        project_chart ['q_30_chart'] = q_30_mscol2D.render()
                        project_chart ['mean_q_chart'] = mean_q_mscol2D.render()
                        #import pdb; pdb.set_trace()
                        # returning complete JavaScript and HTML code, which is used to generate chart in the browsers.
                        return  render(request, 'iSkyLIMS_wetlab/NextSeqStatsPerResearcher.html', {'researcher_one_project' : project_chart})

                    else:
                        researcher_statistics = {}
                        project_names = []
                        theme_q30 = 'ocean'
                        theme_mean ='zune'
                        mean_q_researcher_graph, q30_researcher_graph = {} , {}
                        for project_researcher in r_project_by_researcher:
                            p_name = project_researcher.get_project_name()
                            project_names.append(p_name)
                        q30_user_stats, mean_user_stats = [] , []
                        # get the lane vales for all projects where user was involved
                        for lane in range (1,5):
                            q_30_dict, mean_q_dict = {} , {}
                            q30_lane_stats, mean_lane_stats = [] , []
                            q30_media_in_float , mean_media_in_float = [] , []
                            for project_researcher in r_project_by_researcher:
                                p_name = project_researcher.get_project_name()
                                r_project_id = project_researcher.id
                                data_lane = NextSeqStatsLaneSummary.objects.get(lane__exact = lane, project_id__exact = r_project_id)
                                q_30_value, mean_q_value , yield_mb , cluster_pf = data_lane.get_stats_info().split(';')
                                q_30_dict[p_name] = float(q_30_value)
                                q30_lane_stats.append(float(q_30_value))
                                mean_q_dict[p_name] = float(mean_q_value)
                                mean_lane_stats.append(float(mean_q_value))
                            # create the graphic for q30 quality
                            heading = 'Lane ' + str(lane)
                            sub_caption = 'Comparison of bases with Q value bigger than 30'
                            x_axis_name = 'Projects'
                            y_axis_name = 'Q 30 (ln %)'
                            q30_chart_number = 'q30_chart' + str(lane)
                            q30_index_graph = 'exq'+ str(lane)
                            ####### end creation q_30
                            data_source = researcher_project_column_graphic (heading, sub_caption, x_axis_name, y_axis_name, theme_q30, q_30_dict)
                            #import pdb; pdb.set_trace()
                            q30_researcher_graph[lane] = FusionCharts("column3d", q30_index_graph , "500", "350", q30_chart_number, "json", data_source).render()
                            # create the graphic for mean quality
                            sub_caption = 'Comparison of bases with mean Quality Score'
                            y_axis_name = 'Mean Quality'
                            mean_chart_number = 'mean-chart' + str(lane)
                            mean_index_graph = 'exm'+ str(lane)
                            data_source = researcher_project_column_graphic (heading, sub_caption, x_axis_name, y_axis_name, theme_mean, mean_q_dict)
                            mean_q_researcher_graph[lane] = FusionCharts("column3d", mean_index_graph , "500", "350", mean_chart_number, "json", data_source).render()
                            ####### end creation mean_q
                            # collecting project stats for each lane
                            q30_user_stats.append(statistics.mean (q30_lane_stats))
                            mean_user_stats.append(statistics.mean (mean_lane_stats))

                        researcher_statistics ['q30_researcher_graph'] = q30_researcher_graph
                        researcher_statistics ['mean_q_researcher_graph'] = mean_q_researcher_graph
                        researcher_statistics ['researcher_name'] = r_name
                        researcher_statistics ['projects'] = project_names

                        # fetch percent of Q>30 and mean_q for all projects per lane to create the median
                        # to be compared with the overall percent that researcher has
                        q_30_media, mean_q_media = [] , []
                        for lane in range (1,5):
                            found_lane = NextSeqStatsLaneSummary.objects.filter(lane__exact = lane).exclude(defaultAll__isnull = False)
                            q_30_list , mean_q_list = [] , []
                            #import pdb; pdb.set_trace()
                            for item_lane in found_lane:
                                #import pdb; pdb.set_trace()
                                q_30_value, mean_q_value , yield_mb , cluster_pf = item_lane.get_stats_info().split(';')
                                q_30_list.append(float(q_30_value))
                                mean_q_list.append(float(mean_q_value))
                            #import pdb; pdb.set_trace()
                            q_30_media_lane = format(statistics.mean (q_30_list),'.2f')
                            mean_q_media_lane = format(statistics.mean (mean_q_list), '.2f')
                            q_30_media.append(q_30_media_lane)
                            q30_media_in_float.append(statistics.mean (q_30_list))
                            mean_q_media.append(mean_q_media_lane)
                            mean_media_in_float.append(statistics.mean (mean_q_list))
                        # getting the average for user and for all projects
                        #import pdb; pdb.set_trace()
                        user_q30_average =  format(statistics.mean (q30_user_stats),'.2f')
                        user_mean_average = format(statistics.mean (mean_user_stats),'.2f')

                        overall_q30_average =  format(statistics.mean (q30_media_in_float),'.2f')
                        overall_mean_average = format(statistics.mean (mean_media_in_float),'.2f')

                        heading = 'Comparison of bases with Q value bigger than 30'
                        x_axis_name = 'Lanes'
                        y_axis_name = 'Q > 30 (in %)'

                        data_source = researcher_project_mean_column_graphic(heading, x_axis_name, y_axis_name , q30_user_stats , q_30_media, user_q30_average,overall_q30_average, r_name)
                        q_30_mscol2D = FusionCharts("mscolumn3d", "ex1" , "600", "400", "comparation_q30_chart", "json", data_source)

                        heading = 'Comparison of bases with Mean Quality'
                        y_axis_name = 'Mean in %'
                        data_source = researcher_project_mean_column_graphic(heading, x_axis_name, y_axis_name , mean_user_stats , mean_q_media, user_mean_average, overall_mean_average, r_name)
                        mean_q_mscol2D = FusionCharts("mscolumn3d", "ex2" , "600", "400", "comparation_mean_chart", "json", data_source)
                        #import pdb; pdb.set_trace()

                        researcher_statistics ['comparation_q_30_chart'] = q_30_mscol2D.render()
                        researcher_statistics ['comparations_mean_q_chart'] = mean_q_mscol2D.render()

                        #import pdb; pdb.set_trace()
                        # returning complete JavaScript and HTML code, which is used to generate chart in the browsers.
                        return  render(request, 'iSkyLIMS_wetlab/NextSeqStatsPerResearcher.html', {'researcher_several_projects' : researcher_statistics})

                else:
                    #import pdb; pdb.set_trace()
                    return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Researcher does not have projects in Completed state. ',
                                                            'ADVICE:', 'Contact with your administrator']})
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Researcher does not have projects associated to him ',
                                                            'ADVICE:', 'Contact with your administrator']})
        else:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for researcher name  ',
                                                                'ADVICE:', 'Contact with your administrator']})
    else:
        return render (request, 'iSkyLIMS_wetlab/NextSeqStatsPerResearcher.html', {})


@login_required
def nextSeqStats_per_time (request):
    if request.method=='POST':
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
         ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})

        #############################################################
        #### searching for runs were match the state and start and end date
        #############################################################
        if (start_date != '' and end_date != ''):
            stat_per_time ={}
            if (RunProcess.objects.filter( runState='Completed', run_date__range=(start_date, end_date)).exists()):
                run_stats_list=RunProcess.objects.filter(runState='Completed', run_date__range=(start_date, end_date)).order_by('run_date')
                #import pdb; pdb.set_trace()

                run_list={}
                run_date_name ={}
                ## get the run names that matches de conditions
                for run in run_stats_list:
                    #run_list.append([run.get_run_name(),run.id])
                    run_date = str(run.run_date)
                    if run_date in run_date_name:
                        run_date_name [run_date] +=1
                    else:
                        run_date_name[run_date] = 1
                    run_list [run.id] = [[run.get_run_name(), run_date]]
                    #import pdb; pdb.set_trace()
                stat_per_time ['run_names'] = run_list
                if len (run_stats_list) == 1:
                    number_of_runs = '1 Run'
                else:
                    number_of_runs = str(len (run_stats_list)) + '  Runs'
                stat_per_time ['number_of_runs'] = number_of_runs
                stat_per_time ['dates'] = start_date + ' and  ' + end_date
                #import pdb; pdb.set_trace()
                ############################################################
                ### define the graphics for found run in the period
                heading = 'Runs found during the period ' + str(start_date) + ' and ' + str(end_date)
                sub_caption = ''
                x_axis_name = 'Date'
                y_axis_name = 'Number of runs'
                run_period_chart_number = 'run_period_chart-1'
                run_period_index_graph = 'exq1'

                data_source = researcher_project_column_graphic (heading, sub_caption, x_axis_name, y_axis_name, 'ocean', run_date_name)
                stat_per_time['run_period_graphic'] = FusionCharts("column3d", run_period_index_graph , "550", "350", run_period_chart_number, "json", data_source).render()

                ####### end creation run preparation graphics

                #############################################################
                ### collect statistics for Projects
                if (Projects.objects.filter( procState='Completed', project_run_date__range=(start_date, end_date)).exists()):
                    project_found_list = Projects.objects.filter( procState='Completed', project_run_date__range=(start_date, end_date))

                    project_list={}
                    project_date_name ={}
                    ## get the project names that matches de conditions
                    for project in project_found_list:
                        project_run_date = str(project.project_run_date)
                        if project_run_date in project_date_name:
                            project_date_name [project_run_date] +=1
                        else:
                            project_date_name[project_run_date] = 1
                        project_list [project.id] = [[project.get_project_name(), project_run_date]]
                        #import pdb; pdb.set_trace()
                    stat_per_time ['project_names'] = project_list
                    if len (project_found_list) == 1:
                        number_of_projects = '1 Project'
                    else:
                        number_of_projects = str(len (project_found_list)) + '  Projects'
                    stat_per_time ['number_of_projects'] = number_of_projects
                    stat_per_time ['dates'] = start_date + ' and  ' + end_date
                    #import pdb; pdb.set_trace()
                    ############################################################
                    ### define the graphics for found run in the period
                    heading = 'Projects found during the period ' + str(start_date) + ' and ' + str(end_date)
                    sub_caption = ''
                    x_axis_name = 'Date'
                    y_axis_name = 'Number of Projects'
                    run_period_chart_number = 'project_period_chart-1'
                    run_period_index_graph = 'project_period-1'

                    data_source = researcher_project_column_graphic (heading, sub_caption, x_axis_name, y_axis_name, 'carbon', project_date_name)
                    stat_per_time['project_period_graphic'] = FusionCharts("column3d", run_period_index_graph , "550", "350", run_period_chart_number, "json", data_source).render()

                ####### end creation run preparation graphics


                #############################################################
                ### collect statistics for unkow Barcodes
                top_unbarcode_list = []
                top_count_sequence  = {}
                for lane_number in range (1,5):
                    top_unbarcode_dict_lane  = {}
                    for run in run_stats_list:
                        run_id = run.id
                        top_unbarcode = RawTopUnknowBarcodes.objects.filter(runprocess_id__exact =run_id, lane_number__exact = lane_number, top_number__exact = 1)
                        count ,sequence  = top_unbarcode[0].get_unknow_barcodes().split(';')
                        count_float = float(count.replace(',',''))
                        #import pdb; pdb.set_trace()
                        ## Count the number of times that the sequence is found per project and lane
                        if sequence in top_unbarcode_dict_lane :
                            top_unbarcode_dict_lane [sequence] += 1
                        else:
                            top_unbarcode_dict_lane [sequence] =1

                        if sequence in top_count_sequence :
                            top_count_sequence [sequence] += count_float
                        else:
                            top_count_sequence [sequence]= count_float

                    top_unbarcode_list.append(top_unbarcode_dict_lane)

                l_count = 1
                themes = ['', 'ocean','fint','carbon','zune']
                # prepare the column graphic for nunber of top Unknow Barcode
                for lane_unbarcode in top_unbarcode_list:
                    heading = 'Number of undetermined barcode sequence in lane ' + str(l_count)
                    data_source = graphic_for_top_unbarcodes(heading , themes[l_count] , lane_unbarcode)

                    chart_number = 'chart-' + str(l_count)
                    render_number = 'ex'+ str(l_count)
                    lane_chart = 'lane_chart'+ str(l_count)
                    lane_graphic = FusionCharts("column3d", render_number , "500", "400", chart_number, "json", data_source)
                    #import pdb; pdb.set_trace()
                    stat_per_time [lane_chart] = lane_graphic.render()
                    l_count +=1

                # prepare the pie graphic for the number of top Unknow Barcode per sequence
                data_source = pie_graphic_for_unknow_barcode('Number of count for the Undetermined Sequences', 'fint',top_count_sequence)
                unknow_pie3d = FusionCharts("pie3d", "ex5" , "500", "400", "chart-5", "json", data_source)
                stat_per_time ['unknow_pie3d'] = unknow_pie3d.render()

                #########################
                ### Insert information for disk space utilization
                run_disk_utilization ={}
                for run_disk_stats in run_stats_list :
                    run_name_disk = run_disk_stats.runName
                    run_disk_utilization[run_name_disk] = run_disk_stats.get_disk_space_utilization()


                heading = 'Disk space used for each Run found during the period ' + str(start_date) + ' and ' + str(end_date)
                sub_caption = ''
                x_axis_name = 'Date'
                y_axis_name = 'Disk space used (MB)'
                disk_space_period_chart_number = 'disk_usage_chart-1'
                disk_space_period_index_graph = 'diskusage1'

                data_source = researcher_project_column_graphic (heading, sub_caption, x_axis_name, y_axis_name, 'carbon', run_disk_utilization)
                stat_per_time['disk_space_period_graphic'] = FusionCharts("column3d", disk_space_period_index_graph , "550", "350", disk_space_period_chart_number, "json", data_source).render()

                #import pdb; pdb.set_trace()
                return render(request, 'iSkyLIMS_wetlab/NextSeqStatsPerTime.html', {'display_stats_per_time': stat_per_time })

            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['No matches have been found for Runs created between', start_date, ' and the ',  end_date ]})
        else:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':'Start date and End Date cannot be empty '})

        #############################################################

    return render (request,'iSkyLIMS_wetlab/NextSeqStatsPerTime.html')

def get_list_of_libraries_values (library_found, q30_comparations, mean_comparations , n_bases_comparations) :

    for project_to_compare in library_found :
        library_to_compare_name = project_to_compare.get_library_name()
        project_to_compare_id = project_to_compare.id
        q30_compare_lib, mean_compare_lib, yield_mb_compare_lib = [], [] , []
        for lane_number in range (1,5):
            lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_to_compare_id, lane__exact = lane_number)
            q_30_value, mean_q_value, yield_mb , cluster_pf = lane_in_project.get_stats_info().split(';')
            q30_compare_lib.append(float(q_30_value))
            mean_compare_lib.append(float(mean_q_value))
            yield_mb_compare_lib.append(float(yield_mb.replace(',','')))
        if library_to_compare_name in q30_comparations:
            q30_tmp_list =[float(q30_comparations [library_to_compare_name]), statistics.mean (q30_compare_lib)]
            q30_comparations [library_to_compare_name] = format(statistics.mean (q30_tmp_list), '.2f')
            mean_tmp_list = [float(mean_comparations [library_to_compare_name]), statistics.mean (mean_compare_lib)]
            mean_comparations [library_to_compare_name] = format(statistics.mean (mean_tmp_list), '.2f')
            n_bases_list =[float(n_bases_comparations [library_to_compare_name]), statistics.mean (yield_mb_compare_lib)]
            n_bases_comparations [library_to_compare_name] = format(statistics.mean (n_bases_list), '.2f')
        else:
            q30_comparations [library_to_compare_name] = format(statistics.mean (q30_compare_lib), '.2f')
            mean_comparations [library_to_compare_name] = format(statistics.mean (mean_compare_lib), '.2f')
            n_bases_comparations [library_to_compare_name] = format(statistics.mean (yield_mb_compare_lib), '.2f')


@login_required
def nextSeqStats_per_library (request):
    if request.method=='POST' :
        library_kit_name=request.POST['libraryKitName']
        start_date=request.POST['startdate']
        end_date=request.POST['enddate']
        # check that some values are in the request if not return the form
        if library_kit_name == '' and start_date == '' and end_date == '' :
            return render(request, 'iSkyLIMS_wetlab/NextSeqStatsPerLibrary.html')

        if library_kit_name !=''  and len(library_kit_name) <3 :
             return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The user name must contains at least 4 caracters ',
                                                                    'ADVICE:', 'write the full Library Kit name to get a better match']})
        ### check the right format of start and end date
        if start_date != '':
            try:
                datetime.datetime.strptime(start_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "Start Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if end_date != '':
            try:
                datetime.datetime.strptime(end_date, '%Y-%m-%d')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['The format for the "End Date Search" Field is incorrect ',
                                                                    'ADVICE:', 'Use the format  (YYYY-MM-DD)']})
        if library_kit_name != '':
            if Projects.objects.filter(libraryKit__contains = library_kit_name, procState = 'Completed').exists():
                library_found = Projects.objects.filter(libraryKit__contains = library_kit_name, procState = 'Completed')
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name]})
        else:
            library_found = Projects.objects.filter(procState__exact = 'Completed')
        if (start_date != '' and end_date != ''):
            if library_found.filter(project_run_date__range=(start_date, end_date)).exists():
                 library_found = library_found.filter(project_run_date__range=(start_date, end_date))
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' created between ', start_date, 'and the ', end_date]})
        if start_date !='' and end_date == '':
            if library_found.filter(project_run_date__gte = start_date).exists():
                 library_found = library_found.filter(project_run_date__gte = start_date)
                 #import pdb; pdb.set_trace()
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' starting from', start_date]})
        if start_date =='' and end_date != '':
            if library_found.filter(project_run_date__lte = end_date).exists():
                #import pdb; pdb.set_trace()
                library_found = library_found.filter(project_run_date__lte = end_date)
            else:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['There are no Library containing ', library_kit_name,
                                        ' finish before ', end_date]})

        #Collecting the statistics for the selected library
        # Get the projects which are using the library kit
        #import pdb; pdb.set_trace()
        library_stats ={}
        projects_name_in_library =[]
        q_30_list , mean_q_list , yield_mb_list = [] , [] ,[]
        # Getting 1 library. Library could be in several projects. Information is collected per lane and by project
        #check if only 1 library kit matches the query
        library_names ={}
        for library in library_found :
            library_names [library.libraryKit] = 1
        #import pdb; pdb.set_trace()
        if len(library_names) == 1:
            # There is only 1 library in the query. Results displays all projects data which have this library kit
            mean_lane_graphic ={}
            for project in library_found :
                projects_name_in_library.append(project.get_project_name())
            q30_in_lib, mean_in_lib, yield_mb_in_lib = [], [] , []
            for lane_number in range (1,5):
                q_30_lane , mean_q_lane , yield_mb_lane = {} , {} ,{}
                for project in library_found :
                    project_id = project.id
                    # Get quality information for each Lane summary of the project id
                    #import pdb; pdb.set_trace()
                    lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_id, lane__exact = lane_number)
                    q_30_value, mean_q_value, yield_mb , cluster_pf = lane_in_project.get_stats_info().split(';')
                    project_name = project.get_project_name()
                    q_30_lane[project_name] = q_30_value
                    q30_in_lib.append(float(q_30_value))
                    mean_q_lane[project_name] = mean_q_value
                    mean_in_lib.append(float(mean_q_value))
                    yield_mb_lane[project_name] = yield_mb.replace(',','')
                    yield_mb_in_lib.append(float(yield_mb.replace(',','')))
                    #import pdb; pdb.set_trace()
                # creating the Yield MBases graphics
                chart_number = 'chart-' + str(lane_number)
                render_number = 'ex'+ str(lane_number)
                heading = 'Number of MBases in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Number of M bases', 'ocean', yield_mb_lane)
                yield_mb_lane_graphic = FusionCharts("column3d", render_number , "500", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                yield_graphic = 'yield_mb_graphic' + str(lane_number)
                library_stats [yield_graphic] = yield_mb_lane_graphic.render()

                # creating the Q30 graphics
                chart_number = 'q30-chart-' + str(lane_number)
                render_number = 'q30-ex'+ str(lane_number)
                heading = 'Percent of bases > Q30 in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Percent of Q 30', 'zune', q_30_lane)
                q30_lane_graphic = FusionCharts("column3d", render_number , "400", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                q30_graphic = 'q30_graphic' + str(lane_number)
                library_stats [q30_graphic] = q30_lane_graphic.render()

                # creating the Mean graphics
                chart_number = 'mean-chart-' + str(lane_number)
                render_number = 'mean-ex'+ str(lane_number)
                heading = 'Mean Quality Score in the projects for Lane ' + str(lane_number)
                data_source = graphic_for_library_kit (heading, 'projects in lane ' ,'Project Names', 'Percent of Q 30', 'carbon', mean_q_lane)
                mean_lane_graphic = FusionCharts("column3d", render_number , "400", "300", chart_number, "json", data_source)
                #import pdb; pdb.set_trace()
                mean_graphic = 'mean_graphic' + str(lane_number)
                library_stats [mean_graphic] = mean_lane_graphic.render()


            library_name = project.get_library_name()
            library_stats['library_name'] = library_name
            library_stats['project_names'] = projects_name_in_library
            #import pdb; pdb.set_trace()
            ########################################################################
            # set the data for the library under study
            ########################################################################
            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {}
            q30_comparations [library_name] = format(statistics.mean (q30_in_lib), '.2f')
            mean_comparations [library_name] = format(statistics.mean (mean_in_lib), '.2f')
            n_bases_comparations [library_name] = format(statistics.mean (yield_mb_in_lib), '.2f')
            error_in_library_to_compare = ''
            # get the data for the libraries to compare with
            if start_date == '' and end_date == '':
                if Projects.objects.filter(procState = 'Completed').exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed').exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison. '

            if start_date != '' and end_date == '':
                if Projects.objects.filter(procState = 'Completed', generatedat__gte = start_date).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__gte = start_date).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison, with the starting date  ' + start_date

            if start_date == '' and end_date != '':
                if Projects.objects.filter(procState = 'Completed', generatedat__lte = end_date).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__lte = end_date).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison ending with  ' + end_date

            if start_date != '' and end_date != '':
                if Projects.objects.filter(procState = 'Completed', generatedat__range =(start_date, end_date)).exclude(libraryKit__exact = library_name).exists():
                    libraries_to_compare = Projects.objects.filter(procState = 'Completed', generatedat__range =(start_date, end_date)).exclude(libraryKit__exact = library_name)
                else :
                    error_in_library_to_compare ='No other library have been found for doing the comparison for the start date  ' + start_date + '  and with the ending date  ' + end_date

            if error_in_library_to_compare == '':
                for project_to_compare in libraries_to_compare :
                    library_to_compare_name = project_to_compare.get_library_name()
                    project_to_compare_id = project_to_compare.id
                    #q_30_lane , mean_q_lane , yield_mb_lane = {} , {} ,{}
                    q30_compare_lib, mean_compare_lib, yield_mb_compare_lib = [], [] , []
                    for lane_number in range (1,5):
                        lane_in_project = NextSeqStatsLaneSummary.objects.get(project_id__exact = project_to_compare_id, lane__exact = lane_number)
                        q_30_value, mean_q_value, yield_mb , cluster_pf = lane_in_project.get_stats_info().split(';')
                        q30_compare_lib.append(float(q_30_value))
                        mean_compare_lib.append(float(mean_q_value))
                        yield_mb_compare_lib.append(float(yield_mb.replace(',','')))
                    if library_to_compare_name in q30_comparations:
                        q30_tmp_list =[float(q30_comparations [library_to_compare_name]), statistics.mean (q30_compare_lib)]
                        q30_comparations [library_to_compare_name] = format(statistics.mean (q30_tmp_list), '.2f')
                        mean_tmp_list = [float(mean_comparations [library_to_compare_name]), statistics.mean (mean_compare_lib)]
                        mean_comparations [library_to_compare_name] = format(statistics.mean (mean_tmp_list), '.2f')
                        n_bases_list =[float(n_bases_comparations [library_to_compare_name]), statistics.mean (yield_mb_compare_lib)]
                        n_bases_comparations [library_to_compare_name] = format(statistics.mean (n_bases_list), '.2f')
                    else:
                        q30_comparations [library_to_compare_name] = format(statistics.mean (q30_compare_lib), '.2f')
                        mean_comparations [library_to_compare_name] = format(statistics.mean (mean_compare_lib), '.2f')
                        n_bases_comparations [library_to_compare_name] = format(statistics.mean (yield_mb_compare_lib), '.2f')

            else:
                library_stats ['error_library'] = error_in_library_to_compare


            heading = 'Comparison of Percent of bases > Q30  '
            data_source = graphic_for_library_kit (heading, 'Q30 comparison ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            comp_q30_lib_graphic = FusionCharts("column3d", 'comp-q30-1' , "500", "300", 'comp-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_q30_graphic'] = comp_q30_lib_graphic.render()

            heading = 'Comparison of Mean Quality Score '
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score comparison ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-mean-1' , "500", "300", 'comp-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_mean_graphic'] = comp_mean_lib_graphic.render()

            heading = 'Number of Bases comparison'
            data_source = graphic_for_library_kit (heading, 'Number of Bases comparison ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-n_bases-1' , "500", "300", 'comp-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_stats ['comp_n_bases_graphic'] = comp_mean_lib_graphic.render()

            return render (request,'iSkyLIMS_wetlab/NextSeqStatsPerLibrary.html', {'display_library_stats': library_stats })
        else:
            library_list_stats ={}
            libraries_found_name =[]
            # get the library names that match with the searching criteria
            for library in library_found :
                lib_name =library.get_library_name ()
                if not lib_name in libraries_found_name :
                    libraries_found_name.append(lib_name)
            #import pdb; pdb.set_trace()
            library_list_stats['library_names'] = libraries_found_name
            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {}
            ###
            # get the data for displaying the libraries found in the form request
            ###
            get_list_of_libraries_values (library_found, q30_comparations, mean_comparations , n_bases_comparations)

            heading = 'Comparison of Percent of bases > Q30  '
            data_source = graphic_for_library_kit (heading, 'Q30 comparison ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            comp_q30_lib_graphic = FusionCharts("column3d", 'comp-q30-1' , "500", "300", 'comp-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_q30_graphic'] = comp_q30_lib_graphic.render()

            heading = 'Comparison of Mean Quality Score '
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score comparison ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-mean-1' , "500", "300", 'comp-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_mean_graphic'] = comp_mean_lib_graphic.render()

            heading = 'Number of Bases comparison'
            data_source = graphic_for_library_kit (heading, 'Number of Bases comparison ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            comp_mean_lib_graphic = FusionCharts("column3d", 'comp-n_bases-1' , "500", "300", 'comp-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['comp_n_bases_graphic'] = comp_mean_lib_graphic.render()
            ###
            # get the data for displaying the libraries found in the form request
            ###
            all_libraries = Projects.objects.filter(procState = 'Completed')
            if (start_date != '' and end_date != ''):
                if all_libraries.filter(generatedat__range=(start_date, end_date)).exists():
                     library_found = library_found.filter(generatedat__range=(start_date, end_date))
            if start_date !='' and end_date == '':
                if all_libraries.filter(generatedat__gte = start_date).exists():
                     all_libraries = library_found.filter(generatedat__gte = start_date)
            if start_date =='' and end_date != '':
                if all_libraries.filter(generatedat__lte = end_date).exists():
                    #import pdb; pdb.set_trace()
                    all_libraries = library_found.filter(generatedat__lte = end_date)

            q30_comparations , mean_comparations , n_bases_comparations = {}, {} , {}
            get_list_of_libraries_values (all_libraries, q30_comparations, mean_comparations , n_bases_comparations)
            #import pdb; pdb.set_trace()
            heading = 'Library kits of Percent of bases > Q30  '
            data_source = graphic_for_library_kit (heading, 'Q30 library kits ' ,'Library Names', 'Percent of Q 30', '', q30_comparations)
            lib_q30_lib_graphic = FusionCharts("column3d", 'lib-q30-lib' , "500", "300", 'lib-q30-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_q30_graphic'] = lib_q30_lib_graphic.render()

            heading = 'Library kits of Mean Quality Score '
            data_source = graphic_for_library_kit (heading, 'Mean Quality Score Library kits ' ,'Library Names', 'Mean Quality Score', '', mean_comparations)
            lib_mean_lib_graphic = FusionCharts("column3d", 'lib-mean-lib' , "500", "300", 'lib-mean-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_mean_graphic'] = lib_mean_lib_graphic.render()

            heading = 'Number of Bases per Library kits'
            data_source = graphic_for_library_kit (heading, 'Number of Bases per Library kits ' ,'Library Names', 'Number of Bases ', '', n_bases_comparations)
            lib_mean_lib_graphic = FusionCharts("column3d", 'lib-n_bases-lib' , "500", "300", 'lib-n_bases-chart-1', "json", data_source)
            #import pdb; pdb.set_trace()
            library_list_stats ['lib_n_bases_graphic'] = lib_mean_lib_graphic.render()

            #import pdb; pdb.set_trace()
            return render (request,'iSkyLIMS_wetlab/NextSeqStatsPerLibrary.html', {'display_list_of_library_stats': library_list_stats })

    else:
        return render (request,'iSkyLIMS_wetlab/NextSeqStatsPerLibrary.html')

@login_required
def annual_report (request) :
    # check user privileges
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    if request.method=='POST' :
        year_selected = int(request.POST['yearselected'])
        # get the current year to compare with the input
        present_year = datetime.datetime.now().year
        if year_selected > present_year:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Annual Report cannot be done on the future  ',
                            'the input year in the Form  ',year_selected , 'is not allowed']})

        completed_run_in_year = RunProcess.objects.filter(run_date__year = year_selected, runState__exact = 'Completed')
        #import pdb; pdb.set_trace()
        uncompleted_run_in_year = RunProcess.objects.filter(run_date__year = year_selected).exclude(runState__exact = 'Completed')
        if len (completed_run_in_year)  == 0 and len (uncompleted_run_in_year) == 0:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Annual Report cannot be generated because there is no runs performed the year ', year_selected ]})

        annual_report_information = {}
        annual_report_information['year'] = year_selected
        number_of_runs = {}
        number_of_runs['Completed Runs'] = 0
        number_of_runs['Not Finish Runs'] = 0
        if len ( completed_run_in_year) > 0 :
            completed_run = []
            for run in completed_run_in_year :
                completed_run.append(run.get_run_name)
            annual_report_information['completed_run'] = completed_run
            number_of_runs['Completed Runs'] = len ( completed_run_in_year)
        if len ( uncompleted_run_in_year) > 0 :
            uncompleted_run = []
            for run_uncompleted in uncompleted_run_in_year :
                uncompleted_run.append(run_uncompleted.get_run_name)
            annual_report_information['uncompleted_run'] = uncompleted_run
            number_of_runs['Not Finish Runs'] = len ( uncompleted_run_in_year)
        # prepare the pie graphic for the number of completed/ unfinished runs
        data_source = pie_graphic_year('Number of Runs performed on the year', "",'ocean',number_of_runs)
        graphic_completed_run = FusionCharts("pie3d", "ex1" , "400", "300", "chart-1", "json", data_source)
        annual_report_information ['graphic_completed_run'] = graphic_completed_run.render()

        #import pdb; pdb.set_trace()
        ### Collecting information from NextSeqStatsBinRunSummary
        run_found_bin_summary_year = NextSeqStatsBinRunSummary.objects.filter(stats_summary_run_date__year = year_selected, level__exact = 'Total')
        q30_year, aligned_year, error_rate_year  = {} , {} , {}
        for run_bin_summary in run_found_bin_summary_year :
            bin_summary_data = run_bin_summary.get_bin_run_summary().split(';')
            run_name = run_bin_summary.runprocess_id.get_run_name()
            aligned_year[run_name]= bin_summary_data[2]
            error_rate_year[run_name]= bin_summary_data[3]
            q30_year[run_name]= bin_summary_data[5]
        annual_report_information ['aligned_data'] = aligned_year
        annual_report_information ['error_rate_data'] = error_rate_year
        annual_report_information ['q30_data'] = q30_year
        # graphics for NextSeqStatsBinRunSummary
        heading = 'Aligned % for the runs done on year '+ str(year_selected )
        data_source = column_graphic_for_year_report (heading, 'Aligned  ' , 'Run names ', 'Aligned (in %)', 'ocean', aligned_year)
        aligned_year_graphic = FusionCharts("column3d", 'aligned_year' , "600", "300", 'aligned_chart-3', "json", data_source)
        annual_report_information ['aligned_graphic'] = aligned_year_graphic.render()

        heading = 'Error Rate for the runs done on year '+ str(year_selected )
        data_source = column_graphic_for_year_report (heading, 'Error rate ' , 'Run names ', 'Error rate', 'carbon', error_rate_year)
        error_rate_year_graphic = FusionCharts("column3d", 'error_rate_year' , "600", "300", 'error_rate_chart-4', "json", data_source)
        annual_report_information ['error_rate_graphic'] = error_rate_year_graphic.render()

        heading = '>Q30 for the runs done on year '+ str(year_selected )
        data_source = column_graphic_for_year_report (heading, 'Q30  ' , 'Run names ', '>Q 30 (in %)', 'fint', q30_year)
        q30_year_graphic = FusionCharts("column3d", 'q30_year' , "600", "300", 'q30_chart-2', "json", data_source)
        #import pdb; pdb.set_trace()
        annual_report_information ['q30_graphic'] = q30_year_graphic.render()
        #import pdb; pdb.set_trace()

        # Get the information for investigator name and the projects done
        # number_proyects_investigator contains a dict with 3 ranges 1-5, 6-10, more than 11
        investigator_projects = Projects.objects.filter(project_run_date__year = year_selected).order_by('user_id')
        project_by_user = {}
        investigator_5_project, investigator_10_project, investigator_more_10_project = {}, {} , {}
        #import pdb; pdb.set_trace()
        for investigator in investigator_projects:
            user_name = investigator.get_user_name()
            if user_name in project_by_user:
                project_by_user [user_name].append(investigator.get_project_name())
            else:
                project_by_user [user_name]=([investigator.get_project_name()])
        for key, value in project_by_user.items():
            if len(value) <= 5 :
                investigator_5_project[key]= value
            elif len (value) <=10:
                investigator_10_project[key]= value
            else:
                investigator_more_10_project[key]= value
        annual_report_information['user_5_projects'] = investigator_5_project
        annual_report_information['user_10_projects'] = investigator_10_project
        annual_report_information['user_more_10_projects'] = investigator_more_10_project

        # Create the bar graphic for user projects
        p_user_year ={}
        p_user_year['1 - 5']= len(investigator_5_project)
        p_user_year['6 - 10']= len(investigator_10_project)
        p_user_year['more than 10']= len(investigator_more_10_project)
        heading = 'Projects done per investigator on year '+ str(year_selected )
        data_source = column_graphic_for_year_report (heading, '  ' , 'Projects ', 'number of users', 'ocean', p_user_year)
        p_user_year_graphic = FusionCharts("column3d", 'bar_project_user_year' , "400", "300", 'p_user_chart-1', "json", data_source)
        annual_report_information ['p_user_year_graphic'] = p_user_year_graphic.render()

        data_source = pie_graphic_year (heading, 'Percentage' ,'carbon', p_user_year)
        pie_p_user_year_graphic = FusionCharts("pie3d", "pie_project_user_year" , "400", "300", "p_user_chart-2", "json", data_source)
        annual_report_information ['pie_p_user_year_graphic'] = pie_p_user_year_graphic.render()
        #import pdb; pdb.set_trace()
        return render (request, 'iSkyLIMS_wetlab/AnnualReport.html',{'display_annual_report': annual_report_information})
    else:
        return render (request, 'iSkyLIMS_wetlab/AnnualReport.html')

@login_required
def monthly_report (request) :
    # check user privileges
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    if request.method=='POST' :

        input_value = request.POST['month_year_selected']
        browser_used = request.META['HTTP_USER_AGENT']
        if 'Firefox' in browser_used :
            try:
                datetime.datetime.strptime(input_value, '%m-%Y')
                month_selected, year_selected = input_value.split('-')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Input field does not have the right format  ',
                            'the right input format is MM-YYYY   the entry ', input_value , ' is not allowed']})

        else:
            try:
                datetime.datetime.strptime(input_value, '%Y-%m')
                year_selected , month_selected = input_value.split('-')
            except:
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Monthly Report input field does not have the right format  ',
                            'the right input format is MM-YYYY  ' ,' the entry ', input_value , ' is not allowed']})

        # get the current year to compare with the input
        present_year = datetime.datetime.now().year
        #import pdb; pdb.set_trace()
        if (int(year_selected) > present_year) :
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Monthly Report cannot be done on the future  ',
                            'the input year in the Form  ', year_selected , 'is not allowed']})

        present_month = datetime.datetime.now().month
        if (int(year_selected) == present_year) and (int(month_selected) > present_month) :
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Monthly Report cannot be done on the future  ',
                            'the input month in the Form  ', month_selected , 'is not allowed']})

        completed_run_in_year_month = RunProcess.objects.filter(run_date__year = year_selected,  run_date__month = month_selected ,runState__exact = 'Completed')
        #import pdb; pdb.set_trace()
        uncompleted_run_in_year_month = RunProcess.objects.filter(run_date__year = year_selected, run_date__month = month_selected).exclude(runState__exact = 'Completed')
        if len (completed_run_in_year_month)  == 0 and len (uncompleted_run_in_year_month) == 0:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Montly Report cannot be generated because there is no runs performed the year ', year_selected ]})

        monthly_report_information = {}
        monthly_report_information['month_year'] = str(month_selected + '  ' +  year_selected )
        number_of_runs = {}
        number_of_runs['Completed Runs'] = 0
        number_of_runs['Not Finish Runs'] = 0
        if len ( completed_run_in_year_month) > 0 :
            completed_run = []
            for run in completed_run_in_year_month :
                completed_run.append(run.get_run_name)
            monthly_report_information['completed_run'] = completed_run
            number_of_runs['Completed Runs'] = len ( completed_run_in_year_month)
        if len ( uncompleted_run_in_year_month) > 0 :
            uncompleted_run = []
            for run_uncompleted in uncompleted_run_in_year_month :
                uncompleted_run.append(run_uncompleted.get_run_name)
            monthly_report_information['uncompleted_run'] = uncompleted_run
            number_of_runs['Not Finish Runs'] = len ( uncompleted_run_in_year_month)
        # prepare the pie graphic for the number of completed/ unfinished runs
        heading = str ('Graphics of the Runs performed on the ' + month_selected + ' - ' + year_selected)
        data_source = pie_graphic_year(heading, "",'ocean',number_of_runs)
        graphic_completed_run = FusionCharts("pie3d", "ex1" , "400", "300", "chart-1", "json", data_source)
        monthly_report_information ['graphic_completed_run'] = graphic_completed_run.render()

        # Get the information for investigator name and the projects done
        # number_proyects_investigator contains a dict with 3 ranges 1, 2, more than 2
        investigator_projects = Projects.objects.filter(project_run_date__year = year_selected, project_run_date__month = month_selected).order_by('user_id')
        project_by_user = {}
        investigator_1_project, investigator_2_projects, investigator_more_2_projects = {}, {} , {}
        #import pdb; pdb.set_trace()
        for investigator in investigator_projects:
            user_name = investigator.get_user_name()
            if user_name in project_by_user:
                project_by_user [user_name].append(investigator.get_project_name())
            else:
                project_by_user [user_name]=([investigator.get_project_name()])
        for key, value in project_by_user.items():

            if len(value) == 1 :
                investigator_1_project[key]= value
            elif len (value) == 2:
                investigator_2_projects[key]= value
            else:
                investigator_more_2_projects[key]= value
        monthly_report_information['user_1_project'] = investigator_1_project
        monthly_report_information['user_2_projects'] = investigator_2_projects
        monthly_report_information['user_more_2_projects'] = investigator_more_2_projects

        # Create the bar graphic for user projects
        p_user_month ={}
        p_user_month['1 project']= len(investigator_1_project)
        p_user_month['2 projects']= len(investigator_2_projects)
        p_user_month['more than 2']= len(investigator_more_2_projects)

        heading = 'Projects done per investigator on '+ str(month_selected + ' - ' + year_selected )
        data_source = column_graphic_for_year_report (heading, '  ' , 'Projects ', 'number of users', 'ocean', p_user_month)
        p_user_monthly_graphic = FusionCharts("column3d", 'bar_project_user_month' , "400", "300", 'p_user_chart-1', "json", data_source)
        monthly_report_information ['p_user_monthly_graphic'] = p_user_monthly_graphic.render()

        data_source = pie_graphic_year (heading, 'Percentage' ,'carbon', p_user_month)
        pie_p_user_monthly_graphic = FusionCharts("pie3d", "pie_project_user_month" , "400", "300", "p_user_chart-2", "json", data_source)
        monthly_report_information ['pie_p_user_monthly_graphic'] = pie_p_user_monthly_graphic.render()

        ### Collecting information from NextSeqStatsBinRunSummary
        run_found_bin_summary_month = NextSeqStatsBinRunSummary.objects.filter(stats_summary_run_date__year = year_selected, stats_summary_run_date__month = month_selected, level__exact = 'Total')
        q30_month, aligned_month, error_rate_month  = {} , {} , {}
        for run_bin_summary in run_found_bin_summary_month :
            bin_summary_data = run_bin_summary.get_bin_run_summary().split(';')
            run_name = run_bin_summary.runprocess_id.get_run_name()
            aligned_month[run_name]= bin_summary_data[2]
            error_rate_month[run_name]= bin_summary_data[3]
            q30_month[run_name]= bin_summary_data[5]
        monthly_report_information ['aligned_data'] = aligned_month
        monthly_report_information ['error_rate_data'] = error_rate_month
        monthly_report_information ['q30_data'] = q30_month
        # graphics for NextSeqStatsBinRunSummary
        heading = 'Aligned % for the runs done on '+ str(month_selected + ' - ' + year_selected)
        data_source = column_graphic_for_year_report (heading, 'Aligned  ' , 'Run names ', 'Aligned (in %)', 'ocean', aligned_month)
        aligned_month_graphic = FusionCharts("column3d", 'aligned_year' , "600", "300", 'aligned_chart-3', "json", data_source)
        monthly_report_information ['aligned_graphic'] = aligned_month_graphic.render()

        heading = 'Error Rate for the runs done on  '+ str(month_selected + ' - ' + year_selected)
        data_source = column_graphic_for_year_report (heading, 'Error rate ' , 'Run names ', 'Error rate', 'carbon', error_rate_month)
        error_rate_month_graphic = FusionCharts("column3d", 'error_rate_year' , "600", "300", 'error_rate_chart-4', "json", data_source)
        monthly_report_information ['error_rate_graphic'] = error_rate_month_graphic.render()

        heading = '>Q30 for the runs done on  '+ str(month_selected + ' - ' + year_selected)
        data_source = column_graphic_for_year_report (heading, 'Q30  ' , 'Run names ', '>Q 30 (in %)', 'fint', q30_month)
        q30_month_graphic = FusionCharts("column3d", 'q30_year' , "600", "300", 'q30_chart-2', "json", data_source)
        #import pdb; pdb.set_trace()
        monthly_report_information ['q30_graphic'] = q30_month_graphic.render()

        #import pdb; pdb.set_trace()

        return render (request, 'iSkyLIMS_wetlab/MonthlyReport.html',{'display_monthly_report': monthly_report_information})
    else:
        return render (request, 'iSkyLIMS_wetlab/MonthlyReport.html')

@login_required
def quarter_report (request) :
    # check user privileges
    if request.user.is_authenticated:
        try:
            groups = Group.objects.get(name='WetlabManager')
            if groups not in request.user.groups.all():
                return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
        except:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['You do have the enough privileges to see this page ','Contact with your administrator .']})
    else:
        #redirect to login webpage
        return redirect ('/accounts/login')

    if request.method=='POST' :
        year_selected = request.POST['yearselected']
        quarter_selected = int(request.POST['quarter'])
        quarter_string = ['', 'First Quarter (January -- March) ', 'Second Quarter (April -- June) ',
                            'Third Quarter (July -- September) ', 'Fourth Quarter (October -- Decemmber) ' ]
        days_in_end_quarter = ['0','31','30','30','31']
        start_quarter = str(quarter_selected *3 -2)
        end_quarter = str(quarter_selected *3)
        start_date = str(year_selected + '-' + start_quarter + '-01')
        end_date = str(year_selected + '-' + end_quarter + '-' + days_in_end_quarter[quarter_selected])
        # get the current year to compare with the input
        present_year = datetime.datetime.now().year
        if int (year_selected) > present_year:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Quarter Report cannot be done on the future  ',
                            'the input year in the Form  ',year_selected , 'is not allowed']})

        present_month = datetime.datetime.now().month
        if (int(year_selected) == present_year) and (int(end_quarter) > present_month) :
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Quater Report cannot be done on the future  ',
                            'the selected Quarter ', quarter_string [quarter_selected] + str(year_selected) , 'is not allowed']})

        #import pdb; pdb.set_trace()
        completed_run_in_quarter = RunProcess.objects.filter( run_date__range =(start_date, end_date) , runState__exact = 'Completed')
        #import pdb; pdb.set_trace()
        uncompleted_run_in_quarter = RunProcess.objects.filter(run_date__range =(start_date, end_date)).exclude(runState__exact = 'Completed')
        if len (completed_run_in_quarter)  == 0 and len (uncompleted_run_in_quarter) == 0:
            return render (request,'iSkyLIMS_wetlab/error_page.html', {'content':['Quater Report cannot be generated because there is no runs performed the Quarter ',
                            quarter_string [quarter_selected] + str(year_selected) ]})

        quarter_report_information = {}
        quarter_report_information['quarter_year'] = quarter_string [quarter_selected] + str(year_selected)
        number_of_runs = {}
        number_of_runs['Completed Runs'] = 0
        number_of_runs['Not Finish Runs'] = 0
        if len ( completed_run_in_quarter) > 0 :
            completed_run = []
            for run in completed_run_in_quarter :
                completed_run.append(run.get_run_name)
            quarter_report_information['completed_run'] = completed_run
            number_of_runs['Completed Runs'] = len ( completed_run_in_quarter)
        if len ( uncompleted_run_in_quarter) > 0 :
            uncompleted_run = []
            for run_uncompleted in uncompleted_run_in_quarter :
                uncompleted_run.append(run_uncompleted.get_run_name)
            quarter_report_information['uncompleted_run'] = uncompleted_run
            number_of_runs['Not Finish Runs'] = len ( uncompleted_run_in_quarter)
        # prepare the pie graphic for the number of completed/ unfinished runs
        data_source = pie_graphic_year('Number of Runs performed on the year', "",'ocean',number_of_runs)
        graphic_completed_run = FusionCharts("pie3d", "ex1" , "400", "300", "chart-1", "json", data_source)
        quarter_report_information ['graphic_completed_run'] = graphic_completed_run.render()

        #import pdb; pdb.set_trace()
        ### Collecting information from NextSeqStatsBinRunSummary
        run_found_bin_summary_quarter = NextSeqStatsBinRunSummary.objects.filter(stats_summary_run_date__range = (start_date, end_date), level__exact = 'Total')
        q30_quarter, aligned_quarter, error_rate_quarter  = {} , {} , {}
        for run_bin_summary in run_found_bin_summary_quarter :
            bin_summary_data = run_bin_summary.get_bin_run_summary().split(';')
            run_name = run_bin_summary.runprocess_id.get_run_name()
            aligned_quarter[run_name]= bin_summary_data[2]
            error_rate_quarter[run_name]= bin_summary_data[3]
            q30_quarter[run_name]= bin_summary_data[5]
        quarter_report_information ['aligned_data'] = aligned_quarter
        quarter_report_information ['error_rate_data'] = error_rate_quarter
        quarter_report_information ['q30_data'] = q30_quarter
        # graphics for NextSeqStatsBinRunSummary
        heading = 'Aligned % for the runs done on  ' + quarter_string [quarter_selected] + str(year_selected)
        data_source = column_graphic_for_year_report (heading, 'Aligned  ' , 'Run names ', 'Aligned (in %)', 'ocean', aligned_quarter)
        aligned_quarter_graphic = FusionCharts("column3d", 'aligned_year' , "600", "300", 'aligned_chart-3', "json", data_source)
        quarter_report_information ['aligned_graphic'] = aligned_quarter_graphic.render()

        heading = 'Error Rate for the runs done on year '+ quarter_string [quarter_selected] + str(year_selected)
        data_source = column_graphic_for_year_report (heading, 'Error rate ' , 'Run names ', 'Error rate', 'carbon', error_rate_quarter)
        error_rate_quarter_graphic = FusionCharts("column3d", 'error_rate_year' , "600", "300", 'error_rate_chart-4', "json", data_source)
        quarter_report_information ['error_rate_graphic'] = error_rate_quarter_graphic.render()

        heading = '>Q30 for the runs done on year '+ quarter_string [quarter_selected] + str(year_selected)
        data_source = column_graphic_for_year_report (heading, 'Q30  ' , 'Run names ', '>Q 30 (in %)', 'fint', q30_quarter)
        q30_quarter_graphic = FusionCharts("column3d", 'q30_year' , "600", "300", 'q30_chart-2', "json", data_source)
        #import pdb; pdb.set_trace()
        quarter_report_information ['q30_graphic'] = q30_quarter_graphic.render()
        #import pdb; pdb.set_trace()

        # Get the information for investigator name and the projects done
        # number_proyects_investigator contains a dict with 3 ranges 1-5, 6-10, more than 11
        investigator_projects = Projects.objects.filter(project_run_date__range = (start_date, end_date)).order_by('user_id')
        project_by_user = {}
        investigator_5_project, investigator_10_project, investigator_more_10_project = {}, {} , {}
        #import pdb; pdb.set_trace()
        for investigator in investigator_projects:
            user_name = investigator.get_user_name()
            if user_name in project_by_user:
                project_by_user [user_name].append(investigator.get_project_name())
            else:
                project_by_user [user_name]=([investigator.get_project_name()])
        for key, value in project_by_user.items():
            if len(value) <= 5 :
                investigator_5_project[key]= value
            elif len (value) <=10:
                investigator_10_project[key]= value
            else:
                investigator_more_10_project[key]= value
        quarter_report_information['user_5_projects'] = investigator_5_project
        quarter_report_information['user_10_projects'] = investigator_10_project
        quarter_report_information['user_more_10_projects'] = investigator_more_10_project

        # Create the bar graphic for user projects
        p_user_quarter ={}
        p_user_quarter['1 - 5']= len(investigator_5_project)
        p_user_quarter['6 - 10']= len(investigator_10_project)
        p_user_quarter['more than 10']= len(investigator_more_10_project)
        heading = 'Projects done per investigator on year '+ str(year_selected )
        data_source = column_graphic_for_year_report (heading, '  ' , 'Projects ', 'number of users', 'ocean', p_user_quarter)
        p_user_quarter_graphic = FusionCharts("column3d", 'bar_project_user_year' , "400", "300", 'p_user_chart-1', "json", data_source)
        quarter_report_information ['p_user_year_graphic'] = p_user_quarter_graphic.render()

        data_source = pie_graphic_year (heading, 'Percentage' ,'carbon', p_user_quarter)
        pie_p_user_quarter_graphic = FusionCharts("pie3d", "pie_project_user_year" , "400", "300", "p_user_chart-2", "json", data_source)
        quarter_report_information ['pie_p_user_year_graphic'] = pie_p_user_quarter_graphic.render()
        #import pdb; pdb.set_trace()
        return render (request, 'iSkyLIMS_wetlab/QuarterReport.html',{'display_quarter_report': quarter_report_information})
    else:
        return render (request, 'iSkyLIMS_wetlab/QuarterReport.html')


def email (request):
    subject = 'iSkyLIMS te desea una Feliz Navidad'
    body_message = 'Feliz Navidad Sara. Ya enviamos correo desde iSkyLIMS ;-)'
    from_user = 'bioinformatica@isciii.es'
    #to_user = ['luis.chapado@amgitt.es']
    to_user = ['smonzon@isciii.es']
    request_send_mail (subject, body_message, from_user, to_user)
    #import pdb; pdb.set_trace()
    return render (request,'iSkyLIMS_wetlab/info_page.html', {'content':['Your email was sent to ', to_user, ' with the following message ', body_message]})

def open_samba_connection ():

    from smb.SMBConnection import SMBConnection
    conn=SMBConnection('bioinfocifs', 'fCdEg979I-W.gUx-teDr', 'NGS_Data', 'quibitka', use_ntlm_v2=True)
    conn.connect('172.21.7.11', 445)
    return conn

def get_size_dir (directory, conn, ):
    count_file_size = 0
    file_list = conn.listPath('NGS_Data', directory)
    for sh_file in file_list:
        if sh_file.isDirectory:
            if (sh_file.filename == '.' or sh_file.filename == '..'):
                continue

            sub_directory = os.path.join (directory,sh_file.filename)
            count_file_size += get_size_dir (sub_directory, conn)
        else:
            count_file_size += sh_file.file_size

    return count_file_size




def update_tables (request):
    #### Update the run date for the projects. NextSeqStatsBinRunRead and  NextSeqStatsBinRunSummary
    #### tables when they were not updated. It takes the run date from the run date
    '''
    run_founds = RunProcess.objects.all()
    for run in run_founds :
        run_id = run.id
        run_date = run.run_date
        projects_to_update = Projects.objects.filter(runprocess_id__exact = run_id)
        for project in projects_to_update :
            project.project_run_date = run_date
            project.save()
        stats_run_to_update = NextSeqStatsBinRunSummary.objects.filter(runprocess_id__exact = run_id)
        for stats_run in stats_run_to_update :
            stats_run.stats_summary_run_date = run_date
            stats_run.save()
        stats_read_to_update = NextSeqStatsBinRunRead.objects.filter(runprocess_id__exact = run_id)
        for  stats_read in stats_read_to_update :
            stats_read.stats_read_run_date = run_date
            stats_read.save()
    return render(request, 'iSkyLIMS_wetlab/info_page.html', {'content':['The tables have been updated']})
    '''
    ### Update the disc space used of each run
    ### It will connect to quibitka to get the size of the file for each run


    #conn=open_samba_connection()
    if RunProcess.objects.filter(runState__exact ='Completed', useSpaceImgMb = 0).exists():
        conn = open_samba_connection()
        run_list_be_updated = RunProcess.objects.filter(runState__exact = 'Completed' , useSpaceImgMb =0 )
        for run_be_updated in run_list_be_updated:
            run_id = run_be_updated.id
            run_parameter_id=RunningParameters.objects.get(pk=run_id)

            runID_value = run_parameter_id.RunID
            get_full_list = conn.listPath('NGS_Data' ,runID_value)
            rest_of_dir_size = 0
            data_dir_size = 0
            images_dir_size = 0
            in_mega_bytes = 1024*1024
            #import pdb; pdb.set_trace()
            for item_list in get_full_list:
                if item_list.filename == '.' or item_list.filename == '..':
                    continue
                if item_list.filename == 'Data':
                    dir_data = os.path.join(runID_value,'Data')
                    data_dir_size = get_size_dir(dir_data , conn)
                    continue

                elif item_list.filename == 'Images':
                    dir_images = os.path.join(runID_value, 'Images')
                    images_dir_size = get_size_dir(dir_images , conn)
                    continue

                if item_list.isDirectory:
                    item_dir = os.path.join(runID_value, item_list.filename)
                    rest_of_dir_size += get_size_dir(item_dir, conn)
                else:
                    rest_of_dir_size += item_list.file_size
            #import pdb; pdb.set_trace()
            # format file space and save it into database
            data_dir_size_formated = '{0:,}'.format(round(data_dir_size/in_mega_bytes))
            images_dir_size_formated = '{0:,}'.format(round(images_dir_size/in_mega_bytes))
            rest_of_dir_size_formated = '{0:,}'.format(round(rest_of_dir_size/in_mega_bytes))
            run_be_updated.useSpaceImgMb= images_dir_size_formated
            run_be_updated.useSpaceFastaMb= data_dir_size_formated
            run_be_updated.useSpaceOtherMb= rest_of_dir_size_formated
            #import pdb; pdb.set_trace()
            run_be_updated.save()

        '''

        get_full_list = conn.listPath('NGS_Data' ,run_name)
        rest_of_dir_size = 0
        data_dir_size = 0
        images_dir_size = 0


        conn.close()

        '''
        return render(request, 'iSkyLIMS_wetlab/info_page.html', {'content':['The Disk space usage have been updated']})
    else:
        return render(request, 'iSkyLIMS_wetlab/error_page.html', {'content':['There is no tables which requiered to update with Disk space usage information']})

def update_tables_date (request):
    if RunProcess.objects.filter(runState__exact ='Completed', run_finish_date = None).exists():
        #import pdb; pdb.set_trace()
        conn = open_samba_connection()
        run_list_be_updated = RunProcess.objects.filter(runState__exact = 'Completed' , run_finish_date = None )
        for run_be_updated in run_list_be_updated:
            run_id = run_be_updated.id
            run_parameter_id=RunningParameters.objects.get(pk=run_id)
            runID_value = run_parameter_id.RunID
            completion_file = os.path.join(runID_value, 'RunCompletionStatus.xml')
            try:
            	completion_attributes = conn.getAttributes('NGS_Data' ,completion_file)
            	# fetching the time creation on the RunCompletionStatus.xml for Run finish datetime
            	run_be_updated.run_finish_date = datetime.datetime.fromtimestamp(int(completion_attributes.create_time)).strftime('%Y-%m-%d %H:%M:%S')
            except:
            	pass
            conversion_stats_file = os.path.join (runID_value,'Data/Intensities/BaseCalls/Stats/', 'ConversionStats.xml')
            try:
            	conversion_attributes = conn.getAttributes('NGS_Data' ,conversion_stats_file)
            	#import pdb; pdb.set_trace()
            	run_be_updated.bcl2fastq_finish_date = datetime.datetime.fromtimestamp(int(conversion_attributes.create_time)).strftime('%Y-%m-%d %H:%M:%S')
            except:
            	pass
            finish_process_date = NextSeqStatsBinRunSummary.objects.filter(runprocess_id__exact = run_id)
            run_be_updated.process_completed_date = finish_process_date[0].generatedat

            run_be_updated.save()

        return render(request, 'iSkyLIMS_wetlab/info_page.html', {'content':['The dates for the Runs have been updated']})
    else:
        return render(request, 'iSkyLIMS_wetlab/error_page.html', {'content':['There is no tables which requiered to update with date information']})
